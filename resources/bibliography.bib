@online{afl,
  title = {American Fuzzy Lop},
  author = {Zalewski, Michał},
  url = {https://lcamtuf.coredump.cx/afl/},
  keywords = {project/thesis},
  file = {/home/kchou/HDD/Library/References/afl.html}
}

@inproceedings{afl++paper,
  title = {{{AFL}}++: {{Combining}} Incremental Steps of Fuzzing Research},
  booktitle = {14th {{USENIX}} Workshop on Offensive Technologies ({{WOOT}} 20)},
  author = {Fioraldi, Andrea and Maier, Dominik and Eißfeldt, Heiko and Heuse, Marc},
  date = {2020-08},
  publisher = {USENIX Association},
  keywords = {suggested},
  file = {/home/kchou/HDD/Library/References/Fioraldi et al. - 2020 - AFL++ Combining incremental steps of fuzzing research - @AFLplusplus-Woot20.pdf}
}

@software{aflpp,
  title = {{{AFL}}++},
  author = {Heuse, Marc and Eißfeldt, Heiko and Fioraldi, Andrea and Maier, Dominik},
  date = {2022-01},
  origdate = {2019-05-28T14:29:06Z},
  url = {https://github.com/AFLplusplus/AFLplusplus},
  abstract = {The fuzzer afl++ is afl with community patches, qemu 5.1 upgrade, collision-free coverage, enhanced laf-intel \& redqueen, AFLfast++ power schedules, MOpt mutators, unicorn\_mode, and a lot more!},
  version = {4.00c},
  keywords = {project/thesis,repo}
}

@inproceedings{anderson1993,
  title = {Why Cryptosystems Fail},
  booktitle = {Proceedings of the 1st {{ACM}} Conference on {{Computer}} and Communications Security  - {{CCS}} '93},
  author = {Anderson, Ross},
  date = {1993},
  pages = {215--227},
  publisher = {ACM Press},
  location = {Fairfax, Virginia, United States},
  doi = {10.1145/168588.168615},
  url = {http://portal.acm.org/citation.cfm?doid=168588.168615},
  eventtitle = {The 1st {{ACM}} Conference},
  isbn = {978-0-89791-629-5},
  langid = {english},
  file = {/home/kchou/HDD/Library/References/Anderson - 1993 - Why cryptosystems fail - @andersonWhyCryptosystemsFail1993.pdf}
}

@online{anthropic2025,
  title = {Prompt Engineering Overview},
  author = {{Anthropic}},
  date = {2025},
  url = {https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview},
  langid = {english},
  organization = {Anthropic},
  file = {/home/kchou/HDD/Library/References/overview.html}
}

@software{atheris,
  title = {Google/Atheris},
  author = {{Google}},
  date = {2025-04-09T10:53:48Z},
  origdate = {2020-11-16T22:43:28Z},
  url = {https://github.com/google/atheris},
  organization = {Google},
  keywords = {repo}
}

@inproceedings{backus1959,
  title = {The Syntax and the Semantics of the Proposed International Algebraic Language of the {{Zurich ACM-GAMM Conference}}},
  booktitle = {{{ICIP Proceedings}}},
  author = {Backus, John W.},
  date = {1959},
  pages = {125--132},
  url = {https://cir.nii.ac.jp/crid/1572824501224489728}
}

@book{bacon1861,
  title = {Of the {{Proficience}} and {{Advancement}} of {{Learning}}... {{Edited}} by the {{Rev}}. {{GW Kitchin}}},
  author = {Bacon, Francis},
  date = {1861},
  publisher = {Bell \& Daldy},
  url = {https://books.google.com/books?hl=en&lr=&id=_DVcAAAAcAAJ&oi=fnd&pg=PA1&dq=+Bacon,+Francis+(1605).+The+Proficience+and+Advancement+of+Learning+Divine+and+Humane.+&ots=A-u_4wtoXd&sig=OtPeJlRPbsG5vGNW71xak0G_G84},
  file = {/home/kchou/HDD/Library/References/books.html}
}

@online{bahdanau2016,
  title = {Neural {{Machine Translation}} by {{Jointly Learning}} to {{Align}} and {{Translate}}},
  author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  date = {2016-05-19},
  eprint = {1409.0473},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1409.0473},
  url = {http://arxiv.org/abs/1409.0473},
  abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/home/kchou/HDD/Library/References/Bahdanau et al. - 2016 - Neural Machine Translation by Jointly Learning to Align and Translate - @bahdanauNeuralMachineTranslation2016.pdf;/home/kchou/HDD/Library/References/1409 1.html;/home/kchou/HDD/Library/References/1409.html}
}

@online{bash,
  title = {Bash - {{GNU Project}} - {{Free Software Foundation}}},
  author = {{GNU Project}},
  url = {https://www.gnu.org/software/bash/},
  file = {/home/kchou/HDD/Library/References/bash.html}
}

@software{bellard2025,
  title = {{{QEMU}}},
  author = {Bellard, Fabrice and Maydell, Peter and {QEMU Team}},
  date = {2025-05-29},
  url = {https://www.qemu.org/},
  version = {10.0.2}
}

@online{brown2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  date = {2020-07-22},
  eprint = {2005.14165},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.14165},
  url = {http://arxiv.org/abs/2005.14165},
  abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/home/kchou/HDD/Library/References/Brown et al. - 2020 - Language Models are Few-Shot Learners - brown2020.pdf;/home/kchou/HDD/Library/References/2005.html}
}

@software{cedilnik2000,
  title = {{{CMake}} - {{Upgrade Your Software Build System}}},
  author = {Cedilnik, Andy and Hoffman, Bill and King, Brad and Martin, Ken and Neundorf, Alexander},
  date = {2000},
  url = {https://cmake.org/},
  abstract = {CMake is a powerful and comprehensive solution for managing the software build process. CMake is the de-facto standard for building C++ code, with over 2 million downloads a month.},
  file = {/home/kchou/HDD/Library/References/cmake.org.html}
}

@online{chainofthought,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  date = {2023-01-10},
  eprint = {2201.11903},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2201.11903},
  url = {http://arxiv.org/abs/2201.11903},
  abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,llm,prompting},
  file = {/home/kchou/HDD/Library/References/Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models - wei2023.pdf}
}

@online{chatgpt,
  title = {{{ChatGPT}}},
  author = {{OpenAI}},
  date = {2025},
  url = {https://chatgpt.com},
  abstract = {A conversational AI system that listens, learns, and challenges},
  langid = {american},
  file = {/home/kchou/HDD/Library/References/chatgpt.com.html}
}

@online{chen2021,
  title = {Evaluating {{Large Language Models Trained}} on {{Code}}},
  author = {Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and Ray, Alex and Puri, Raul and Krueger, Gretchen and Petrov, Michael and Khlaaf, Heidy and Sastry, Girish and Mishkin, Pamela and Chan, Brooke and Gray, Scott and Ryder, Nick and Pavlov, Mikhail and Power, Alethea and Kaiser, Lukasz and Bavarian, Mohammad and Winter, Clemens and Tillet, Philippe and Such, Felipe Petroski and Cummings, Dave and Plappert, Matthias and Chantzis, Fotios and Barnes, Elizabeth and Herbert-Voss, Ariel and Guss, William Hebgen and Nichol, Alex and Paino, Alex and Tezak, Nikolas and Tang, Jie and Babuschkin, Igor and Balaji, Suchir and Jain, Shantanu and Saunders, William and Hesse, Christopher and Carr, Andrew N. and Leike, Jan and Achiam, Josh and Misra, Vedant and Morikawa, Evan and Radford, Alec and Knight, Matthew and Brundage, Miles and Murati, Mira and Mayer, Katie and Welinder, Peter and McGrew, Bob and Amodei, Dario and McCandlish, Sam and Sutskever, Ilya and Zaremba, Wojciech},
  date = {2021-07-14},
  eprint = {2107.03374},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2107.03374},
  url = {http://arxiv.org/abs/2107.03374},
  abstract = {We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8\% of the problems, while GPT-3 solves 0\% and GPT-J solves 11.4\%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2\% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/home/kchou/HDD/Library/References/Chen et al. - 2021 - Evaluating Large Language Models Trained on Code - chen2021.pdf;/home/kchou/HDD/Library/References/2107.html}
}

@online{chen2023a,
  title = {{{HOPPER}}: {{Interpretative Fuzzing}} for {{Libraries}}},
  shorttitle = {{{HOPPER}}},
  author = {Chen, Peng and Xie, Yuxuan and Lyu, Yunlong and Wang, Yuxiao and Chen, Hao},
  date = {2023-09-07},
  eprint = {2309.03496},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.03496},
  url = {http://arxiv.org/abs/2309.03496},
  abstract = {Despite the fact that the state-of-the-art fuzzers can generate inputs efficiently, existing fuzz drivers still cannot adequately cover entries in libraries. Most of these fuzz drivers are crafted manually by developers, and their quality depends on the developers' understanding of the code. Existing works have attempted to automate the generation of fuzz drivers by learning API usage from code and execution traces. However, the generated fuzz drivers are limited to a few specific call sequences by the code being learned. To address these challenges, we present HOPPER, which can fuzz libraries without requiring any domain knowledge to craft fuzz drivers. It transforms the problem of library fuzzing into the problem of interpreter fuzzing. The interpreters linked against libraries under test can interpret the inputs that describe arbitrary API usage. To generate semantically correct inputs for the interpreter, HOPPER learns the intra- and inter-API constraints in the libraries and mutates the program with grammar awareness. We implemented HOPPER and evaluated its effectiveness on 11 real-world libraries against manually crafted fuzzers and other automatic solutions. Our results show that HOPPER greatly outperformed the other fuzzers in both code coverage and bug finding, having uncovered 25 previously unknown bugs that other fuzzers couldn't. Moreover, we have demonstrated that the proposed intra- and inter-API constraint learning methods can correctly learn constraints implied by the library and, therefore, significantly improve the fuzzing efficiency. The experiment results indicate that HOPPER is able to explore a vast range of API usages for library fuzzing out of the box.},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,with-notes},
  annotation = {Read\_Status: Not Reading\\
Read\_Status\_Date: 2025-07-15T16:20:46.360Z},
  file = {/home/kchou/HDD/Library/References/Chen et al. - 2023 - HOPPER Interpretative Fuzzing for Libraries - chen2023a.pdf;/home/kchou/HDD/Library/References/2309.html}
}

@online{cheng2025,
  title = {Towards {{Reliable LLM-Driven Fuzz Testing}}: {{Vision}} and {{Road Ahead}}},
  shorttitle = {Towards {{Reliable LLM-Driven Fuzz Testing}}},
  author = {Cheng, Yiran and Kang, Hong Jin and Shar, Lwin Khin and Dong, Chaopeng and Shi, Zhiqiang and Lv, Shichao and Sun, Limin},
  date = {2025-03-02},
  eprint = {2503.00795},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2503.00795},
  url = {http://arxiv.org/abs/2503.00795},
  abstract = {Fuzz testing is a crucial component of software security assessment, yet its effectiveness heavily relies on valid fuzz drivers and diverse seed inputs. Recent advancements in Large Language Models (LLMs) offer transformative potential for automating fuzz testing (LLM4Fuzz), particularly in generating drivers and seeds. However, current LLM4Fuzz solutions face critical reliability challenges, including low driver validity rates and seed quality trade-offs, hindering their practical adoption. This paper aims to examine the reliability bottlenecks of LLM-driven fuzzing and explores potential research directions to address these limitations. It begins with an overview of the current development of LLM4SE and emphasizes the necessity for developing reliable LLM4Fuzz solutions. Following this, the paper envisions a vision where reliable LLM4Fuzz transforms the landscape of software testing and security for industry, software development practitioners, and economic accessibility. It then outlines a road ahead for future research, identifying key challenges and offering specific suggestions for the researchers to consider. This work strives to spark innovation in the field, positioning reliable LLM4Fuzz as a fundamental component of modern software testing.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering,fuzzing,llm,llm fuzzing},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-06T10:56:05.200Z},
  file = {/home/kchou/HDD/Library/References/Cheng et al. - 2025 - Towards Reliable LLM-Driven Fuzz Testing Vision and Road Ahead - @chengReliableLLMDrivenFuzz2025.pdf;/home/kchou/HDD/Library/References/2503.html}
}

@online{claude,
  title = {Claude},
  author = {{Anthropic}},
  date = {2025},
  url = {https://claude.ai/new},
  file = {/home/kchou/HDD/Library/References/new.html}
}

@software{clib,
  title = {Clibs/Clib},
  author = {{Clibs Project}},
  date = {2025-07-01T22:43:40Z},
  origdate = {2012-10-28T07:50:09Z},
  url = {https://github.com/clibs/clib},
  abstract = {Package manager for the C programming language.},
  organization = {clibs},
  keywords = {c,clib,manager,package}
}

@online{clibs,
  title = {Clib {{Packages}}},
  author = {{Clibs Project}},
  date = {2025},
  url = {https://github.com/clibs/clib/wiki/Packages},
  abstract = {Package manager for the C programming language. Contribute to clibs/clib development by creating an account on GitHub.},
  langid = {english},
  organization = {GitHub},
  file = {/home/kchou/HDD/Library/References/Packages.html}
}

@software{clusterfuzz,
  title = {Google/Clusterfuzz},
  author = {{Google}},
  date = {2025-04-09T13:01:59Z},
  origdate = {2019-01-29T00:19:40Z},
  url = {https://github.com/google/clusterfuzz},
  abstract = {Scalable fuzzing infrastructure.},
  organization = {Google},
  keywords = {fuzzing,repo,security,stability,vulnerabilities}
}

@online{cursor,
  title = {Cursor - {{The AI Code Editor}}},
  author = {{Anysphere}},
  date = {2025},
  url = {https://cursor.com/},
  abstract = {Built to make you extraordinarily productive, Cursor is the best way to code with AI.},
  langid = {english},
  file = {/home/kchou/HDD/Library/References/cursor.com.html}
}

@online{deepseek-ai2025,
  title = {{{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},
  shorttitle = {{{DeepSeek-R1}}},
  author = {DeepSeek-AI and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
  date = {2025-01-22},
  eprint = {2501.12948},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.12948},
  url = {http://arxiv.org/abs/2501.12948},
  abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/kchou/HDD/Library/References/DeepSeek-AI et al. - 2025 - DeepSeek-R1 Incentivizing Reasoning Capability in LLMs via Reinforcement Learning - deepseek-ai2025.pdf;/home/kchou/HDD/Library/References/2501 4.html}
}

@online{devlin2019,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  date = {2019-05-24},
  eprint = {1810.04805},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1810.04805},
  url = {http://arxiv.org/abs/1810.04805},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/home/kchou/HDD/Library/References/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf;/home/kchou/HDD/Library/Zotero data/storage/QRT9E3GR/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding - devlin2019.pdf;/home/kchou/HDD/Library/References/1810 1.html;/home/kchou/HDD/Library/References/1810.html}
}

@inproceedings{dow2009,
  title = {The Efficacy of Prototyping under Time Constraints},
  booktitle = {Proceedings of the Seventh {{ACM}} Conference on {{Creativity}} and Cognition},
  author = {Dow, Steven P. and Heddleston, Kate and Klemmer, Scott R.},
  date = {2009-10-26},
  pages = {165--174},
  publisher = {ACM},
  location = {Berkeley California USA},
  doi = {10.1145/1640233.1640260},
  url = {https://dl.acm.org/doi/10.1145/1640233.1640260},
  eventtitle = {C\&{{C}} '09: {{Creativity}} and {{Cognition}} 2009},
  isbn = {978-1-60558-865-0},
  langid = {english},
  file = {/home/kchou/HDD/Library/References/Dow et al. - 2009 - The efficacy of prototyping under time constraints - dow2009.pdf}
}

@online{dspy,
  title = {{{DSPy}}: {{Compiling Declarative Language Model Calls}} into {{Self-Improving Pipelines}}},
  shorttitle = {{{DSPy}}},
  author = {Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T. and Moazam, Hanna and Miller, Heather and Zaharia, Matei and Potts, Christopher},
  date = {2023-10-05},
  eprint = {2310.03714},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.03714},
  url = {http://arxiv.org/abs/2310.03714},
  abstract = {The ML community is rapidly exploring techniques for prompting language models (LMs) and for stacking them into pipelines that solve complex tasks. Unfortunately, existing LM pipelines are typically implemented using hard-coded "prompt templates", i.e. lengthy strings discovered via trial and error. Toward a more systematic approach for developing and optimizing LM pipelines, we introduce DSPy, a programming model that abstracts LM pipelines as text transformation graphs, i.e. imperative computational graphs where LMs are invoked through declarative modules. DSPy modules are parameterized, meaning they can learn (by creating and collecting demonstrations) how to apply compositions of prompting, finetuning, augmentation, and reasoning techniques. We design a compiler that will optimize any DSPy pipeline to maximize a given metric. We conduct two case studies, showing that succinct DSPy programs can express and optimize sophisticated LM pipelines that reason about math word problems, tackle multi-hop retrieval, answer complex questions, and control agent loops. Within minutes of compiling, a few lines of DSPy allow GPT-3.5 and llama2-13b-chat to self-bootstrap pipelines that outperform standard few-shot prompting (generally by over 25\% and 65\%, respectively) and pipelines with expert-created demonstrations (by up to 5-46\% and 16-40\%, respectively). On top of that, DSPy programs compiled to open and relatively small LMs like 770M-parameter T5 and llama2-13b-chat are competitive with approaches that rely on expert-written prompt chains for proprietary GPT-3.5. DSPy is available at https://github.com/stanfordnlp/dspy},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/home/kchou/HDD/Library/References/Khattab et al. - 2023 - DSPy Compiling Declarative Language Model Calls into Self-Improving Pipelines - @khattabDSPyCompilingDeclarative2023.pdf;/home/kchou/HDD/Library/References/2310.html}
}

@article{ege2025,
  title = {{{ChatGPT}} as an Inventor: Eliciting the Strengths and Weaknesses of Current Large Language Models against Humans in Engineering Design},
  shorttitle = {{{ChatGPT}} as an Inventor},
  author = {Ege, Daniel N. and Øvrebø, Henrik H. and Stubberud, Vegar and Berg, Martin F. and Elverum, Christer and Steinert, Martin and Vestad, Håvard},
  date = {2025-01},
  journaltitle = {AI EDAM},
  volume = {39},
  pages = {e6},
  issn = {0890-0604, 1469-1760},
  doi = {10.1017/S0890060425000010},
  url = {https://www.cambridge.org/core/journals/ai-edam/article/chatgpt-as-an-inventor-eliciting-the-strengths-and-weaknesses-of-current-large-language-models-against-humans-in-engineering-design/1796F76E5B42020B42DCE586CF11E59B#},
  abstract = {This study compares the design practices and performance of ChatGPT 4.0, a large language model (LLM), against graduate engineering students in a 48-h prototyping hackathon, based on a dataset comprising more than 100 prototypes. The LLM participated by instructing two participants who executed its instructions and provided objective feedback, generated ideas autonomously and made all design decisions without human intervention. The LLM exhibited similar prototyping practices to human participants and finished second among six teams, successfully designing and providing building instructions for functional prototypes. The LLM’s concept generation capabilities were particularly strong. However, the LLM prematurely abandoned promising concepts when facing minor difficulties, added unnecessary complexity to designs, and experienced design fixation. Communication between the LLM and participants was challenging due to vague or unclear descriptions, and the LLM had difficulty maintaining continuity and relevance in answers. Based on these findings, six recommendations for implementing an LLM like ChatGPT in the design process are proposed, including leveraging it for ideation, ensuring human oversight for key decisions, implementing iterative feedback loops, prompting it to consider alternatives, and assigning specific and manageable tasks at a subsystem level.},
  langid = {english},
  keywords = {artificial intelligence,engineering design,large language model,product development,prototyping},
  file = {/home/kchou/HDD/Library/References/Ege et al. - 2025 - ChatGPT as an inventor eliciting the strengths and weaknesses of current large language models agai - ege2025.pdf}
}

@online{faiss,
  title = {The {{Faiss}} Library},
  author = {Douze, Matthijs and Guzhva, Alexandr and Deng, Chengqi and Johnson, Jeff and Szilvasy, Gergely and Mazaré, Pierre-Emmanuel and Lomeli, Maria and Hosseini, Lucas and Jégou, Hervé},
  date = {2025-02-11},
  eprint = {2401.08281},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.08281},
  url = {http://arxiv.org/abs/2401.08281},
  abstract = {Vector databases typically manage large collections of embedding vectors. Currently, AI applications are growing rapidly, and so is the number of embeddings that need to be stored and indexed. The Faiss library is dedicated to vector similarity search, a core functionality of vector databases. Faiss is a toolkit of indexing methods and related primitives used to search, cluster, compress and transform vectors. This paper describes the trade-off space of vector search and the design principles of Faiss in terms of structure, approach to optimization and interfacing. We benchmark key features of the library and discuss a few selected applications to highlight its broad applicability.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {/home/kchou/HDD/Library/References/Douze et al. - 2025 - The Faiss library - faiss.pdf;/home/kchou/HDD/Library/References/2401 1.html}
}

@article{feldman1979,
  title = {Make — a Program for Maintaining Computer Programs},
  author = {Feldman, Stuart I.},
  date = {1979},
  journaltitle = {Software: Practice and Experience},
  volume = {9},
  number = {4},
  pages = {255--265},
  issn = {1097-024X},
  doi = {10.1002/spe.4380090402},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.4380090402},
  abstract = {Good programmers break their projects into a number of pieces, each to be processed or compiled by a different chain of programs. After a set of changes is made, the series of actions that must be taken can be quite complex, and costly errors are frequently made. This paper describes a program that can keep track of the relationships between parts of a program, and issue the commands needed to make the parts consistent after changes are made. Make has been in use on UNIX UNIX is a trademark of Bell Laboratories. systems since 1975. The underlying idea is quite simple and can be adapted to many other environments.},
  langid = {english},
  keywords = {Program maintenance,Program updating},
  file = {/home/kchou/HDD/Library/References/Feldman - 1979 - Make — a program for maintaining computer programs - feldman1979.pdf;/home/kchou/HDD/Library/References/spe.html}
}

@online{flawfinder,
  title = {Flawfinder {{Home Page}}},
  author = {Wheeler, David A.},
  url = {https://dwheeler.com/flawfinder/},
  organization = {Flawfinder},
  file = {/home/kchou/HDD/Library/References/flawfinder.html}
}

@article{franksen1993,
  title = {Babbage and Cryptography. {{Or}}, the Mystery of {{Admiral Beaufort}}'s Cipher},
  author = {Franksen, Ole Immanuel},
  date = {1993},
  journaltitle = {Mathematics and Computers in Simulation},
  volume = {35},
  number = {4},
  pages = {327--367},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/037847549390063Z}
}

@inproceedings{fudge,
  title = {{{FUDGE}}: Fuzz Driver Generation at Scale},
  shorttitle = {{{FUDGE}}},
  booktitle = {Proceedings of the 2019 27th {{ACM Joint Meeting}} on {{European Software Engineering Conference}} and {{Symposium}} on the {{Foundations}} of {{Software Engineering}}},
  author = {Babić, Domagoj and Bucur, Stefan and Chen, Yaohui and Ivančić, Franjo and King, Tim and Kusano, Markus and Lemieux, Caroline and Szekeres, László and Wang, Wei},
  date = {2019-08-12},
  pages = {975--985},
  publisher = {ACM},
  location = {Tallinn Estonia},
  doi = {10.1145/3338906.3340456},
  url = {https://dl.acm.org/doi/10.1145/3338906.3340456},
  abstract = {At Google we have found tens of thousands of security and robustness bugs by fuzzing C and C++ libraries. To fuzz a library, a fuzzer requires a fuzz driver—which exercises some library code—to which it can pass inputs. Unfortunately, writing fuzz drivers remains a primarily manual exercise, a major hindrance to the widespread adoption of fuzzing. In this paper, we address this major hindrance by introducing the Fudge system for automated fuzz driver generation. Fudge automatically generates fuzz driver candidates for libraries based on existing client code. We have used Fudge to generate thousands of new drivers for a wide variety of libraries. Each generated driver includes a synthesized C/C++ program and a corresponding build script, and is automatically analyzed for quality. Developers have integrated over 200 of these generated drivers into continuous fuzzing services and have committed to address reported security bugs. Further, several of these fuzz drivers have been upstreamed to open source projects and integrated into the OSS-Fuzz fuzzing infrastructure. Running these fuzz drivers has resulted in over 150 bug fixes, including the elimination of numerous exploitable security vulnerabilities.},
  eventtitle = {{{ESEC}}/{{FSE}} '19: 27th {{ACM Joint European Software Engineering Conference}} and {{Symposium}} on the {{Foundations}} of {{Software Engineering}}},
  isbn = {978-1-4503-5572-8},
  langid = {english},
  keywords = {with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T10:20:12.413Z},
  file = {/home/kchou/HDD/Library/Zotero data/storage/VMLR5CAA/Babić et al. - 2019 - FUDGE fuzz driver generation at scale - @babicFUDGEFuzzDriver2019.pdf}
}

@software{fuzz-introspector,
  title = {Ossf/Fuzz-Introspector},
  author = {{Open Source Security Foundation (OpenSSF)}},
  date = {2025-06-30T22:12:31Z},
  origdate = {2021-12-06T19:27:40Z},
  url = {https://github.com/ossf/fuzz-introspector},
  abstract = {Fuzz Introspector -- introspect, extend and optimise fuzzers},
  organization = {Open Source Security Foundation (OpenSSF)},
  keywords = {fuzz-testing,fuzzing,security,security-research,testing,vulnerability-analysis}
}

@inproceedings{fuzzgen,
  title = {{{FuzzGen}}: {{Automatic}} Fuzzer Generation},
  shorttitle = {{{FuzzGen}}},
  booktitle = {29th {{USENIX Security Symposium}} ({{USENIX Security}} 20)},
  author = {Ispoglou, Kyriakos and Austin, Daniel and Mohan, Vishwath and Payer, Mathias},
  date = {2020},
  pages = {2271--2287},
  url = {https://www.usenix.org/conference/usenixsecurity20/presentation/ispoglou},
  abstract = {Fuzzing is a testing technique to discover unknown vulnerabilities in software. When applying fuzzing to libraries, the core idea of supplying random input remains unchanged, yet it is non-trivial to achieve good code coverage. Libraries cannot run as standalone programs, but instead are invoked through another application. Triggering code deep in a library remains challenging as specific sequences of API calls are required to build up the necessary state. Libraries are diverse and have unique interfaces that require unique fuzzers, so far written by a human analyst. To address this issue, we present FuzzGen, a tool for automatically synthesizing fuzzers for complex libraries in a given environment. FuzzGen leverages a whole system analysis to infer the library’s interface and synthesizes fuzzers specifically for that library. FuzzGen requires no human interaction and can be applied to a wide range of libraries. Furthermore, the generated fuzzers leverage LibFuzzer to achieve better code coverage and expose bugs that reside deep in the library. FuzzGen was evaluated on Debian and the Android Open Source Project (AOSP) selecting 7 libraries to generate fuzzers. So far, we have found 17 previously unpatched vulnerabilities with 6 assigned CVEs. The generated fuzzers achieve an average of 54.94\% code coverage; an improvement of 6.94\% when compared to manually written fuzzers, demonstrating the effectiveness and generality of FuzzGen.},
  keywords = {fuzzing,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T11:39:03.348Z},
  file = {/home/kchou/HDD/Library/References/Ispoglou et al. - 2020 - FuzzGen Automatic fuzzer generation - fuzzgen.pdf}
}

@online{fuzzgpt,
  title = {Large {{Language Models}} Are {{Edge-Case Fuzzers}}: {{Testing Deep Learning Libraries}} via {{FuzzGPT}}},
  shorttitle = {Large {{Language Models}} Are {{Edge-Case Fuzzers}}},
  author = {Deng, Yinlin and Xia, Chunqiu Steven and Yang, Chenyuan and Zhang, Shizhuo Dylan and Yang, Shujing and Zhang, Lingming},
  date = {2023-04-04},
  eprint = {2304.02014},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.02014},
  url = {http://arxiv.org/abs/2304.02014},
  abstract = {Bugs in Deep Learning (DL) libraries may affect almost all downstream DL applications, and it is crucial to ensure the quality of such systems. It is challenging to generate valid input programs for fuzzing DL libraries, since the input programs need to satisfy both the syntax/semantics of the supported languages (e.g., Python) and the tensor/operator constraints for constructing valid computational graphs. Recently, the TitanFuzz work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the language and DL computation constraints to generate valid programs for fuzzing DL libraries. However, LLMs tend to generate ordinary programs following similar patterns/tokens with typical programs seen in their massive training corpora (e.g., GitHub), while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced. To fill this gap, this paper proposes FuzzGPT, the first technique to prime LLMs to synthesize unusual programs for fuzzing. FuzzGPT is built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding. Meanwhile, while traditional techniques leveraging such historical information require intensive human efforts to both design dedicated generators and ensure the syntactic/semantic validity of generated programs, FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains. While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and CodeGen. Moreover, FuzzGPT also shows the potential of directly leveraging the instruct-following capability of the recent ChatGPT for effective fuzzing. The experimental study on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TitanFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Software Engineering,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T12:07:19.426Z},
  file = {/home/kchou/HDD/Library/References/Deng et al. - 2023 - Large Language Models are Edge-Case Fuzzers Testing Deep Learning Libraries via FuzzGPT - deng2023.pdf}
}

@software{fuzztest,
  title = {Google/Fuzztest},
  author = {{Google}},
  date = {2025-07-10T13:29:04Z},
  origdate = {2022-08-10T20:54:25Z},
  url = {https://github.com/google/fuzztest},
  organization = {Google}
}

@online{ganguly2024,
  title = {Proof of {{Thought}} : {{Neurosymbolic Program Synthesis}} Allows {{Robust}} and {{Interpretable Reasoning}}},
  shorttitle = {Proof of {{Thought}}},
  author = {Ganguly, Debargha and Iyengar, Srinivasan and Chaudhary, Vipin and Kalyanaraman, Shivkumar},
  date = {2024-09-25},
  eprint = {2409.17270},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2409.17270},
  url = {http://arxiv.org/abs/2409.17270},
  abstract = {Large Language Models (LLMs) have revolutionized natural language processing, yet they struggle with inconsistent reasoning, particularly in novel domains and complex logical sequences. This research introduces Proof of Thought, a framework that enhances the reliability and transparency of LLM outputs. Our approach bridges LLM-generated ideas with formal logic verification, employing a custom interpreter to convert LLM outputs into First Order Logic constructs for theorem prover scrutiny. Central to our method is an intermediary JSON-based Domain-Specific Language, which by design balances precise logical structures with intuitive human concepts. This hybrid representation enables both rigorous validation and accessible human comprehension of LLM reasoning processes. Key contributions include a robust type system with sort management for enhanced logical integrity, explicit representation of rules for clear distinction between factual and inferential knowledge, and a flexible architecture that allows for easy extension to various domain-specific applications. We demonstrate Proof of Thought's effectiveness through benchmarking on StrategyQA and a novel multimodal reasoning task, showing improved performance in open-ended scenarios. By providing verifiable and interpretable results, our technique addresses critical needs for AI system accountability and sets a foundation for human-in-the-loop oversight in high-stakes domains.},
  pubstate = {prepublished},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2025-07-11T10:05:29.861Z},
  file = {/home/kchou/HDD/Library/References/Ganguly et al. - 2024 - Proof of Thought  Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning - @gangulyProofThoughtNeurosymbolic2024.pdf;/home/kchou/HDD/Library/References/2409 1.html}
}

@inproceedings{gao2023,
  title = {Beyond the {{Coverage Plateau}}: {{A Comprehensive Study}} of {{Fuzz Blockers}} ({{Registered Report}})},
  shorttitle = {Beyond the {{Coverage Plateau}}},
  booktitle = {Proceedings of the 2nd {{International Fuzzing Workshop}}},
  author = {Gao, Wentao and Pham, Van-Thuan and Liu, Dongge and Chang, Oliver and Murray, Toby and Rubinstein, Benjamin I.P.},
  date = {2023-07-17},
  series = {{{FUZZING}} 2023},
  pages = {47--55},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3605157.3605177},
  url = {https://dl.acm.org/doi/10.1145/3605157.3605177},
  abstract = {Fuzzing and particularly code coverage-guided greybox fuzzing is highly successful in automated vulnerability discovery, as evidenced by the multitude of vulnerabilities uncovered in real-world software systems. However, results on large benchmarks such as FuzzBench indicate that the state-of-the-art fuzzers often reach a plateau after a certain period, typically around 12 hours. With the aid of the newly introduced FuzzIntrospector platform, this study aims to analyze and categorize the fuzz blockers that impede the progress of fuzzers. Such insights can shed light on future fuzzing research, suggesting areas that require further attention. Our preliminary findings reveal that the majority of top fuzz blockers are not directly related to the program input, emphasizing the need for enhanced techniques in automated fuzz driver generation and modification.},
  isbn = {979-8-4007-0247-1},
  keywords = {project/thesis},
  file = {/home/kchou/HDD/Library/References/Gao et al. - 2023 - Beyond the Coverage Plateau A Comprehensive Study of Fuzz Blockers (Registered Report) - @gaoCoveragePlateauComprehensive2023.pdf}
}

@online{gao2024,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
  date = {2024-03-27},
  eprint = {2312.10997},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.10997},
  url = {http://arxiv.org/abs/2312.10997},
  abstract = {Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,RAG},
  file = {/home/kchou/HDD/Library/References/Gao et al. - 2024 - Retrieval-Augmented Generation for Large Language Models A Survey - @gaoRetrievalAugmentedGenerationLarge2024.pdf;/home/kchou/HDD/Library/References/2312 2.html}
}

@online{garcez2020,
  title = {Neurosymbolic {{AI}}: {{The}} 3rd {{Wave}}},
  shorttitle = {Neurosymbolic {{AI}}},
  author = {family=Garcez, given=Artur, prefix=d'Avila, useprefix=false and Lamb, Luis C.},
  date = {2020-12-16},
  eprint = {2012.05876},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2012.05876},
  url = {http://arxiv.org/abs/2012.05876},
  abstract = {Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.},
  pubstate = {prepublished},
  annotation = {Read\_Status: In Progress\\
Read\_Status\_Date: 2025-02-24T20:57:10.231Z},
  file = {/home/kchou/HDD/Library/References/Garcez and Lamb - 2020 - Neurosymbolic AI The 3rd Wave - @garcezNeurosymbolicAI3rd2020.pdf;/home/kchou/HDD/Library/References/2012 1.html}
}

@online{gaur2023,
  title = {Building {{Trustworthy NeuroSymbolic AI Systems}}: {{Consistency}}, {{Reliability}}, {{Explainability}}, and {{Safety}}},
  shorttitle = {Building {{Trustworthy NeuroSymbolic AI Systems}}},
  author = {Gaur, Manas and Sheth, Amit},
  date = {2023-12-05},
  eprint = {2312.06798},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2312.06798},
  url = {http://arxiv.org/abs/2312.06798},
  abstract = {Explainability and Safety engender Trust. These require a model to exhibit consistency and reliability. To achieve these, it is necessary to use and analyze data and knowledge with statistical and symbolic AI methods relevant to the AI application - neither alone will do. Consequently, we argue and seek to demonstrate that the NeuroSymbolic AI approach is better suited for making AI a trusted AI system. We present the CREST framework that shows how Consistency, Reliability, user-level Explainability, and Safety are built on NeuroSymbolic methods that use data and knowledge to support requirements for critical applications such as health and well-being. This article focuses on Large Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs have garnered substantial attention from researchers due to their versatility in handling a broad array of natural language processing (NLP) scenarios. For example, ChatGPT and Google's MedPaLM have emerged as highly promising platforms for providing information in general and health-related queries, respectively. Nevertheless, these models remain black boxes despite incorporating human feedback and instruction-guided tuning. For instance, ChatGPT can generate unsafe responses despite instituting safety guardrails. CREST presents a plausible approach harnessing procedural and graph-based knowledge within a NeuroSymbolic framework to shed light on the challenges associated with LLMs.},
  pubstate = {prepublished},
  file = {/home/kchou/HDD/Library/References/Gaur and Sheth - 2023 - Building Trustworthy NeuroSymbolic AI Systems Consistency, Reliability, Explainability, and Safety - @gaurBuildingTrustworthyNeuroSymbolic2023.pdf;/home/kchou/HDD/Library/References/2312.html}
}

@article{gazzola2019,
  title = {Automatic {{Software Repair}}: {{A Survey}}},
  shorttitle = {Automatic {{Software Repair}}},
  author = {Gazzola, Luca and Micucci, Daniela and Mariani, Leonardo},
  date = {2019-01},
  journaltitle = {IEEE Transactions on Software Engineering},
  volume = {45},
  number = {1},
  pages = {34--67},
  issn = {1939-3520},
  doi = {10.1109/TSE.2017.2755013},
  url = {https://ieeexplore.ieee.org/document/8089448/},
  abstract = {Despite their growing complexity and increasing size, modern software applications must satisfy strict release requirements that impose short bug fixing and maintenance cycles, putting significant pressure on developers who are responsible for timely producing high-quality software. To reduce developers workload, repairing and healing techniques have been extensively investigated as solutions for efficiently repairing and maintaining software in the last few years. In particular, repairing solutions have been able to automatically produce useful fixes for several classes of bugs that might be present in software programs. A range of algorithms, techniques, and heuristics have been integrated, experimented, and studied, producing a heterogeneous and articulated research framework where automatic repair techniques are proliferating. This paper organizes the knowledge in the area by surveying a body of 108 papers about automatic software repair techniques, illustrating the algorithms and the approaches, comparing them on representative examples, and discussing the open challenges and the empirical evidence reported so far.},
  keywords = {Automatic program repair,Computer bugs,Conferences,correct by construction,Debugging,Fault diagnosis,generate and validate,localization,Maintenance engineering,program synthesis,search-based,self-repairing,semantics-driven repair,Software,Software algorithms},
  file = {/home/kchou/HDD/Library/References/Gazzola et al. - 2019 - Automatic Software Repair A Survey - @gazzolaAutomaticSoftwareRepair2019.pdf}
}

@online{gemini,
  title = {‎{{Google Gemini}}},
  author = {{Google}},
  date = {2025},
  url = {https://gemini.google.com},
  abstract = {Gemini is your personal, proactive, and powerful AI assistant from Google. Try it for free to help with work, school, and at home for whatever inspires you.},
  langid = {english},
  organization = {Gemini},
  file = {/home/kchou/HDD/Library/References/gemini.google.com.html}
}

@online{ghcopilot,
  title = {{{GitHub Copilot}} · {{Your AI}} Pair Programmer},
  author = {{Microsoft}},
  date = {2025},
  url = {https://github.com/features/copilot},
  abstract = {GitHub Copilot works alongside you directly in your editor, suggesting whole lines or entire functions for you.},
  langid = {english},
  organization = {GitHub},
  file = {/home/kchou/HDD/Library/References/copilot.html}
}

@online{giannone2025,
  title = {Demystifying {{AI Agents}}: {{ReAct-Style Agents}} vs {{Agentic Workflows}}},
  shorttitle = {Demystifying {{AI Agents}}},
  author = {Giannone, Dan},
  date = {2025-02-09T20:37:04},
  url = {https://medium.com/@DanGiannone/demystifying-ai-agents-react-style-agents-vs-agentic-workflows-cedca7e26471},
  abstract = {Understanding the current industry trends towards a “default” agent architecture and how to thoughtfully think through agent design.},
  langid = {english},
  organization = {Medium},
  keywords = {llm,llm-agents,reAct},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-22T07:06:25.712Z},
  file = {/home/kchou/HDD/Library/References/GiannoneD/2025/demystifying-ai-agents-react-style-agents-vs-agentic-workflows-cedca7e26471.html}
}

@online{grattafiori2024,
  title = {The {{Llama}} 3 {{Herd}} of {{Models}}},
  author = {Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and Yang, Amy and Fan, Angela and Goyal, Anirudh and Hartshorn, Anthony and Yang, Aobo and Mitra, Archi and Sravankumar, Archie and Korenev, Artem and Hinsvark, Arthur and Rao, Arun and Zhang, Aston and Rodriguez, Aurelien and Gregerson, Austen and Spataru, Ava and Roziere, Baptiste and Biron, Bethany and Tang, Binh and Chern, Bobbie and Caucheteux, Charlotte and Nayak, Chaya and Bi, Chloe and Marra, Chris and McConnell, Chris and Keller, Christian and Touret, Christophe and Wu, Chunyang and Wong, Corinne and Ferrer, Cristian Canton and Nikolaidis, Cyrus and Allonsius, Damien and Song, Daniel and Pintz, Danielle and Livshits, Danny and Wyatt, Danny and Esiobu, David and Choudhary, Dhruv and Mahajan, Dhruv and Garcia-Olano, Diego and Perino, Diego and Hupkes, Dieuwke and Lakomkin, Egor and AlBadawy, Ehab and Lobanova, Elina and Dinan, Emily and Smith, Eric Michael and Radenovic, Filip and Guzmán, Francisco and Zhang, Frank and Synnaeve, Gabriel and Lee, Gabrielle and Anderson, Georgia Lewis and Thattai, Govind and Nail, Graeme and Mialon, Gregoire and Pang, Guan and Cucurell, Guillem and Nguyen, Hailey and Korevaar, Hannah and Xu, Hu and Touvron, Hugo and Zarov, Iliyan and Ibarra, Imanol Arrieta and Kloumann, Isabel and Misra, Ishan and Evtimov, Ivan and Zhang, Jack and Copet, Jade and Lee, Jaewon and Geffert, Jan and Vranes, Jana and Park, Jason and Mahadeokar, Jay and Shah, Jeet and family=Linde, given=Jelmer, prefix=van der, useprefix=false and Billock, Jennifer and Hong, Jenny and Lee, Jenya and Fu, Jeremy and Chi, Jianfeng and Huang, Jianyu and Liu, Jiawen and Wang, Jie and Yu, Jiecao and Bitton, Joanna and Spisak, Joe and Park, Jongsoo and Rocca, Joseph and Johnstun, Joshua and Saxe, Joshua and Jia, Junteng and Alwala, Kalyan Vasuden and Prasad, Karthik and Upasani, Kartikeya and Plawiak, Kate and Li, Ke and Heafield, Kenneth and Stone, Kevin and El-Arini, Khalid and Iyer, Krithika and Malik, Kshitiz and Chiu, Kuenley and Bhalla, Kunal and Lakhotia, Kushal and Rantala-Yeary, Lauren and family=Maaten, given=Laurens, prefix=van der, useprefix=false and Chen, Lawrence and Tan, Liang and Jenkins, Liz and Martin, Louis and Madaan, Lovish and Malo, Lubo and Blecher, Lukas and Landzaat, Lukas and family=Oliveira, given=Luke, prefix=de, useprefix=false and Muzzi, Madeline and Pasupuleti, Mahesh and Singh, Mannat and Paluri, Manohar and Kardas, Marcin and Tsimpoukelli, Maria and Oldham, Mathew and Rita, Mathieu and Pavlova, Maya and Kambadur, Melanie and Lewis, Mike and Si, Min and Singh, Mitesh Kumar and Hassan, Mona and Goyal, Naman and Torabi, Narjes and Bashlykov, Nikolay and Bogoychev, Nikolay and Chatterji, Niladri and Zhang, Ning and Duchenne, Olivier and Çelebi, Onur and Alrassy, Patrick and Zhang, Pengchuan and Li, Pengwei and Vasic, Petar and Weng, Peter and Bhargava, Prajjwal and Dubal, Pratik and Krishnan, Praveen and Koura, Punit Singh and Xu, Puxin and He, Qing and Dong, Qingxiao and Srinivasan, Ragavan and Ganapathy, Raj and Calderer, Ramon and Cabral, Ricardo Silveira and Stojnic, Robert and Raileanu, Roberta and Maheswari, Rohan and Girdhar, Rohit and Patel, Rohit and Sauvestre, Romain and Polidoro, Ronnie and Sumbaly, Roshan and Taylor, Ross and Silva, Ruan and Hou, Rui and Wang, Rui and Hosseini, Saghar and Chennabasappa, Sahana and Singh, Sanjay and Bell, Sean and Kim, Seohyun Sonia and Edunov, Sergey and Nie, Shaoliang and Narang, Sharan and Raparthy, Sharath and Shen, Sheng and Wan, Shengye and Bhosale, Shruti and Zhang, Shun and Vandenhende, Simon and Batra, Soumya and Whitman, Spencer and Sootla, Sten and Collot, Stephane and Gururangan, Suchin and Borodinsky, Sydney and Herman, Tamar and Fowler, Tara and Sheasha, Tarek and Georgiou, Thomas and Scialom, Thomas and Speckbacher, Tobias and Mihaylov, Todor and Xiao, Tong and Karn, Ujjwal and Goswami, Vedanuj and Gupta, Vibhor and Ramanathan, Vignesh and Kerkez, Viktor and Gonguet, Vincent and Do, Virginie and Vogeti, Vish and Albiero, Vítor and Petrovic, Vladan and Chu, Weiwei and Xiong, Wenhan and Fu, Wenyin and Meers, Whitney and Martinet, Xavier and Wang, Xiaodong and Wang, Xiaofang and Tan, Xiaoqing Ellen and Xia, Xide and Xie, Xinfeng and Jia, Xuchao and Wang, Xuewei and Goldschlag, Yaelle and Gaur, Yashesh and Babaei, Yasmine and Wen, Yi and Song, Yiwen and Zhang, Yuchen and Li, Yue and Mao, Yuning and Coudert, Zacharie Delpierre and Yan, Zheng and Chen, Zhengxing and Papakipos, Zoe and Singh, Aaditya and Srivastava, Aayushi and Jain, Abha and Kelsey, Adam and Shajnfeld, Adam and Gangidi, Adithya and Victoria, Adolfo and Goldstand, Ahuva and Menon, Ajay and Sharma, Ajay and Boesenberg, Alex and Baevski, Alexei and Feinstein, Allie and Kallet, Amanda and Sangani, Amit and Teo, Amos and Yunus, Anam and Lupu, Andrei and Alvarado, Andres and Caples, Andrew and Gu, Andrew and Ho, Andrew and Poulton, Andrew and Ryan, Andrew and Ramchandani, Ankit and Dong, Annie and Franco, Annie and Goyal, Anuj and Saraf, Aparajita and Chowdhury, Arkabandhu and Gabriel, Ashley and Bharambe, Ashwin and Eisenman, Assaf and Yazdan, Azadeh and James, Beau and Maurer, Ben and Leonhardi, Benjamin and Huang, Bernie and Loyd, Beth and Paola, Beto De and Paranjape, Bhargavi and Liu, Bing and Wu, Bo and Ni, Boyu and Hancock, Braden and Wasti, Bram and Spence, Brandon and Stojkovic, Brani and Gamido, Brian and Montalvo, Britt and Parker, Carl and Burton, Carly and Mejia, Catalina and Liu, Ce and Wang, Changhan and Kim, Changkyu and Zhou, Chao and Hu, Chester and Chu, Ching-Hsiang and Cai, Chris and Tindal, Chris and Feichtenhofer, Christoph and Gao, Cynthia and Civin, Damon and Beaty, Dana and Kreymer, Daniel and Li, Daniel and Adkins, David and Xu, David and Testuggine, Davide and David, Delia and Parikh, Devi and Liskovich, Diana and Foss, Didem and Wang, Dingkang and Le, Duc and Holland, Dustin and Dowling, Edward and Jamil, Eissa and Montgomery, Elaine and Presani, Eleonora and Hahn, Emily and Wood, Emily and Le, Eric-Tuan and Brinkman, Erik and Arcaute, Esteban and Dunbar, Evan and Smothers, Evan and Sun, Fei and Kreuk, Felix and Tian, Feng and Kokkinos, Filippos and Ozgenel, Firat and Caggioni, Francesco and Kanayet, Frank and Seide, Frank and Florez, Gabriela Medina and Schwarz, Gabriella and Badeer, Gada and Swee, Georgia and Halpern, Gil and Herman, Grant and Sizov, Grigory and Guangyi and Zhang and Lakshminarayanan, Guna and Inan, Hakan and Shojanazeri, Hamid and Zou, Han and Wang, Hannah and Zha, Hanwen and Habeeb, Haroun and Rudolph, Harrison and Suk, Helen and Aspegren, Henry and Goldman, Hunter and Zhan, Hongyuan and Damlaj, Ibrahim and Molybog, Igor and Tufanov, Igor and Leontiadis, Ilias and Veliche, Irina-Elena and Gat, Itai and Weissman, Jake and Geboski, James and Kohli, James and Lam, Janice and Asher, Japhet and Gaya, Jean-Baptiste and Marcus, Jeff and Tang, Jeff and Chan, Jennifer and Zhen, Jenny and Reizenstein, Jeremy and Teboul, Jeremy and Zhong, Jessica and Jin, Jian and Yang, Jingyi and Cummings, Joe and Carvill, Jon and Shepard, Jon and McPhie, Jonathan and Torres, Jonathan and Ginsburg, Josh and Wang, Junjie and Wu, Kai and U, Kam Hou and Saxena, Karan and Khandelwal, Kartikay and Zand, Katayoun and Matosich, Kathy and Veeraraghavan, Kaushik and Michelena, Kelly and Li, Keqian and Jagadeesh, Kiran and Huang, Kun and Chawla, Kunal and Huang, Kyle and Chen, Lailin and Garg, Lakshya and A, Lavender and Silva, Leandro and Bell, Lee and Zhang, Lei and Guo, Liangpeng and Yu, Licheng and Moshkovich, Liron and Wehrstedt, Luca and Khabsa, Madian and Avalani, Manav and Bhatt, Manish and Mankus, Martynas and Hasson, Matan and Lennie, Matthew and Reso, Matthias and Groshev, Maxim and Naumov, Maxim and Lathi, Maya and Keneally, Meghan and Liu, Miao and Seltzer, Michael L. and Valko, Michal and Restrepo, Michelle and Patel, Mihir and Vyatskov, Mik and Samvelyan, Mikayel and Clark, Mike and Macey, Mike and Wang, Mike and Hermoso, Miquel Jubert and Metanat, Mo and Rastegari, Mohammad and Bansal, Munish and Santhanam, Nandhini and Parks, Natascha and White, Natasha and Bawa, Navyata and Singhal, Nayan and Egebo, Nick and Usunier, Nicolas and Mehta, Nikhil and Laptev, Nikolay Pavlovich and Dong, Ning and Cheng, Norman and Chernoguz, Oleg and Hart, Olivia and Salpekar, Omkar and Kalinli, Ozlem and Kent, Parkin and Parekh, Parth and Saab, Paul and Balaji, Pavan and Rittner, Pedro and Bontrager, Philip and Roux, Pierre and Dollar, Piotr and Zvyagina, Polina and Ratanchandani, Prashant and Yuvraj, Pritish and Liang, Qian and Alao, Rachad and Rodriguez, Rachel and Ayub, Rafi and Murthy, Raghotham and Nayani, Raghu and Mitra, Rahul and Parthasarathy, Rangaprabhu and Li, Raymond and Hogan, Rebekkah and Battey, Robin and Wang, Rocky and Howes, Russ and Rinott, Ruty and Mehta, Sachin and Siby, Sachin and Bondu, Sai Jayesh and Datta, Samyak and Chugh, Sara and Hunt, Sara and Dhillon, Sargun and Sidorov, Sasha and Pan, Satadru and Mahajan, Saurabh and Verma, Saurabh and Yamamoto, Seiji and Ramaswamy, Sharadh and Lindsay, Shaun and Lindsay, Shaun and Feng, Sheng and Lin, Shenghao and Zha, Shengxin Cindy and Patil, Shishir and Shankar, Shiva and Zhang, Shuqiang and Zhang, Shuqiang and Wang, Sinong and Agarwal, Sneha and Sajuyigbe, Soji and Chintala, Soumith and Max, Stephanie and Chen, Stephen and Kehoe, Steve and Satterfield, Steve and Govindaprasad, Sudarshan and Gupta, Sumit and Deng, Summer and Cho, Sungmin and Virk, Sunny and Subramanian, Suraj and Choudhury, Sy and Goldman, Sydney and Remez, Tal and Glaser, Tamar and Best, Tamara and Koehler, Thilo and Robinson, Thomas and Li, Tianhe and Zhang, Tianjun and Matthews, Tim and Chou, Timothy and Shaked, Tzook and Vontimitta, Varun and Ajayi, Victoria and Montanez, Victoria and Mohan, Vijai and Kumar, Vinay Satish and Mangla, Vishal and Ionescu, Vlad and Poenaru, Vlad and Mihailescu, Vlad Tiberiu and Ivanov, Vladimir and Li, Wei and Wang, Wenchen and Jiang, Wenwen and Bouaziz, Wes and Constable, Will and Tang, Xiaocheng and Wu, Xiaojian and Wang, Xiaolan and Wu, Xilun and Gao, Xinbo and Kleinman, Yaniv and Chen, Yanjun and Hu, Ye and Jia, Ye and Qi, Ye and Li, Yenda and Zhang, Yilin and Zhang, Ying and Adi, Yossi and Nam, Youngjin and Yu and Wang and Zhao, Yu and Hao, Yuchen and Qian, Yundi and Li, Yunlu and He, Yuzi and Rait, Zach and DeVito, Zachary and Rosnbrick, Zef and Wen, Zhaoduo and Yang, Zhenyu and Zhao, Zhiwei and Ma, Zhiyu},
  date = {2024-11-23},
  eprint = {2407.21783},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.21783},
  url = {http://arxiv.org/abs/2407.21783},
  abstract = {Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/kchou/HDD/Library/References/Grattafiori et al. - 2024 - The Llama 3 Herd of Models - grattafiori2024.pdf;/home/kchou/HDD/Library/References/2407.html}
}

@inproceedings{green2022,
  title = {{{GraphFuzz}}: Library {{API}} Fuzzing with Lifetime-Aware Dataflow Graphs},
  shorttitle = {{{GraphFuzz}}},
  booktitle = {Proceedings of the 44th {{International Conference}} on {{Software Engineering}}},
  author = {Green, Harrison and Avgerinos, Thanassis},
  date = {2022-05-21},
  pages = {1070--1081},
  publisher = {ACM},
  location = {Pittsburgh Pennsylvania},
  doi = {10.1145/3510003.3510228},
  url = {https://dl.acm.org/doi/10.1145/3510003.3510228},
  eventtitle = {{{ICSE}} '22: 44th {{International Conference}} on {{Software Engineering}}},
  keywords = {with-notes},
  annotation = {Read\_Status: Not Reading\\
Read\_Status\_Date: 2025-07-09T15:09:25.747Z},
  file = {/home/kchou/HDD/Library/References/Green and Avgerinos - 2022 - GraphFuzz library API fuzzing with lifetime-aware dataflow graphs - green2022.pdf}
}

@online{grov2024,
  title = {On the Use of Neurosymbolic {{AI}} for Defending against Cyber Attacks},
  author = {Grov, Gudmund and Halvorsen, Jonas and Eckhoff, Magnus Wiik and Hansen, Bjørn Jervell and Eian, Martin and Mavroeidis, Vasileios},
  date = {2024-08-09},
  eprint = {2408.04996},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2408.04996},
  url = {http://arxiv.org/abs/2408.04996},
  abstract = {It is generally accepted that all cyber attacks cannot be prevented, creating a need for the ability to detect and respond to cyber attacks. Both connectionist and symbolic AI are currently being used to support such detection and response. In this paper, we make the case for combining them using neurosymbolic AI. We identify a set of challenges when using AI today and propose a set of neurosymbolic use cases we believe are both interesting research directions for the neurosymbolic AI community and can have an impact on the cyber security field. We demonstrate feasibility through two proof-of-concept experiments.},
  pubstate = {prepublished},
  file = {/home/kchou/HDD/Library/References/Grov et al. - 2024 - On the use of neurosymbolic AI for defending against cyber attacks - @grovUseNeurosymbolicAI2024.pdf;/home/kchou/HDD/Library/References/2408 2.html}
}

@software{he2025,
  title = {Sighingnow/Libclang},
  author = {He, Tao},
  date = {2025-07-03T09:54:44Z},
  origdate = {2020-08-06T11:43:56Z},
  url = {https://github.com/sighingnow/libclang},
  abstract = {(Unofficial) Release libclang (clang.cindex) on pypi.}
}

@online{heartbleed,
  title = {Heartbleed {{Bug}}},
  author = {{Blackduck, Inc.}},
  date = {2025-03-07},
  url = {https://heartbleed.com/},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-04T14:28:15.555Z},
  file = {/home/kchou/HDD/Library/References/heartbleed.com.html}
}

@online{heartbleed-cve,
  title = {{{CVE}} - {{CVE-2014-0160}}},
  author = {{CVE Program}},
  date = {2014},
  url = {https://cve.mitre.org/cgi-bin/cvename.cgi?name=cve-2014-0160},
  file = {/home/kchou/HDD/Library/References/cvename.html}
}

@inproceedings{herrera2021,
  title = {Seed Selection for Successful Fuzzing},
  booktitle = {Proceedings of the 30th {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}}},
  author = {Herrera, Adrian and Gunadi, Hendra and Magrath, Shane and Norrish, Michael and Payer, Mathias and Hosking, Antony L.},
  date = {2021-07-11},
  pages = {230--243},
  publisher = {ACM},
  location = {Virtual Denmark},
  doi = {10.1145/3460319.3464795},
  url = {https://dl.acm.org/doi/10.1145/3460319.3464795},
  abstract = {Mutation-based greybox fuzzingÐunquestionably the most widelyused fuzzing techniqueÐrelies on a set of non-crashing seed inputs (a corpus) to bootstrap the bug-finding process. When evaluating a fuzzer, common approaches for constructing this corpus include: (i) using an empty file; (ii) using a single seed representative of the target’s input format; or (iii) collecting a large number of seeds (e.g., by crawling the Internet). Little thought is given to how this seed choice affects the fuzzing process, and there is no consensus on which approach is best (or even if a best approach exists).},
  eventtitle = {{{ISSTA}} '21: 30th {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}}},
  isbn = {978-1-4503-8459-9},
  langid = {english},
  file = {/home/kchou/HDD/Library/References/Herrera et al. - 2021 - Seed selection for successful fuzzing - @herreraSeedSelectionSuccessful2021.pdf}
}

@software{honggfuzz,
  title = {Google/Honggfuzz},
  author = {{Google}},
  date = {2025-07-10T08:01:50Z},
  origdate = {2015-05-07T15:43:01Z},
  url = {https://github.com/google/honggfuzz},
  abstract = {Security oriented software fuzzer. Supports evolutionary, feedback-driven fuzzing based on code coverage (SW and HW based)},
  organization = {Google},
  keywords = {c,fuzzing,security}
}

@online{huang2024,
  title = {Large Language Models Based Fuzzing Techniques: A Survey},
  shorttitle = {Large Language Models Based Fuzzing Techniques},
  author = {Huang, Linghan and Zhao, Peizhou and Chen, Huaming and Ma, Lei},
  date = {2024},
  url = {https://arxiv.org/abs/2402.00350},
  pubstate = {prepublished},
  annotation = {Read\_Status: In Progress\\
Read\_Status\_Date: 2025-02-24T20:29:10.448Z},
  file = {/home/kchou/HDD/Library/References/Huang et al. - 2024 - Large language models based fuzzing techniques a survey - @huangLargeLanguageModels2024.pdf}
}

@online{iris,
  title = {{{IRIS}}: {{LLM-Assisted Static Analysis}} for {{Detecting Security Vulnerabilities}}},
  shorttitle = {{{IRIS}}},
  author = {Li, Ziyang and Dutta, Saikat and Naik, Mayur},
  date = {2025-04-06},
  eprint = {2405.17238},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.17238},
  url = {http://arxiv.org/abs/2405.17238},
  abstract = {Software is prone to security vulnerabilities. Program analysis tools to detect them have limited effectiveness in practice due to their reliance on human labeled specifications. Large language models (or LLMs) have shown impressive code generation capabilities but they cannot do complex reasoning over code to detect such vulnerabilities especially since this task requires whole-repository analysis. We propose IRIS, a neuro-symbolic approach that systematically combines LLMs with static analysis to perform whole-repository reasoning for security vulnerability detection. Specifically, IRIS leverages LLMs to infer taint specifications and perform contextual analysis, alleviating needs for human specifications and inspection. For evaluation, we curate a new dataset, CWE-Bench-Java, comprising 120 manually validated security vulnerabilities in real-world Java projects. A state-of-the-art static analysis tool CodeQL detects only 27 of these vulnerabilities whereas IRIS with GPT-4 detects 55 (+28) and improves upon CodeQL's average false discovery rate by 5\% points. Furthermore, IRIS identifies 4 previously unknown vulnerabilities which cannot be found by existing tools. IRIS is available publicly at https://github.com/iris-sast/iris.},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Programming Languages,Computer Science - Software Engineering,llm fuzzing,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T16:36:31.431Z},
  file = {/home/kchou/HDD/Library/References/Li et al. - 2025 - IRIS LLM-Assisted Static Analysis for Detecting Security Vulnerabilities - @liIRISLLMAssistedStatic2025.pdf;/home/kchou/HDD/Library/References/2405 2.html}
}

@online{jensen2024,
  title = {Software {{Vulnerability}} and {{Functionality Assessment}} Using {{LLMs}}},
  author = {Jensen, Rasmus Ingemann Tuffveson and Tawosi, Vali and Alamir, Salwa},
  date = {2024-03-13},
  eprint = {2403.08429},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2403.08429},
  url = {http://arxiv.org/abs/2403.08429},
  abstract = {While code review is central to the software development process, it can be tedious and expensive to carry out. In this paper, we investigate whether and how Large Language Models (LLMs) can aid with code reviews. Our investigation focuses on two tasks that we argue are fundamental to good reviews: (i) flagging code with security vulnerabilities and (ii) performing software functionality validation, i.e., ensuring that code meets its intended functionality. To test performance on both tasks, we use zero-shot and chain-of-thought prompting to obtain final ``approve or reject'' recommendations. As data, we employ seminal code generation datasets (HumanEval and MBPP) along with expert-written code snippets with security vulnerabilities from the Common Weakness Enumeration (CWE). Our experiments consider a mixture of three proprietary models from OpenAI and smaller open-source LLMs. We find that the former outperforms the latter by a large margin. Motivated by promising results, we finally ask our models to provide detailed descriptions of security vulnerabilities. Results show that 36.7\% of LLM-generated descriptions can be associated with true CWE vulnerabilities.},
  pubstate = {prepublished},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-04T15:42:14.215Z},
  file = {/home/kchou/HDD/Library/References/Jensen et al. - 2024 - Software Vulnerability and Functionality Assessment using LLMs - @jensenSoftwareVulnerabilityFunctionality2024.pdf;/home/kchou/HDD/Library/References/Jensen et al. - 2024 - Software Vulnerability and Functionality Assessmen.html}
}

@unpublished{kautz2020,
  type = {Lecture},
  title = {The {{Third AI Summer}}},
  author = {Kautz, Henry},
  date = {2020-02-10},
  url = {https://www.youtube.com/watch?v=_cQITY0SPiw},
  abstract = {Talk presented Henry Kautz, winner of the Robert S. Engelmore Memorial Lecture Award, at the 34th Annual Meeting of the Association for the Advancement of Artificial Intelligence (AAAI-2020) in New York, NY on February 10, 2020.  Dr. Kautz received the award for for "outstanding research contributions in the area of knowledge representation, data analytics, and data mining of social media for public good."},
  eventtitle = {34th {{Annual Meeting}} of the {{Association}} for the {{Advancement}} of {{Artificial Intelligence}}},
  langid = {english},
  venue = {New York, NY, USA}
}

@online{kim2024,
  title = {Codexity: {{Secure AI-assisted Code Generation}}},
  shorttitle = {Codexity},
  author = {Kim, Sung Yong and Fan, Zhiyu and Noller, Yannic and Roychoudhury, Abhik},
  date = {2024-05-07},
  eprint = {2405.03927},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2405.03927},
  url = {http://arxiv.org/abs/2405.03927},
  abstract = {Despite the impressive performance of Large Language Models (LLMs) in software development activities, recent studies show the concern of introducing vulnerabilities into software codebase by AI programming assistants (e.g., Copilot, CodeWhisperer). In this work, we present Codexity, a security-focused code generation framework integrated with five LLMs. Codexity leverages the feedback of static analysis tools such as Infer and CppCheck to mitigate security vulnerabilities in LLM-generated programs. Our evaluation in a real-world benchmark with 751 automatically generated vulnerable subjects demonstrates Codexity can prevent 60\% of the vulnerabilities being exposed to the software developer.},
  pubstate = {prepublished},
  version = {1},
  file = {/home/kchou/HDD/Library/References/Kim et al. - 2024 - Codexity Secure AI-assisted Code Generation - @kimCodexitySecureAIassisted2024.pdf;/home/kchou/HDD/Library/References/2405 1.html}
}

@inproceedings{kim2025,
  title = {Performance {{Comparison}} of {{Prompt Engineering}} and {{Fine-Tuning Approaches}} for {{Fuzz Driver Generation Using Large Language Models}}},
  booktitle = {Innovative {{Mobile}} and {{Internet Services}} in {{Ubiquitous Computing}}},
  author = {Kim, Sanggu and Lee, Sun-young},
  editor = {Barolli, Leonard and Chen, Hsing-Chung and Yim, Kangbin},
  date = {2025},
  pages = {111--120},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-96093-2_12},
  abstract = {Fuzz test is known as a dynamic testing method, which is reasonably effective at detecting security vulnerabilities and abnormal conditions by providing irregular inputs to the program and observing its response. The efficiency and application scope of fuzz test heavily depends on the quality of the fuzz driver that constructs appropriate inputs for the target function. However, it requires an enormous amount of time and professional knowledge to generate a high-quality fuzz driver. For that reason, numerous studies about automation of fuzz driver generation using LLM are being conducted recently. In this study, the performance difference between prompt engineering and fine-tuning is evaluated by the fuzz driver creation method using LLM. To do so, two types of data set were built based on prompt data used in OSS-Fuzz-gen and a fuzz driver source code collected from the project Introspector, and fine-tuning on GPT-3.5 Turbo Model was conducted. Performance evaluation was carried out based on line, function, and region coverage, as well as the success of target function invocations. As a result of this evaluation, the fine-tuning based model demonstrated overall superior performance compared to prompt-based model.},
  isbn = {978-3-031-96093-2},
  langid = {english},
  keywords = {with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-11T16:06:15.109Z},
  file = {/home/kchou/HDD/Library/References/Kim and Lee - 2025 - Performance Comparison of Prompt Engineering and Fine-Tuning Approaches for Fuzz Driver Generation U - kim2025.pdf}
}

@inproceedings{klee,
  title = {{{KLEE}}: {{Unassisted}} and {{Automatic Generation}} of {{High-Coverage Tests}} for {{Complex Systems Programs}}},
  shorttitle = {{{KLEE}}},
  author = {Cadar, Cristian and Dunbar, Daniel and Engler, D.},
  date = {2008-12-08},
  url = {https://www.semanticscholar.org/paper/KLEE%3A-Unassisted-and-Automatic-Generation-of-Tests-Cadar-Dunbar/0b93657965e506dfbd56fbc1c1d4b9666b1d01c8},
  abstract = {We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage -- on average over 90\% per tool (median: over 94\%) -- and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100\% coverage on 31 of them.    We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.},
  eventtitle = {{{USENIX Symposium}} on {{Operating Systems Design}} and {{Implementation}}},
  keywords = {suggested,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T10:41:06.670Z},
  file = {/home/kchou/HDD/Library/References/Cadar et al. - 2008 - KLEE Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs - @cadarKLEEUnassistedAutomatic2008.pdf}
}

@online{laban2025,
  title = {{{LLMs Get Lost In Multi-Turn Conversation}}},
  author = {Laban, Philippe and Hayashi, Hiroaki and Zhou, Yingbo and Neville, Jennifer},
  date = {2025-05-09},
  eprint = {2505.06120},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2505.06120},
  url = {http://arxiv.org/abs/2505.06120},
  abstract = {Large Language Models (LLMs) are conversational interfaces. As such, LLMs have the potential to assist their users not only when they can fully specify the task at hand, but also to help them define, explore, and refine what they need through multi-turn conversational exchange. Although analysis of LLM conversation logs has confirmed that underspecification occurs frequently in user instructions, LLM evaluation has predominantly focused on the single-turn, fully-specified instruction setting. In this work, we perform large-scale simulation experiments to compare LLM performance in single- and multi-turn settings. Our experiments confirm that all the top open- and closed-weight LLMs we test exhibit significantly lower performance in multi-turn conversations than single-turn, with an average drop of 39\% across six generation tasks. Analysis of 200,000+ simulated conversations decomposes the performance degradation into two components: a minor loss in aptitude and a significant increase in unreliability. We find that LLMs often make assumptions in early turns and prematurely attempt to generate final solutions, on which they overly rely. In simpler terms, we discover that *when LLMs take a wrong turn in a conversation, they get lost and do not recover*.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Human-Computer Interaction,suggested,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-16T16:26:54.456Z},
  file = {/home/kchou/HDD/Library/References/Laban et al. - 2025 - LLMs Get Lost In Multi-Turn Conversation - laban2025.pdf;/home/kchou/HDD/Library/References/2505.html}
}

@software{langchain,
  title = {{{LangChain}}},
  author = {Chase, Harrison},
  date = {2022-10},
  url = {https://github.com/langchain-ai/langchain}
}

@software{langgraph,
  title = {Langchain-Ai/Langgraph},
  author = {{Langchain Project}},
  date = {2025-05-21T17:09:48Z},
  origdate = {2023-08-09T18:33:12Z},
  url = {https://github.com/langchain-ai/langgraph},
  abstract = {Build resilient language agents as graphs.},
  organization = {LangChain}
}

@inproceedings{lazar2014,
  title = {Why Does Cryptographic Software Fail? A Case Study and Open Problems},
  shorttitle = {Why Does Cryptographic Software Fail?},
  booktitle = {Proceedings of 5th {{Asia-Pacific Workshop}} on {{Systems}}},
  author = {Lazar, David and Chen, Haogang and Wang, Xi and Zeldovich, Nickolai},
  date = {2014-06-25},
  series = {{{APSys}} '14},
  pages = {1--7},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/2637166.2637237},
  url = {https://doi.org/10.1145/2637166.2637237},
  abstract = {Mistakes in cryptographic software implementations often undermine the strong security guarantees offered by cryptography. This paper presents a systematic study of cryptographic vulnerabilities in practice, an examination of state-of-the-art techniques to prevent such vulnerabilities, and a discussion of open problems and possible future research directions. Our study covers 269 cryptographic vulnerabilities reported in the CVE database from January 2011 to May 2014. The results show that just 17\% of the bugs are in cryptographic libraries (which often have devastating consequences), and the remaining 83\% are misuses of cryptographic libraries by individual applications. We observe that preventing bugs in different parts of a system requires different techniques, and that no effective techniques exist to deal with certain classes of mistakes, such as weak key generation.},
  isbn = {978-1-4503-3024-4},
  keywords = {suggested},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-10-12T16:34:56.082Z},
  file = {/home/kchou/HDD/Library/References/Lazar et al. - 2014 - Why does cryptographic software fail a case study and open problems - @lazarWhyDoesCryptographic2014.pdf}
}

@article{lee2025,
  title = {The {{Impact}} of {{Generative AI}} on {{Critical Thinking}}: {{Self-Reported Reductions}} in {{Cognitive Effort}} and {{Confidence Effects From}} a {{Survey}} of {{Knowledge Workers}}},
  shorttitle = {The {{Impact}} of {{Generative AI}} on {{Critical Thinking}}},
  author = {Lee, Hao-Ping Hank and Sarkar, Advait and Tankelevitch, Lev and Drosos, Ian and Rintel, Sean and Banks, Richard and Wilson, Nicholas},
  date = {2025},
  url = {https://hankhplee.com/papers/genai_critical_thinking.pdf},
  keywords = {cognition,LLM,project/thesis,study},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2025-04-07T08:11:49.006Z},
  file = {/home/kchou/HDD/Library/References/Lee et al. - 2025 - The Impact of Generative AI on Critical Thinking Self-Reported Reductions in Cognitive Effort and C - @leeImpactGenerativeAI2025.pdf}
}

@article{legoues2013Repair,
  title = {Current Challenges in Automatic Software Repair},
  author = {Le Goues, Claire and Forrest, Stephanie and Weimer, Westley},
  date = {2013-09},
  journaltitle = {Software Quality Journal},
  shortjournal = {Software Qual J},
  volume = {21},
  number = {3},
  pages = {421--443},
  issn = {0963-9314, 1573-1367},
  doi = {10.1007/s11219-013-9208-0},
  url = {http://link.springer.com/10.1007/s11219-013-9208-0},
  langid = {english},
  keywords = {localization},
  file = {/home/kchou/HDD/Library/References/Le Goues et al. - 2013 - Current challenges in automatic software repair - @.pdf}
}

@online{lewis2021,
  title = {Retrieval-{{Augmented Generation}} for {{Knowledge-Intensive NLP Tasks}}},
  author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and Riedel, Sebastian and Kiela, Douwe},
  date = {2021-04-12},
  eprint = {2005.11401},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.11401},
  url = {http://arxiv.org/abs/2005.11401},
  abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/kchou/HDD/Library/References/Lewis et al. - 2021 - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks - lewis2021.pdf;/home/kchou/HDD/Library/References/2005 1.html}
}

@article{li2022,
  title = {Language Models: Past, Present, and Future},
  shorttitle = {Language Models},
  author = {Li, Hang},
  date = {2022-06-21},
  journaltitle = {Commun. ACM},
  volume = {65},
  number = {7},
  pages = {56--63},
  issn = {0001-0782},
  doi = {10.1145/3490443},
  url = {https://dl.acm.org/doi/10.1145/3490443},
  abstract = {A language modeling overview, highlighting basic concepts, intuitive explanations, technical achievements, and fundamental challenges.},
  file = {/home/kchou/HDD/Library/References/Li - 2022 - Language models past, present, and future - @liLanguageModelsPresent2022.pdf}
}

@online{libfuzzer,
  title = {{{libFuzzer}} – a Library for Coverage-Guided Fuzz Testing. — {{LLVM}} 21.0.0git Documentation},
  author = {{LLVM Project}},
  date = {2025},
  url = {https://llvm.org/docs/LibFuzzer.html},
  keywords = {project/thesis},
  file = {/home/kchou/HDD/Library/References/LibFuzzer.html}
}

@article{licklider1960,
  title = {Man-{{Computer Symbiosis}}},
  author = {Licklider, J. C. R.},
  date = {1960-03},
  journaltitle = {IRE Transactions on Human Factors in Electronics},
  volume = {HFE-1},
  number = {1},
  pages = {4--11},
  issn = {2168-2836},
  doi = {10.1109/THFE2.1960.4503259},
  url = {https://ieeexplore.ieee.org/document/4503259},
  abstract = {Man-computer symbiosis is an expected development in cooperative interaction between men and electronic computers. It will involve very close coupling between the human and the electronic members of the partnership. The main aims are 1) to let computers facilitate formulative thinking as they now facilitate the solution of formulated problems, and 2) to enable men and computers to cooperate in making decisions and controlling complex situations without inflexible dependence on predetermined programs. In the anticipated symbiotic partnership, men will set the goals, formulate the hypotheses, determine the criteria, and perform the evaluations. Computing machines will do the routinizable work that must be done to prepare the way for insights and decisions in technical and scientific thinking. Preliminary analyses indicate that the symbiotic partnership will perform intellectual operations much more effectively than man alone can perform them. Prerequisites for the achievement of the effective, cooperative association include developments in computer time sharing, in memory components, in memory organization, in programming languages, and in input and output equipment.},
  eventtitle = {{{IRE Transactions}} on {{Human Factors}} in {{Electronics}}},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2025-04-02T08:50:08.357Z},
  file = {/home/kchou/HDD/Library/References/Licklider - 1960 - Man-Computer Symbiosis - @lickliderManComputerSymbiosis1960.pdf;/home/kchou/HDD/Library/References/4503259.html}
}

@online{liu2023,
  type = {Blog},
  title = {{{AI-Powered Fuzzing}}: {{Breaking}} the {{Bug Hunting Barrier}}},
  shorttitle = {{{AI-Powered Fuzzing}}},
  author = {Liu, Dongge and Metzman, Jonathan and Chang, Oliver and Team, Google Open Source Security},
  date = {2023-08-16},
  url = {https://security.googleblog.com/2023/08/ai-powered-fuzzing-breaking-bug-hunting.html},
  abstract = {Dongge Liu, Jonathan Metzman, Oliver Chang, Google Open Source Security Team~ Since 2016, OSS-Fuzz  has been at the forefront of automated v...},
  langid = {english},
  organization = {Google Online Security Blog},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-11T10:02:21.362Z},
  file = {/home/kchou/HDD/Library/References/ai-powered-fuzzing-breaking-bug-hunting 1.html}
}

@online{liu2025,
  title = {Can {{LLM Generate Regression Tests}} for {{Software Commits}}?},
  author = {Liu, Jing and Lee, Seongmin and Losiouk, Eleonora and Böhme, Marcel},
  date = {2025-01-19},
  eprint = {2501.11086},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.11086},
  url = {http://arxiv.org/abs/2501.11086},
  abstract = {Large Language Models (LLMs) have shown tremendous promise in automated software engineering. In this paper, we investigate the opportunities of LLMs for automatic regression test generation for programs that take highly structured, human-readable inputs, such as XML parsers or JavaScript interpreters. Concretely, we explore the following regression test generation scenarios for such programs that have so far been difficult to test automatically in the absence of corresponding input grammars: \$\textbackslash bullet\$ Bug finding. Given a code change (e.g., a commit or pull request), our LLM-based approach generates a test case with the objective of revealing any bugs that might be introduced if that change is applied. \$\textbackslash bullet\$ Patch testing. Given a patch, our LLM-based approach generates a test case that fails before but passes after the patch. This test can be added to the regression test suite to catch similar bugs in the future. We implement Cleverest, a feedback-directed, zero-shot LLM-based regression test generation technique, and evaluate its effectiveness on 22 commits to three subject programs: Mujs, Libxml2, and Poppler. For programs using more human-readable file formats, like XML or JavaScript, we found Cleverest performed very well. It generated easy-to-understand bug-revealing or bug-reproduction test cases for the majority of commits in just under three minutes -- even when only the code diff or commit message (unless it was too vague) was given. For programs with more compact file formats, like PDF, as expected, it struggled to generate effective test cases. However, the LLM-supplied test cases are not very far from becoming effective (e.g., when used as a seed by a greybox fuzzer or as a starting point by the developer).},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering,llm fuzzing},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2025-05-05T11:45:47.763Z},
  file = {/home/kchou/HDD/Library/References/Liu et al. - 2025 - Can LLM Generate Regression Tests for Software Commits - @liuCanLLMGenerate2025.pdf;/home/kchou/HDD/Library/References/2501 3.html}
}

@software{llamaindex,
  title = {{{LlamaIndex}}},
  author = {Liu, Jerry},
  date = {2022-11},
  doi = {10.5281/zenodo.1234},
  url = {https://github.com/jerryjliu/llama_index},
  abstract = {LlamaIndex is the leading framework for building LLM-powered agents over your data.}
}

@online{llvm,
  title = {The {{LLVM Compiler Infrastructure Project}}},
  author = {{LLVM Project}},
  date = {2025},
  url = {https://llvm.org/},
  file = {/home/kchou/HDD/Library/References/llvm.org.html}
}

@online{lyu2024,
  title = {Prompt {{Fuzzing}} for {{Fuzz Driver Generation}}},
  author = {Lyu, Yunlong and Xie, Yuxuan and Chen, Peng and Chen, Hao},
  date = {2024-05-29},
  eprint = {2312.17677},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.17677},
  url = {http://arxiv.org/abs/2312.17677},
  abstract = {Crafting high-quality fuzz drivers not only is time-consuming but also requires a deep understanding of the library. However, the state-of-the-art automatic fuzz driver generation techniques fall short of expectations. While fuzz drivers derived from consumer code can reach deep states, they have limited coverage. Conversely, interpretative fuzzing can explore most API calls but requires numerous attempts within a large search space. We propose PromptFuzz, a coverage-guided fuzzer for prompt fuzzing that iteratively generates fuzz drivers to explore undiscovered library code. To explore API usage in fuzz drivers during prompt fuzzing, we propose several key techniques: instructive program generation, erroneous program validation, coverage-guided prompt mutation, and constrained fuzzer scheduling. We implemented PromptFuzz and evaluated it on 14 real-world libraries. Compared with OSS-Fuzz and Hopper (the state-of-the-art fuzz driver generation tool), fuzz drivers generated by PromptFuzz achieved 1.61 and 1.63 times higher branch coverage than those by OSS-Fuzz and Hopper, respectively. Moreover, the fuzz drivers generated by PromptFuzz detected 33 genuine, new bugs out of a total of 49 crashes, out of which 30 bugs have been confirmed by their respective communities.},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Software Engineering,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-14T10:25:06.712Z},
  file = {/home/kchou/HDD/Library/References/Lyu et al. - 2024 - Prompt Fuzzing for Fuzz Driver Generation - lyuPromptFuzzingFuzz2024.pdf;/home/kchou/HDD/Library/References/2312 1 1.html}
}

@online{manes2019,
  title = {The {{Art}}, {{Science}}, and {{Engineering}} of {{Fuzzing}}: {{A Survey}}},
  shorttitle = {The {{Art}}, {{Science}}, and {{Engineering}} of {{Fuzzing}}},
  author = {Manes, Valentin J. M. and Han, HyungSeok and Han, Choongwoo and Cha, Sang Kil and Egele, Manuel and Schwartz, Edward J. and Woo, Maverick},
  date = {2019-04-07},
  eprint = {1812.00140},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1812.00140},
  url = {http://arxiv.org/abs/1812.00140},
  abstract = {Among the many software vulnerability discovery techniques available today, fuzzing has remained highly popular due to its conceptual simplicity, its low barrier to deployment, and its vast amount of empirical evidence in discovering real-world software vulnerabilities. At a high level, fuzzing refers to a process of repeatedly running a program with generated inputs that may be syntactically or semantically malformed. While researchers and practitioners alike have invested a large and diverse effort towards improving fuzzing in recent years, this surge of work has also made it difficult to gain a comprehensive and coherent view of fuzzing. To help preserve and bring coherence to the vast literature of fuzzing, this paper presents a unified, general-purpose model of fuzzing together with a taxonomy of the current fuzzing literature. We methodically explore the design decisions at every stage of our model fuzzer by surveying the related literature and innovations in the art, science, and engineering that make modern-day fuzzers effective.},
  pubstate = {prepublished},
  keywords = {suggested,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-14T21:03:20.585Z},
  file = {/home/kchou/HDD/Library/References/Manes et al. - 2019 - The Art, Science, and Engineering of Fuzzing A Survey - @manesArtScienceEngineering2019.pdf;/home/kchou/HDD/Library/References/1812.html}
}

@software{martin2025,
  title = {Ninja-Build/Ninja},
  author = {Martin, Evan},
  date = {2025-07-14T08:19:17Z},
  origdate = {2011-02-06T19:07:12Z},
  url = {https://github.com/ninja-build/ninja},
  abstract = {a small build system with a focus on speed},
  organization = {ninja-build}
}

@online{meyer2013,
  title = {Lessons {{Learned From Previous SSL}}/{{TLS Attacks}} - {{A Brief Chronology Of Attacks And Weaknesses}}},
  author = {Meyer, Christopher and Schwenk, Jörg},
  date = {2013},
  number = {2013/049},
  url = {https://eprint.iacr.org/2013/049},
  abstract = {Since its introduction in 1994 the Secure Socket Layer (SSL) protocol (later renamed to Transport Layer Security (TLS)) evolved to the de facto standard for securing the transport layer. SSL/TLS can be used for ensuring data confidentiality, integrity and authenticity during transport. A main feature of the protocol is its flexibility. Modes of operation and security aims can easily be configured through different cipher suites. During its evolutionary development process several flaws were found. However, the flexible architecture of SSL/TLS allowed efficient fixes in order to counter the issues. This paper presents an overview on theoretical and practical attacks of the last 15 years, in chronological order and four categories: Attacks on the TLS Handshake protocol, on the TLS Record and Application Data Protocols, on the PKI infrastructure of TLS, and on various other attacks. We try to give a short ”Lessons Learned” at the end of each paragraph.},
  pubstate = {prepublished},
  keywords = {suggested},
  annotation = {Publication info: Published elsewhere. SSL, TLS, Handshake Protocol, Record Layer, Public Key Infrastructures, Bleichenbacher Attack, Padding Oracles\\
Read\_Status: Read\\
Read\_Status\_Date: 2024-12-20T14:54:14.658Z},
  file = {/home/kchou/HDD/Library/References/Meyer and Schwenk - 2013 - Lessons Learned From Previous SSLTLS Attacks - A Brief Chronology Of Attacks And Weaknesses - @meyerLessonsLearnedPrevious2013.pdf}
}

@online{microsoft2024,
  title = {Magentic-{{One}}: {{A Generalist Multi-Agent System}} for {{Solving Complex Tasks}}},
  shorttitle = {Magentic-{{One}}},
  author = {{Microsoft}},
  date = {2024-11-04},
  url = {https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/},
  abstract = {By Adam Fourney, Principal Researcher; Gagan Bansal, Senior Researcher; Hussein Mozannar, Senior Researcher; Victor Dibia, Principal Research Software Engineer; Saleema Amershi, Partner Research Manager Contributors: Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang (Eric) Zhu, Friederike Niedtner, Grace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor […]},
  langid = {american},
  organization = {Microsoft Research},
  file = {/home/kchou/HDD/Library/References/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks.html}
}

@online{mikolov2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  date = {2013-09-06},
  eprint = {1301.3781},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1301.3781},
  url = {http://arxiv.org/abs/1301.3781},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  pubstate = {prepublished},
  file = {/home/kchou/HDD/Library/References/Mikolov et al_2013_Efficient Estimation of Word Representations in Vector Space.pdf;/home/kchou/HDD/Library/Zotero data/storage/UL4A6XIX/1301.html}
}

@article{miller1990,
  title = {An Empirical Study of the Reliability of {{UNIX}} Utilities},
  author = {Miller, Barton P. and Fredriksen, Lars and So, Bryan},
  date = {1990-12-01},
  journaltitle = {Commun. ACM},
  volume = {33},
  number = {12},
  pages = {32--44},
  issn = {0001-0782},
  doi = {10.1145/96267.96279},
  url = {https://dl.acm.org/doi/10.1145/96267.96279},
  abstract = {The following section describes the tools we built to test the utilities. These tools include the fuzz (random character) generator, ptyjig (to test interactive utilities), and scripts to automate the testing process. Next, we will describe the tests we performed, giving the types of input we presented to the utilities. Results from the tests will follow along with an analysis of the results, including identification and classification of the program bugs that caused the crashes. The final section presents concluding remarks, including suggestions for avoiding the types of problems detected by our study and some commentary on the bugs we found. We include an Appendix with the user manual pages for fuzz and ptyjig.},
  file = {/home/kchou/HDD/Library/References/Miller et al. - 1990 - An empirical study of the reliability of UNIX utilities - miller1990.pdf}
}

@article{nethercote2007,
  title = {Valgrind: A Framework for Heavyweight Dynamic Binary Instrumentation},
  shorttitle = {Valgrind},
  author = {Nethercote, Nicholas and Seward, Julian},
  date = {2007-06-10},
  journaltitle = {SIGPLAN Not.},
  volume = {42},
  number = {6},
  pages = {89--100},
  issn = {0362-1340},
  doi = {10.1145/1273442.1250746},
  url = {https://doi.org/10.1145/1273442.1250746},
  abstract = {Dynamic binary instrumentation (DBI) frameworks make it easy to build dynamic binary analysis (DBA) tools such as checkers and profilers. Much of the focus on DBI frameworks has been on performance; little attention has been paid to their capabilities. As a result, we believe the potential of DBI has not been fully exploited.In this paper we describe Valgrind, a DBI framework designed for building heavyweight DBA tools. We focus on its unique support for shadow values-a powerful but previously little-studied and difficult-to-implement DBA technique, which requires a tool to shadow every register and memory value with another value that describes it. This support accounts for several crucial design features that distinguish Valgrind from other DBI frameworks. Because of these features, lightweight tools built with Valgrind run comparatively slowly, but Valgrind can be used to build more interesting, heavyweight tools that are difficult or impossible to build with other DBI frameworks such as Pin and DynamoRIO.},
  keywords = {suggested},
  file = {/home/kchou/HDD/Library/References/Nethercote and Seward - 2007 - Valgrind a framework for heavyweight dynamic binary instrumentation - @nethercoteValgrindFrameworkHeavyweight2007.pdf}
}

@article{nijkamp2023,
  title = {{{CodeGen}}: {{An}} Open Large Language Model for Code with Multi-Turn Program Synthesis},
  author = {Nijkamp, Erik and Pang, Bo and Hayashi, Hiroaki and Tu, Lifu and Wang, Huan and Zhou, Yingbo and Savarese, Silvio and Xiong, Caiming},
  date = {2023},
  journaltitle = {ICLR},
  file = {/home/kchou/HDD/Library/References/Nijkamp et al. - 2023 - CodeGen An open large language model for code with multi-turn program synthesis - nijkamp2023.pdf}
}

@article{nijkamp2023a,
  title = {{{CodeGen2}}: {{Lessons}} for Training Llms on Programming and Natural Languages},
  author = {Nijkamp, Erik and Hayashi, Hiroaki and Xiong, Caiming and Savarese, Silvio and Zhou, Yingbo},
  date = {2023},
  journaltitle = {ICLR},
  file = {/home/kchou/HDD/Library/References/Nijkamp et al. - 2023 - CodeGen2 Lessons for training llms on programming and natural languages - nijkamp2023a.pdf}
}

@online{openai2024,
  title = {{{GPT-4 Technical Report}}},
  author = {OpenAI and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and Avila, Red and Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and Belgum, Jeff and Bello, Irwan and Berdine, Jake and Bernadett-Shapiro, Gabriel and Berner, Christopher and Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and Brundage, Miles and Button, Kevin and Cai, Trevor and Campbell, Rosie and Cann, Andrew and Carey, Brittany and Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and Chang, Che and Chantzis, Fotis and Chen, Derek and Chen, Sully and Chen, Ruby and Chen, Jason and Chen, Mark and Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and Deville, Damien and Dhar, Arka and Dohan, David and Dowling, Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty and Eloundou, Tyna and Farhi, David and Fedus, Liam and Felix, Niko and Fishman, Simón Posada and Forte, Juston and Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson, Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel and Gontijo-Lopes, Rapha and Gordon, Jonathan and Grafstein, Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han, Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and Heidecke, Johannes and Hesse, Chris and Hickey, Alan and Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost and Jain, Shantanu and Jain, Shawn and Jang, Joanne and Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin, Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and Kaftan, Tomer and Kaiser, Łukasz and Kamali, Ali and Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan, Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim, Christina and Kim, Yongjik and Kirchner, Jan Hendrik and Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and Kondraciuk, Łukasz and Kondrich, Andrew and Konstantinidis, Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike, Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin, Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia and Makanju, Anna and Malfacini, Kim and Manning, Sam and Markov, Todor and Markovski, Yaniv and Martin, Bianca and Mayer, Katie and Mayne, Andrew and McGrew, Bob and McKinney, Scott Mayer and McLeavey, Christine and McMillan, Paul and McNeil, Jake and Medina, David and Mehta, Aalok and Menick, Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin, Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing, Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and Mély, David and Nair, Ashvin and Nakano, Reiichiro and Nayak, Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh, Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki, Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley and Parascandolo, Giambattista and Parish, Joel and Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng, Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and Michael and Pokorny and Pokrass, Michelle and Pong, Vitchyr H. and Powell, Tolly and Power, Alethea and Power, Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted, Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario and Sanders, Ted and Santurkar, Shibani and Sastry, Girish and Schmidt, Heather and Schnurr, David and Schulman, John and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor, Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin and Song, Yang and Staudacher, Natalie and Such, Felipe Petroski and Summers, Natalie and Sutskever, Ilya and Tang, Jie and Tezak, Nikolas and Thompson, Madeleine B. and Tillet, Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle, Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan Felipe Cerón and Vallone, Andrea and Vijayvergiya, Arun and Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei, Jason and Weinmann, C. J. and Welihinda, Akila and Welinder, Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and Willner, Dave and Winter, Clemens and Wolrich, Samuel and Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers, Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and Zoph, Barret},
  date = {2024-03-04},
  eprint = {2303.08774},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.08774},
  url = {http://arxiv.org/abs/2303.08774},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/kchou/HDD/Library/References/OpenAI et al. - 2024 - GPT-4 Technical Report - openai2024.pdf;/home/kchou/HDD/Library/References/2303.html}
}

@online{openai2025,
  title = {Introducing {{GPT-4}}.1 in the {{API}}},
  author = {{OpenAI}},
  date = {2025-04-14},
  url = {https://openai.com/index/gpt-4-1/},
  abstract = {Introducing GPT-4.1 in the API—a new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We’re also releasing our first nano model. Available to developers worldwide starting today.},
  langid = {american},
  file = {/home/kchou/HDD/Library/References/gpt-4-1.html}
}

@online{openai2025a,
  title = {Introducing {{Codex}}},
  author = {{OpenAI}},
  date = {2025-05-16},
  url = {https://openai.com/index/introducing-codex/},
  abstract = {Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.},
  langid = {american},
  file = {/home/kchou/HDD/Library/References/introducing-codex.html}
}

@software{oss-fuzz,
  title = {{{OSS-Fuzz}}},
  author = {Arya, Abhishek and Chang, Oliver and Metzman, Jonathan and Serebryany, Kostya and Liu, Dongge},
  date = {2025-04-08T14:23:14Z},
  origdate = {2016-07-20T19:39:50Z},
  url = {https://github.com/google/oss-fuzz},
  abstract = {OSS-Fuzz - continuous fuzzing for open source software.},
  keywords = {project/thesis,repo}
}

@software{oss-fuzz-gen,
  title = {{{OSS-fuzz-gen}}: {{Automated}} Fuzz Target Generation},
  author = {Liu, Dongge and Chang, Oliver and {metzman}, Jonathan and Sablotny, Martin and Maruseac, Mihai},
  date = {2024-05},
  url = {https://github.com/google/oss-fuzz-gen},
  version = {https://github.com/google/oss-fuzz-gen/tree/v1.0},
  keywords = {project/thesis,repo}
}

@online{oss-fuzzmaintainers2024,
  title = {Introducing {{LLM-based}} Harness Synthesis for Unfuzzed Projects},
  author = {{OSS-Fuzz Maintainers}},
  date = {2024-05-27T00:00:00+00:00},
  url = {https://blog.oss-fuzz.com/posts/introducing-llm-based-harness-synthesis-for-unfuzzed-projects/},
  abstract = {The primary goal of our efforts are to take as input a GitHub repository and output an OSS-Fuzz project as well as a ClusterFuzzLite project with a meaningful fuzz harness. In this blog post we will describe how we automatically build projects, how we generate fuzzing harnesses using LLMs, how these are evaluated and list a selection of 15 projects that we generated OSS-Fuzz/ClusterFuzzLite integrations for and have upstreamed the results. Introducing LLM-based harness generation for unfuzzed projects.},
  langid = {english},
  organization = {OSS-Fuzz blog},
  keywords = {with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T15:21:06.199Z},
  file = {/home/kchou/HDD/Library/References/index.html}
}

@online{ossfuzzdocs2025,
  title = {{{OSS-Fuzz Documentation}}},
  author = {{OSS-Fuzz}},
  date = {2025},
  url = {https://google.github.io/oss-fuzz/},
  abstract = {Documentation for OSS-Fuzz},
  langid = {american},
  organization = {OSS-Fuzz},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-04T14:28:02.098Z},
  file = {/home/kchou/HDD/Library/References/oss-fuzz.html}
}

@online{owaspfoundation,
  title = {Fuzzing},
  author = {{OWASP Foundation}},
  url = {https://owasp.org/www-community/Fuzzing},
  abstract = {Fuzzing on the main website for The OWASP Foundation. OWASP is a nonprofit foundation that works to improve the security of software.},
  langid = {english},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-15T16:21:13.984Z},
  file = {/home/kchou/HDD/Library/References/Fuzzing.html}
}

@software{pakkanen2025,
  title = {Mesonbuild/Meson},
  author = {Pakkanen, Jussi},
  date = {2025-07-14T02:07:49Z},
  origdate = {2014-05-14T15:08:16Z},
  url = {https://github.com/mesonbuild/meson},
  abstract = {The Meson Build System},
  organization = {The Meson Build System}
}

@online{perry2023,
  title = {Do {{Users Write More Insecure Code}} with {{AI Assistants}}?},
  author = {Perry, Neil and Srivastava, Megha and Kumar, Deepak and Boneh, Dan},
  date = {2023-12-18},
  eprint = {2211.03622},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2211.03622},
  url = {http://arxiv.org/abs/2211.03622},
  abstract = {We conduct the first large-scale user study examining how users interact with an AI Code assistant to solve a variety of security related tasks across different programming languages. Overall, we find that participants who had access to an AI assistant based on OpenAI's codex-davinci-002 model wrote significantly less secure code than those without access. Additionally, participants with access to an AI assistant were more likely to believe they wrote secure code than those without access to the AI assistant. Furthermore, we find that participants who trusted the AI less and engaged more with the language and format of their prompts (e.g. re-phrasing, adjusting temperature) provided code with fewer security vulnerabilities. Finally, in order to better inform the design of future AI-based Code assistants, we provide an in-depth analysis of participants' language and interaction behavior, as well as release our user interface as an instrument to conduct similar studies in the future.},
  pubstate = {prepublished},
  file = {/home/kchou/HDD/Library/References/Perry et al. - 2023 - Do Users Write More Insecure Code with AI Assistants - @perryUsersWriteMore2023.pdf;/home/kchou/HDD/Library/References/2211.html}
}

@online{pip,
  title = {Pip Documentation V25.1.1},
  author = {{pip developers}},
  date = {2025},
  url = {https://pip.pypa.io/en/stable/},
  file = {/home/kchou/HDD/Library/References/stable.html}
}

@online{prophetfuzz,
  title = {{{ProphetFuzz}}: {{Fully Automated Prediction}} and {{Fuzzing}} of {{High-Risk Option Combinations}} with {{Only Documentation}} via {{Large Language Model}}},
  shorttitle = {{{ProphetFuzz}}},
  author = {Wang, Dawei and Zhou, Geng and Chen, Li and Li, Dan and Miao, Yukai},
  date = {2024-09-01},
  eprint = {2409.00922},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.1145/3658644.3690231},
  url = {http://arxiv.org/abs/2409.00922},
  abstract = {Vulnerabilities related to option combinations pose a significant challenge in software security testing due to their vast search space. Previous research primarily addressed this challenge through mutation or filtering techniques, which inefficiently treated all option combinations as having equal potential for vulnerabilities, thus wasting considerable time on non-vulnerable targets and resulting in low testing efficiency. In this paper, we utilize carefully designed prompt engineering to drive the large language model (LLM) to predict high-risk option combinations (i.e., more likely to contain vulnerabilities) and perform fuzz testing automatically without human intervention. We developed a tool called ProphetFuzz and evaluated it on a dataset comprising 52 programs collected from three related studies. The entire experiment consumed 10.44 CPU years. ProphetFuzz successfully predicted 1748 high-risk option combinations at an average cost of only \textbackslash\$8.69 per program. Results show that after 72 hours of fuzzing, ProphetFuzz discovered 364 unique vulnerabilities associated with 12.30\textbackslash\% of the predicted high-risk option combinations, which was 32.85\textbackslash\% higher than that found by state-of-the-art in the same timeframe. Additionally, using ProphetFuzz, we conducted persistent fuzzing on the latest versions of these programs, uncovering 140 vulnerabilities, with 93 confirmed by developers and 21 awarded CVE numbers.},
  pubstate = {prepublished},
  keywords = {with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T15:35:05.407Z},
  file = {/home/kchou/HDD/Library/References/Wang et al. - 2024 - ProphetFuzz Fully Automated Prediction and Fuzzing of High-Risk Option Combinations with Only Docum - @wangProphetFuzzFullyAutomated2024.pdf;/home/kchou/HDD/Library/References/2409.html}
}

@software{pydantic2025,
  title = {Pydantic/Pydantic-Ai},
  author = {{Pydantic}},
  date = {2025-05-26T18:39:53Z},
  origdate = {2024-06-21T15:55:04Z},
  url = {https://github.com/pydantic/pydantic-ai},
  abstract = {Agent Framework / shim to use Pydantic with LLMs},
  organization = {Pydantic},
  keywords = {agent-framework,llms,pydantic,python}
}

@online{pytorch,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  shorttitle = {{{PyTorch}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  date = {2019-12-03},
  eprint = {1912.01703},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1912.01703},
  url = {http://arxiv.org/abs/1912.01703},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
  pubstate = {prepublished},
  file = {/home/kchou/HDD/Library/References/Paszke et al_2019_PyTorch.pdf;/home/kchou/HDD/Library/Zotero data/storage/6MM7VAXX/1912.html}
}

@article{radford2018,
  title = {Improving Language Understanding by Generative Pre-Training},
  author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  date = {2018},
  publisher = {San Francisco, CA, USA},
  url = {https://www.mikecaptain.com/resources/pdf/GPT-1.pdf},
  file = {/home/kchou/HDD/Library/References/Radford et al. - 2018 - Improving language understanding by generative pre-training - radford2018.pdf}
}

@article{radford2019,
  title = {Language Models Are Unsupervised Multitask Learners},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  date = {2019},
  journaltitle = {OpenAI blog},
  volume = {1},
  number = {8},
  pages = {9},
  url = {https://storage.prod.researchhub.com/uploads/papers/2020/06/01/language-models.pdf},
  file = {/home/kchou/HDD/Library/References/Radford et al. - 2019 - Language models are unsupervised multitask learners - radford2019.pdf}
}

@book{rathaus2007,
  title = {Open Source Fuzzing Tools},
  author = {Rathaus, Noam and Evron, Gadi},
  editor = {Evron, Gadi},
  date = {2007},
  publisher = {Syngress Pub},
  location = {Burlington, MA},
  isbn = {978-1-59749-195-2},
  pagetotal = {199},
  keywords = {Computer software,Debugging in computer science,Open source software,Testing}
}

@online{reAct,
  title = {{{ReAct}}: {{Synergizing Reasoning}} and {{Acting}} in {{Language Models}}},
  shorttitle = {{{ReAct}}},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  date = {2023-03-10},
  eprint = {2210.03629},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2210.03629},
  url = {http://arxiv.org/abs/2210.03629},
  abstract = {While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
  pubstate = {prepublished},
  file = {/home/kchou/HDD/Library/References/Yao et al. - 2023 - ReAct Synergizing Reasoning and Acting in Language Models - @yaoReActSynergizingReasoning2023.pdf;/home/kchou/HDD/Library/References/2210.html}
}

@inproceedings{rebert2014,
  title = {Optimizing Seed Selection for Fuzzing},
  booktitle = {Proceedings of the 23rd {{USENIX}} Conference on {{Security Symposium}}},
  author = {Rebert, Alexandre and Cha, Sang Kil and Avgerinos, Thanassis and Foote, Jonathan and Warren, David and Grieco, Gustavo and Brumley, David},
  date = {2014-08-20},
  series = {{{SEC}}'14},
  pages = {861--875},
  publisher = {USENIX Association},
  location = {USA},
  abstract = {Randomly mutating well-formed program inputs or simply fuzzing, is a highly effective and widely used strategy to find bugs in software. Other than showing fuzzers find bugs, there has been little systematic effort in understanding the science of how to fuzz properly. In this paper, we focus on how to mathematically formulate and reason about one critical aspect in fuzzing: how best to pick seed files to maximize the total number of bugs found during a fuzz campaign. We design and evaluate six different algorithms using over 650 CPU days on Amazon Elastic Compute Cloud (EC2) to provide ground truth data. Overall, we find 240 bugs in 8 applications and show that the choice of algorithm can greatly increase the number of bugs found. We also show that current seed selection strategies as found in Peach may fare no better than picking seeds at random. We make our data set and code publicly available.},
  isbn = {978-1-931971-15-7},
  file = {/home/kchou/HDD/Library/References/Rebert et al. - 2014 - Optimizing seed selection for fuzzing - rebert2014.pdf}
}

@online{saarinen2014,
  title = {Further Flaws Render {{Shellshock}} Patch Ineffective},
  author = {Saarinen, Juha},
  date = {2014-09-29},
  url = {https://www.itnews.com.au/news/further-flaws-render-shellshock-patch-ineffective-396256},
  abstract = {Patched systems remain vulnerable.},
  organization = {iTnews},
  file = {/home/kchou/HDD/Library/References/further-flaws-render-shellshock-patch-ineffective-396256.html}
}

@online{sarkar2025,
  title = {Vibe Coding: Programming through Conversation with Artificial Intelligence},
  shorttitle = {Vibe Coding},
  author = {Sarkar, Advait and Drosos, Ian},
  date = {2025-06-29},
  eprint = {2506.23253},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2506.23253},
  url = {http://arxiv.org/abs/2506.23253},
  abstract = {We examine "vibe coding": an emergent programming paradigm where developers primarily write code by interacting with code-generating large language models rather than writing code directly. We analysed a curated set of videos depicting extended vibe coding sessions with rich think-aloud reflections. Using framework analysis, we investigated programmers' goals, workflows, prompting techniques, debugging approaches, and challenges encountered. We find that vibe coding follows iterative goal satisfaction cycles where developers alternate between prompting AI, evaluating generated code through rapid scanning and application testing, and manual editing. Prompting strategies blend vague, high-level directives with detailed technical specifications. Debugging remains a hybrid process combining AI assistance with manual practices. Critically, vibe coding does not eliminate the need for programming expertise but rather redistributes it toward context management, rapid code evaluation, and decisions about when to transition between AI-driven and manual manipulation of code. Trust in AI tools during vibe coding is dynamic and contextual, developed through iterative verification rather than blanket acceptance. Vibe coding is an evolution of AI-assisted programming that represents an early manifestation of "material disengagement", where practitioners orchestrate code production and manipulation, mediated through AI, while maintaining selective and strategic oversight.},
  pubstate = {prepublished},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {/home/kchou/HDD/Library/References/Sarkar and Drosos - 2025 - Vibe coding programming through conversation with artificial intelligence - sarkar2025.pdf;/home/kchou/HDD/Library/References/2506 1.html}
}

@article{sarker2022,
  title = {Neuro-Symbolic Artificial Intelligence: {{Current}} Trends},
  shorttitle = {Neuro-Symbolic Artificial Intelligence},
  author = {Sarker, Md Kamruzzaman and Zhou, Lu and Eberhart, Aaron and Hitzler, Pascal},
  date = {2022-03-04},
  journaltitle = {AI Communications},
  shortjournal = {AIC},
  volume = {34},
  number = {3},
  pages = {197--209},
  publisher = {SAGE Publications},
  issn = {1875-8452, 0921-7126},
  doi = {10.3233/aic-210084},
  url = {https://journals.sagepub.com/doi/full/10.3233/AIC-210084},
  abstract = {Neuro-Symbolic Artificial Intelligence – the combination of symbolic methods with methods that are based on artificial neural networks – has a long-standing history. In this article, we provide a structured overview of current trends, by means of categorizing recent publications from key conferences. The article is meant to serve as a convenient starting point for research on the general topic.},
  file = {/home/kchou/HDD/Library/References/Sarker et al. - 2022 - Neuro-symbolic artificial intelligence Current trends - sarker2022.pdf}
}

@article{sasirekha2011Slicing,
  title = {Program {{Slicing Techniques}} and Its {{Applications}}},
  author = {Sasirekha, N and Edwin Robert, A and Hemalatha, M},
  date = {2011-07-31},
  journaltitle = {International Journal of Software Engineering \& Applications},
  shortjournal = {IJSEA},
  volume = {2},
  number = {3},
  pages = {50--64},
  issn = {09762221},
  doi = {10.5121/ijsea.2011.2304},
  url = {http://www.airccse.org/journal/ijsea/papers/0711ijsea04.pdf},
  file = {/home/kchou/HDD/Library/References/Sasirekha et al. - 2011 - Program Slicing Techniques and its Applications - sasirekha2011Program.pdf}
}

@online{semver,
  title = {Semantic {{Versioning}} 2.0.0},
  author = {Preston-Werner, Tom},
  url = {https://semver.org/},
  abstract = {Semantic Versioning spec and website},
  langid = {english},
  organization = {Semantic Versioning},
  file = {/home/kchou/HDD/Library/References/semver.org.html}
}

@inproceedings{serebryany2012,
  title = {{{AddressSanitizer}}: {{A}} Fast Address Sanity Checker},
  shorttitle = {{{AddressSanitizer}}},
  booktitle = {2012 {{USENIX}} Annual Technical Conference ({{USENIX ATC}} 12)},
  author = {Serebryany, Konstantin and Bruening, Derek and Potapenko, Alexander and Vyukov, Dmitriy},
  date = {2012},
  pages = {309--318},
  url = {https://www.usenix.org/conference/atc12/technical-sessions/presentation/serebryany},
  file = {/home/kchou/HDD/Library/References/Serebryany et al. - 2012 - AddressSanitizer A fast address sanity checker - serebryany2012.pdf}
}

@online{shellshock-cve,
  title = {{{NVD}} - {{CVE-2014-6271}}},
  author = {{NIST}},
  date = {2014},
  url = {https://nvd.nist.gov/vuln/detail/CVE-2014-6271}
}

@online{sheth2023,
  title = {Neurosymbolic {{AI}} -- {{Why}}, {{What}}, and {{How}}},
  author = {Sheth, Amit and Roy, Kaushik and Gaur, Manas},
  date = {2023-05-01},
  eprint = {2305.00813},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.00813},
  url = {http://arxiv.org/abs/2305.00813},
  abstract = {Humans interact with the environment using a combination of perception - transforming sensory inputs from their environment into symbols, and cognition - mapping symbols to knowledge about the environment for supporting abstraction, reasoning by analogy, and long-term planning. Human perception-inspired machine perception, in the context of AI, refers to large-scale pattern recognition from raw data using neural networks trained using self-supervised learning objectives such as next-word prediction or object recognition. On the other hand, machine cognition encompasses more complex computations, such as using knowledge of the environment to guide reasoning, analogy, and long-term planning. Humans can also control and explain their cognitive functions. This seems to require the retention of symbolic mappings from perception outputs to knowledge about their environment. For example, humans can follow and explain the guidelines and safety constraints driving their decision-making in safety-critical applications such as healthcare, criminal justice, and autonomous driving. This article introduces the rapidly emerging paradigm of Neurosymbolic AI combines neural networks and knowledge-guided symbolic approaches to create more capable and flexible AI systems. These systems have immense potential to advance both algorithm-level (e.g., abstraction, analogy, reasoning) and application-level (e.g., explainable and safety-constrained decision-making) capabilities of AI systems.},
  pubstate = {prepublished},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-02-19T16:36:56.658Z},
  file = {/home/kchou/HDD/Library/References/Sheth et al. - 2023 - Neurosymbolic AI -- Why, What, and How - @shethNeurosymbolicAIWhy2023.pdf;/home/kchou/HDD/Library/References/2305.html}
}

@article{simonite2020mayhem,
  entrysubtype = {magazine},
  title = {This {{Bot Hunts Software Bugs}} for the {{Pentagon}}},
  author = {Simonite, Tom},
  date = {2020-06-01},
  journaltitle = {Wired},
  issn = {1059-1028},
  url = {https://www.wired.com/story/bot-hunts-software-bugs-pentagon/},
  abstract = {Mayhem emerged from a 2016 government-sponsored contest at a Las Vegas casino hotel. Now it's used by the military.},
  langid = {american},
  keywords = {artificial intelligence,cybersecurity,darpa,malware,vulnerabilities},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-04T14:28:05.460Z}
}

@inproceedings{sun2024,
  title = {Automated {{Generation}} and {{Compilation}} of {{Fuzz Driver Based}} on {{Large Language Models}}},
  booktitle = {Proceedings of the 2024 9th {{International Conference}} on {{Cyber Security}} and {{Information Engineering}}},
  author = {Sun, Yuxuan},
  date = {2024-12-03},
  series = {{{ICCSIE}} '24},
  pages = {461--468},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3689236.3689272},
  url = {https://doi.org/10.1145/3689236.3689272},
  abstract = {Fuzz drivers are essential components of library fuzz testing, yet automatically generating correct and robust fuzz drivers and executing them is challenging. The predominant approach to fuzz testing libraries and their function interfaces involves security experts manually writing test drivers for fuzz testers. In contrast, generation based on LLMs (Large Language Models) is a promising direction, as it can operate with lower requirements on consumer programs, utilizes API (Application Programming Interface) usage information across multiple dimensions, and generates user-friendly output code. However, there is currently no fully automated method for driver generation and compilation. To address this issue, this paper has designed an automated method for generating and compiling drivers, and has evaluated the quality of the drivers it produces. Evaluation results indicate that drivers generated by large language models perform nearly as well in coverage as those written manually, and the generated compilation commands achieve an accuracy of 75\%.},
  isbn = {979-8-4007-1813-7},
  keywords = {with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T15:44:36.518Z},
  file = {/home/kchou/HDD/Library/References/Sun - 2024 - Automated Generation and Compilation of Fuzz Driver Based on Large Language Models - sun2024.pdf}
}

@book{sutton2007,
  title = {Fuzzing: Brute Force Vulnerabilty Discovery},
  shorttitle = {Fuzzing},
  author = {Sutton, Michael and Greene, Adam and Amini, Pedram},
  date = {2007},
  publisher = {Addison-Wesley},
  location = {Upper Saddle River, NJ},
  isbn = {978-0-321-44611-4},
  pagetotal = {543},
  keywords = {Computer networks,Computer security,Computer software,Development,Security measures}
}

@book{takanen2018,
  title = {Fuzzing for Software Security Testing and Quality Assurance},
  author = {Takanen, Ari and DeMott, Jared and Miller, Charlie and Kettunen, Atte},
  date = {2018},
  series = {Information Security and Privacy Library},
  edition = {Second edition},
  publisher = {Artech House},
  location = {Boston London Norwood, MA},
  isbn = {978-1-63081-519-6},
  langid = {english},
  pagetotal = {1}
}

@software{tensorflow,
  title = {{{TensorFlow}}, {{Large-scale}} Machine Learning on Heterogeneous Systems},
  author = {Abadi, Martín and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jozefowicz, Rafal and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mané, Dan and Schuster, Mike and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viégas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  date = {2015-11},
  doi = {10.5281/zenodo.4724125}
}

@software{theopensslproject2025,
  title = {Openssl/Openssl},
  author = {{The OpenSSL Project}},
  date = {2025-07-15T07:33:10Z},
  origdate = {2013-01-15T22:34:48Z},
  url = {https://github.com/openssl/openssl},
  abstract = {TLS/SSL and crypto library},
  organization = {OpenSSL},
  keywords = {cryptography,decryption,encryption,openssl,ssl,tls}
}

@software{thomason2025,
  title = {Leethomason/Tinyxml2},
  author = {Thomason, Lee},
  date = {2025-07-10T03:54:27Z},
  origdate = {2012-02-25T05:15:50Z},
  url = {https://github.com/leethomason/tinyxml2},
  abstract = {TinyXML2 is a simple, small, efficient, C++ XML parser that can be easily integrated into other programs.}
}

@online{tilwani2024,
  title = {Neurosymbolic {{AI}} Approach to {{Attribution}} in {{Large Language Models}}},
  author = {Tilwani, Deepa and Venkataramanan, Revathy and Sheth, Amit P.},
  date = {2024-09-30},
  eprint = {2410.03726},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2410.03726},
  url = {http://arxiv.org/abs/2410.03726},
  abstract = {Attribution in large language models (LLMs) remains a significant challenge, particularly in ensuring the factual accuracy and reliability of the generated outputs. Current methods for citation or attribution, such as those employed by tools like Perplexity.ai and Bing Search-integrated LLMs, attempt to ground responses by providing real-time search results and citations. However, so far, these approaches suffer from issues such as hallucinations, biases, surface-level relevance matching, and the complexity of managing vast, unfiltered knowledge sources. While tools like Perplexity.ai dynamically integrate web-based information and citations, they often rely on inconsistent sources such as blog posts or unreliable sources, which limits their overall reliability. We present that these challenges can be mitigated by integrating Neurosymbolic AI (NesyAI), which combines the strengths of neural networks with structured symbolic reasoning. NesyAI offers transparent, interpretable, and dynamic reasoning processes, addressing the limitations of current attribution methods by incorporating structured symbolic knowledge with flexible, neural-based learning. This paper explores how NesyAI frameworks can enhance existing attribution models, offering more reliable, interpretable, and adaptable systems for LLMs.},
  pubstate = {prepublished},
  file = {/home/kchou/HDD/Library/References/Tilwani et al. - 2024 - Neurosymbolic AI approach to Attribution in Large Language Models - @tilwaniNeurosymbolicAIApproach2024.pdf;/home/kchou/HDD/Library/References/2410 1.html}
}

@inproceedings{titanfuzz,
  title = {Large {{Language Models Are Zero-Shot Fuzzers}}: {{Fuzzing Deep-Learning Libraries}} via {{Large Language Models}}},
  shorttitle = {Large {{Language Models Are Zero-Shot Fuzzers}}},
  booktitle = {Proceedings of the 32nd {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}}},
  author = {Deng, Yinlin and Xia, Chunqiu Steven and Peng, Haoran and Yang, Chenyuan and Zhang, Lingming},
  date = {2023-07-13},
  series = {{{ISSTA}} 2023},
  pages = {423--435},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3597926.3598067},
  url = {https://dl.acm.org/doi/10.1145/3597926.3598067},
  abstract = {Deep Learning (DL) systems have received exponential growth in popularity and have become ubiquitous in our everyday life. Such systems are built on top of popular DL libraries, e.g., TensorFlow and PyTorch which provide APIs as building blocks for DL systems. Detecting bugs in these DL libraries is critical for almost all downstream DL systems in ensuring effectiveness/safety for end users. Meanwhile, traditional fuzzing techniques can be hardly effective for such a challenging domain since the input DL programs need to satisfy both the input language (e.g., Python) syntax/semantics and the DL API input/shape constraints for tensor computations.   To address these limitations, we propose TitanFuzz – the first approach to directly leveraging Large Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are titanic models trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora, and thus can implicitly learn both language syntax/semantics and intricate DL API constraints for valid DL program generation. More specifically, we use both generative and infilling LLMs (e.g., Codex/InCoder) to generate and mutate valid/diverse input DL programs for fuzzing. Our experimental results demonstrate that TitanFuzz can achieve 30.38\%/50.84\% higher code coverage than state-of-the-art fuzzers on TensorFlow/PyTorch. Furthermore, TitanFuzz is able to detect 65 bugs, with 44 already confirmed as previously unknown bugs.   This paper demonstrates that modern titanic LLMs can be leveraged to directly perform both generation-based and mutation-based fuzzing studied for decades, while being fully automated, generalizable, and applicable to domains challenging for traditional approaches (such as DL systems). We hope TitanFuzz can stimulate more work in this promising direction of LLMs for fuzzing.},
  isbn = {979-8-4007-0221-1},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T11:59:04.570Z},
  file = {/home/kchou/HDD/Library/References/Deng et al. - 2023 - Large Language Models Are Zero-Shot Fuzzers Fuzzing Deep-Learning Libraries via Large Language Mode - @dengLargeLanguageModels2023.pdf}
}

@software{torvalds2005,
  title = {Git},
  author = {Torvalds, Linus},
  date = {2005-04-07},
  url = {https://git-scm.com/},
  file = {/home/kchou/HDD/Library/References/git-scm.com.html}
}

@online{tzachristas2024,
  title = {Creating an {{LLM-based AI-agent}}: {{A}} High-Level Methodology towards Enhancing {{LLMs}} with {{APIs}}},
  shorttitle = {Creating an {{LLM-based AI-agent}}},
  author = {Tzachristas, Ioannis},
  date = {2024-12-21},
  eprint = {2412.13233},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2412.13233},
  url = {http://arxiv.org/abs/2412.13233},
  abstract = {Large Language Models (LLMs) have revolutionized various aspects of engineering and science. Their utility is often bottlenecked by the lack of interaction with the external digital environment. To overcome this limitation and achieve integration of LLMs and Artificial Intelligence (AI) into real-world applications, customized AI agents are being constructed. Based on the technological trends and techniques, we extract a high-level approach for constructing these AI agents, focusing on their underlying architecture. This thesis serves as a comprehensive guide that elucidates a multi-faceted approach for empowering LLMs with the capability to leverage Application Programming Interfaces (APIs). We present a 7-step methodology that begins with the selection of suitable LLMs and the task decomposition that is necessary for complex problem-solving. This methodology includes techniques for generating training data for API interactions and heuristics for selecting the appropriate API among a plethora of options. These steps eventually lead to the generation of API calls that are both syntactically and semantically aligned with the LLM's understanding of a given task. Moreover, we review existing frameworks and tools that facilitate these processes and highlight the gaps in current attempts. In this direction, we propose an on-device architecture that aims to exploit the functionality of carry-on devices by using small models from the Hugging Face community. We examine the effectiveness of these approaches on real-world applications of various domains, including the generation of a piano sheet. Through an extensive analysis of the literature and available technologies, this thesis aims to set a compass for researchers and practitioners to harness the full potential of LLMs augmented with external tool capabilities, thus paving the way for more autonomous, robust, and context-aware AI agents.},
  pubstate = {prepublished},
  version = {2},
  keywords = {suggested},
  annotation = {Read\_Status: Not Reading\\
Read\_Status\_Date: 2025-05-04T14:30:45.262Z},
  file = {/home/kchou/HDD/Library/References/Tzachristas - 2024 - Creating an LLM-based AI-agent A high-level methodology towards enhancing LLMs with APIs - @tzachristasCreatingLLMbasedAIagent2024.pdf;/home/kchou/HDD/Library/References/2412.html}
}

@software{unicornengine2025,
  title = {Unicorn-Engine/Unicorn},
  author = {{Unicorn Engine}},
  date = {2025-07-15T08:29:04Z},
  origdate = {2015-08-20T16:35:45Z},
  url = {https://github.com/unicorn-engine/unicorn},
  abstract = {Unicorn CPU emulator framework (ARM, AArch64, M68K, Mips, Sparc, PowerPC, RiscV, S390x, TriCore, X86)},
  organization = {Unicorn Engine},
  keywords = {arm,arm64,cpu,cpu-emulator,emulator,framework,m68k,mips,powerpc,reverse-engineering,riscv,s390x,security,sparc,systemz,tricore,x86,x86-64}
}

@inproceedings{utopia,
  title = {{{UTopia}}: {{Automatic Generation}} of {{Fuzz Driver}} Using {{Unit Tests}}},
  shorttitle = {{{UTopia}}},
  booktitle = {2023 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  author = {Jeong, Bokdeuk and Jang, Joonun and Yi, Hayoon and Moon, Jiin and Kim, Junsik and Jeon, Intae and Kim, Taesoo and Shim, WooChul and Hwang, Yong Ho},
  date = {2023-05},
  pages = {2676--2692},
  issn = {2375-1207},
  doi = {10.1109/SP46215.2023.10179394},
  url = {https://ieeexplore.ieee.org/abstract/document/10179394},
  abstract = {Fuzzing is arguably the most practical approach for detecting security bugs in software, but a non-trivial extent of efforts is required for its adoption. To be effective, high-quality fuzz drivers should be first formulated with a proper sequence of APIs that can exhaustively explore the program states. To alleviate this burden, existing solutions attempt to generate fuzz drivers either by inferring the valid sequences of APIs from the consumer code (i.e., actual uses of APIs) or by directly extracting them from sample executions. Unfortunately, all existing approaches suffer from a common problem: the observed API sequences, either statically inferred or dynamically monitored, are intermingled with custom application logics. However, we observed that the unit tests are carefully crafted by the actual designer of the APIs to validate their proper usages, and importantly, it is a common practice to write the unit tests during their development (e.g., over 70\% of popular GitHub projects).In this paper, we propose, UTopia, an open-source tool and analysis algorithm that can automatically synthesize effective fuzz drivers from existing unit tests with near-zero human involvement. To demonstrate its effectiveness, we applied UTopia to 55 open-source project libraries, including Tizen and Node.js, and automatically generated 5K fuzz drivers from 8K eligible unit tests. In addition, we executed the generated fuzzers for approximately 5 million per-core hours and discovered 123 bugs. More importantly, 2.4K of the generated fuzz drivers were adopted to the continuous integration process of the Tizen project, indicating the quality of the synthesized fuzz driver. The proposed tool and results are publicly available and maintained for a broader adoption among both researchers and practitioners.},
  eventtitle = {2023 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  keywords = {Codes,Computer bugs,Libraries,Privacy,Security,Semantics,Software,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-09T12:35:17.953Z},
  file = {/home/kchou/HDD/Library/References/Jeong et al. - 2023 - UTopia Automatic Generation of Fuzz Driver using Unit Tests - jeong2023.pdf}
}

@online{vaswani2023,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2023-08-01},
  eprint = {1706.03762},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {prepublished},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-02-21T21:12:48.910Z},
  file = {/home/kchou/HDD/Library/References/Vaswani et al_2023_Attention Is All You Need.pdf;/home/kchou/HDD/Library/Zotero data/storage/VWIT3A5A/1706.html}
}

@online{venv,
  type = {Documentation},
  title = {Venv — {{Creation}} of Virtual Environments},
  author = {{Python Software Foundation}},
  date = {2025-07-17},
  url = {https://docs.python.org/3/library/venv.html},
  abstract = {Source code: Lib/venv/ The venv module supports creating lightweight “virtual environments”, each with their own independent set of Python packages installed in their site directories. A virtual en...},
  langid = {english},
  organization = {Python documentation},
  file = {/home/kchou/HDD/Library/References/venv.html}
}

@article{wang2025,
  title = {History, Development, and Principles of Large Language Models: An Introductory Survey},
  shorttitle = {History, Development, and Principles of Large Language Models},
  author = {Wang, Zichong and Chu, Zhibo and Doan, Thang Viet and Ni, Shiwen and Yang, Min and Zhang, Wenbin},
  date = {2025-06-01},
  journaltitle = {AI and Ethics},
  shortjournal = {AI Ethics},
  volume = {5},
  number = {3},
  pages = {1955--1971},
  issn = {2730-5961},
  doi = {10.1007/s43681-024-00583-7},
  url = {https://doi.org/10.1007/s43681-024-00583-7},
  abstract = {Language models serve as a cornerstone in natural language processing, utilizing mathematical methods to generalize language laws and knowledge for prediction and generation. Over extensive research spanning decades, language modeling has progressed from initial statistical language models to the contemporary landscape of large language models (LLMs). Notably, the swift evolution of LLMs has reached the ability to process, understand, and generate human-level text. Nevertheless, despite the significant advantages that LLMs offer in improving both work and personal lives, the limited understanding among general practitioners about the background and principles of these models hampers their full potential. Notably, most LLM reviews focus on specific aspects and utilize specialized language, posing a challenge for practitioners lacking relevant background knowledge. In light of this, this survey aims to present a comprehensible overview of LLMs to assist a broader audience. It strives to facilitate a comprehensive understanding by exploring the historical background of language models and tracing their evolution over time. The survey further investigates the factors influencing the development of LLMs, emphasizing key contributions. Additionally, it concentrates on elucidating the underlying principles of LLMs, equipping audiences with essential theoretical knowledge. The survey also highlights the limitations of existing work and points out promising future directions.},
  langid = {english},
  keywords = {Analytical Philosophy of Language,Artificial intelligence,Computational Linguistics,Evolution of language,Historical Linguistics,Language History,Language model,Large language model,Natural language processing,Research Methods in Language and Linguistics},
  file = {/home/kchou/HDD/Library/References/Wang et al. - 2025 - History, development, and principles of large language models an introductory survey - wang2025 1.pdf;/home/kchou/HDD/Library/References/Wang et al. - 2025 - History, development, and principles of large language models an introductory survey - wang2025.pdf}
}

@online{wheeler2014,
  title = {How to {{Prevent}} the next {{Heartbleed}}},
  author = {Wheeler, David},
  date = {2014},
  url = {https://dwheeler.com/essays/heartbleed.html},
  file = {/home/kchou/HDD/Library/References/heartbleed.html}
}

@online{xu2024,
  title = {{{CKGFuzzer}}: {{LLM-Based Fuzz Driver Generation Enhanced By Code Knowledge Graph}}},
  shorttitle = {{{CKGFuzzer}}},
  author = {Xu, Hanxiang and Ma, Wei and Zhou, Ting and Zhao, Yanjie and Chen, Kai and Hu, Qiang and Liu, Yang and Wang, Haoyu},
  date = {2024-12-20},
  eprint = {2411.11532},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.11532},
  url = {http://arxiv.org/abs/2411.11532},
  abstract = {In recent years, the programming capabilities of large language models (LLMs) have garnered significant attention. Fuzz testing, a highly effective technique, plays a key role in enhancing software reliability and detecting vulnerabilities. However, traditional fuzz testing tools rely on manually crafted fuzz drivers, which can limit both testing efficiency and effectiveness. To address this challenge, we propose an automated fuzz testing method driven by a code knowledge graph and powered by an LLM-based intelligent agent system, referred to as CKGFuzzer. We approach fuzz driver creation as a code generation task, leveraging the knowledge graph of the code repository to automate the generation process within the fuzzing loop, while continuously refining both the fuzz driver and input seeds. The code knowledge graph is constructed through interprocedural program analysis, where each node in the graph represents a code entity, such as a function or a file. The knowledge graph-enhanced CKGFuzzer not only effectively resolves compilation errors in fuzz drivers and generates input seeds tailored to specific API usage scenarios, but also analyzes fuzz driver crash reports, assisting developers in improving code quality. By querying the knowledge graph of the code repository and learning from API usage scenarios, we can better identify testing targets and understand the specific purpose of each fuzz driver. We evaluated our approach using eight open-source software projects. The experimental results indicate that CKGFuzzer achieved an average improvement of 8.73\% in code coverage compared to state-of-the-art techniques. Additionally, CKGFuzzer reduced the manual review workload in crash case analysis by 84.4\% and successfully detected 11 real bugs (including nine previously unreported bugs) across the tested libraries.},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Software Engineering,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-13T21:00:35.053Z},
  file = {/home/kchou/HDD/Library/References/Xu et al. - 2024 - CKGFuzzer LLM-Based Fuzz Driver Generation Enhanced By Code Knowledge Graph - xu2024.pdf;/home/kchou/HDD/Library/References/2411.html}
}

@online{yao2023,
  title = {Tree of {{Thoughts}}: {{Deliberate Problem Solving}} with {{Large Language Models}}},
  shorttitle = {Tree of {{Thoughts}}},
  author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
  date = {2023-12-03},
  eprint = {2305.10601},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.10601},
  url = {http://arxiv.org/abs/2305.10601},
  abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.},
  pubstate = {prepublished},
  keywords = {suggested},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-10-15T11:27:12.812Z},
  file = {/home/kchou/HDD/Library/References/Yao et al. - 2023 - Tree of Thoughts Deliberate Problem Solving with Large Language Models - @yaoTreeThoughtsDeliberate2023.pdf;/home/kchou/HDD/Library/References/2305 1.html}
}

@online{zebaze2024,
  title = {Tree of {{Problems}}: {{Improving}} Structured Problem Solving with Compositionality},
  shorttitle = {Tree of {{Problems}}},
  author = {Zebaze, Armel and Sagot, Benoît and Bawden, Rachel},
  date = {2024-10-09},
  eprint = {2410.06634},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2410.06634},
  url = {http://arxiv.org/abs/2410.06634},
  abstract = {Large Language Models (LLMs) have demonstrated remarkable performance across multiple tasks through in-context learning. For complex reasoning tasks that require step-by-step thinking, Chain-of-Thought (CoT) prompting has given impressive results, especially when combined with self-consistency. Nonetheless, some tasks remain particularly difficult for LLMs to solve. Tree of Thoughts (ToT) and Graph of Thoughts (GoT) emerged as alternatives, dividing the complex problem into paths of subproblems. In this paper, we propose Tree of Problems (ToP), a simpler version of ToT, which we hypothesise can work better for complex tasks that can be divided into identical subtasks. Our empirical results show that our approach outperforms ToT and GoT, and in addition performs better than CoT on complex reasoning tasks. All code for this paper is publicly available here: https://github.com/ArmelRandy/tree-of-problems.},
  pubstate = {prepublished},
  file = {/home/kchou/HDD/Library/References/Zebaze et al. - 2024 - Tree of Problems Improving structured problem solving with compositionality - @zebazeTreeProblemsImproving2024.pdf}
}

@online{zhang2021,
  title = {{{IntelliGen}}: {{Automatic Driver Synthesis}} for {{FuzzTesting}}},
  shorttitle = {{{IntelliGen}}},
  author = {Zhang, Mingrui and Liu, Jianzhong and Ma, Fuchen and Zhang, Huafeng and Jiang, Yu},
  date = {2021-03-01},
  eprint = {2103.00862},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2103.00862},
  url = {http://arxiv.org/abs/2103.00862},
  abstract = {Fuzzing is a technique widely used in vulnerability detection. The process usually involves writing effective fuzz driver programs, which, when done manually, can be extremely labor intensive. Previous attempts at automation leave much to be desired, in either degree of automation or quality of output. In this paper, we propose IntelliGen, a framework that constructs valid fuzz drivers automatically. First, IntelliGen determines a set of entry functions and evaluates their respective chance of exhibiting a vulnerability. Then, IntelliGen generates fuzz drivers for the entry functions through hierarchical parameter replacement and type inference. We implemented IntelliGen and evaluated its effectiveness on real-world programs selected from the Android Open-Source Project, Google's fuzzer-test-suite and industrial collaborators. IntelliGen covered on average 1.08X-2.03X more basic blocks and 1.36X-2.06X more paths over state-of-the-art fuzz driver synthesizers FUDGE and FuzzGen. IntelliGen performed on par with manually written drivers and found 10 more bugs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Software Engineering,with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-11T17:29:15.700Z},
  file = {/home/kchou/HDD/Library/References/Zhang et al. - 2021 - IntelliGen Automatic Driver Synthesis for FuzzTesting - zhang2021.pdf;/home/kchou/HDD/Library/References/2103.html}
}

@inproceedings{zhang2024,
  title = {How {{Effective Are They}}? {{Exploring Large Language Model Based Fuzz Driver Generation}}},
  shorttitle = {How {{Effective Are They}}?},
  booktitle = {Proceedings of the 33rd {{ACM SIGSOFT International Symposium}} on {{Software Testing}} and {{Analysis}}},
  author = {Zhang, Cen and Zheng, Yaowen and Bai, Mingqiang and Li, Yeting and Ma, Wei and Xie, Xiaofei and Li, Yuekang and Sun, Limin and Liu, Yang},
  date = {2024-09-11},
  series = {{{ISSTA}} 2024},
  pages = {1223--1235},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3650212.3680355},
  url = {https://dl.acm.org/doi/10.1145/3650212.3680355},
  abstract = {Fuzz drivers are essential for library API fuzzing. However, automatically generating fuzz drivers is a complex task, as it demands the creation of high-quality, correct, and robust API usage code. An LLM-based (Large Language Model) approach for generating fuzz drivers is a promising area of research. Unlike traditional program analysis-based generators, this text-based approach is more generalized and capable of harnessing a variety of API usage information, resulting in code that is friendly for human readers. However, there is still a lack of understanding regarding the fundamental issues on this direction, such as its effectiveness and potential challenges.     To bridge this gap, we conducted the first in-depth study targeting the important issues of using LLMs to generate effective fuzz drivers. Our study features a curated dataset with 86 fuzz driver generation questions from 30 widely-used C projects. Six prompting strategies are designed and tested across five state-of-the-art LLMs with five different temperature settings. In total, our study evaluated 736,430 generated fuzz drivers, with 0.85 billion token costs (\$8,000+ charged tokens). Additionally, we compared the LLM-generated drivers against those utilized in industry, conducting extensive fuzzing experiments (3.75 CPU-year). Our study uncovered that:     1) While LLM-based fuzz driver generation is a promising direction, it still encounters several obstacles towards practical applications;   2) LLMs face difficulties in generating effective fuzz drivers for APIs with intricate specifics. Three featured design choices of prompt strategies can be beneficial: issuing repeat queries, querying with examples, and employing an iterative querying process;   3) While LLM-generated drivers can yield fuzzing outcomes that are on par with those used in the industry, there are substantial opportunities for enhancement, such as extending contained API usage, or integrating semantic oracles to facilitate logical bug detection.     Our insights have been implemented to improve the OSS-Fuzz-Gen project, facilitating practical fuzz driver generation in industry.},
  isbn = {979-8-4007-0612-7},
  keywords = {with-notes},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-07-08T11:58:56.334Z},
  file = {/home/kchou/HDD/Library/References/Zhang et al. - 2024 - How Effective Are They Exploring Large Language Model Based Fuzz Driver Generation - @zhangHowEffectiveAre2024.pdf;/home/kchou/HDD/Documents/Zotero Library/2307 1.html}
}

@online{zhang2025,
  title = {Your {{Fix Is My Exploit}}: {{Enabling Comprehensive DL Library API Fuzzing}} with {{Large Language Models}}},
  shorttitle = {Your {{Fix Is My Exploit}}},
  author = {Zhang, Kunpeng and Wang, Shuai and Han, Jitao and Zhu, Xiaogang and Li, Xian and Wang, Shaohua and Wen, Sheng},
  date = {2025-01-08},
  eprint = {2501.04312},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2501.04312},
  url = {http://arxiv.org/abs/2501.04312},
  abstract = {Deep learning (DL) libraries, widely used in AI applications, often contain vulnerabilities like buffer overflows and use-after-free errors. Traditional fuzzing struggles with the complexity and API diversity of DL libraries such as TensorFlow and PyTorch, which feature over 1,000 APIs. Testing all these APIs is challenging due to complex inputs and varied usage patterns. While large language models (LLMs) show promise in code understanding and generation, existing LLM-based fuzzers lack deep knowledge of API edge cases and struggle with test input generation. To address this, we propose DFUZZ, an LLM-driven fuzzing approach for DL libraries. DFUZZ leverages two insights: (1) LLMs can reason about error-triggering edge cases from API code and apply this knowledge to untested APIs, and (2) LLMs can accurately synthesize test programs to automate API testing. By providing LLMs with a "white-box view" of APIs, DFUZZ enhances reasoning and generation for comprehensive fuzzing. Experimental results show that DFUZZ outperforms state-of-the-art fuzzers in API coverage for TensorFlow and PyTorch, uncovering 37 bugs, with 8 fixed and 19 under developer investigation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Software Engineering,llm fuzzing},
  file = {/home/kchou/HDD/Library/References/Zhang et al. - 2025 - Your Fix Is My Exploit Enabling Comprehensive DL Library API Fuzzing with Large Language Models - @zhangYourFixMy2025.pdf;/home/kchou/HDD/Library/References/2501 2.html}
}

@online{zhao2024,
  title = {Retrieval {{Augmented Generation}} ({{RAG}}) and {{Beyond}}: {{A Comprehensive Survey}} on {{How}} to {{Make}} Your {{LLMs}} Use {{External Data More Wisely}}},
  shorttitle = {Retrieval {{Augmented Generation}} ({{RAG}}) and {{Beyond}}},
  author = {Zhao, Siyun and Yang, Yuqing and Wang, Zilong and He, Zhiyuan and Qiu, Luna K. and Qiu, Lili},
  date = {2024-09-23},
  eprint = {2409.14924},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.14924},
  url = {http://arxiv.org/abs/2409.14924},
  abstract = {Large language models (LLMs) augmented with external data have demonstrated remarkable capabilities in completing real-world tasks. Techniques for integrating external data into LLMs, such as Retrieval-Augmented Generation (RAG) and fine-tuning, are gaining increasing attention and widespread application. Nonetheless, the effective deployment of data-augmented LLMs across various specialized fields presents substantial challenges. These challenges encompass a wide range of issues, from retrieving relevant data and accurately interpreting user intent to fully harnessing the reasoning capabilities of LLMs for complex tasks. We believe that there is no one-size-fits-all solution for data-augmented LLM applications. In practice, underperformance often arises from a failure to correctly identify the core focus of a task or because the task inherently requires a blend of multiple capabilities that must be disentangled for better resolution. In this survey, we propose a RAG task categorization method, classifying user queries into four levels based on the type of external data required and primary focus of the task: explicit fact queries, implicit fact queries, interpretable rationale queries, and hidden rationale queries. We define these levels of queries, provide relevant datasets, and summarize the key challenges and most effective techniques for addressing these challenges. Finally, we discuss three main forms of integrating external data into LLMs: context, small model, and fine-tuning, highlighting their respective strengths, limitations, and the types of problems they are suited to solve. This work aims to help readers thoroughly understand and decompose the data requirements and key bottlenecks in building LLM applications, offering solutions to the different challenges and serving as a guide to systematically developing such applications.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/kchou/HDD/Library/References/Zhao et al. - 2024 - Retrieval Augmented Generation (RAG) and Beyond A Comprehensive Survey on How to Make your LLMs use - zhao2024.pdf;/home/kchou/HDD/Library/References/2409 2.html}
}

@online{zhong2024,
  title = {A {{Guide}} to {{Large Language Model Abstractions}}},
  author = {Zhong, Peter Yong and He, Haoze and Khattab, Omar and Potts, Christopher and Zaharia, Matei and Miller, Heather},
  date = {2024-01-16},
  url = {https://www.twosigma.com/articles/a-guide-to-large-language-model-abstractions/},
  abstract = {A map of frameworks for abstracting interactions with and between large language models, plus two systems of organization for reasoning about LLM approaches and philosophies.},
  langid = {american},
  organization = {Two Sigma},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-04-01T17:25:06.645Z},
  file = {/home/kchou/HDD/Library/References/a-guide-to-large-language-model-abstractions.html;/home/kchou/HDD/Library/References/a-guide-to-large-language-model-abstractions.html}
}

@online{zibaeirad2025,
  title = {Reasoning with {{LLMs}} for {{Zero-Shot Vulnerability Detection}}},
  author = {Zibaeirad, Arastoo and Vieira, Marco},
  date = {2025-03-22},
  eprint = {2503.17885},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2503.17885},
  url = {http://arxiv.org/abs/2503.17885},
  abstract = {Automating software vulnerability detection (SVD) remains a critical challenge in an era of increasingly complex and interdependent software systems. Despite significant advances in Large Language Models (LLMs) for code analysis, prevailing evaluation methodologies often lack the \textbackslash textbf\{context-aware robustness\} necessary to capture real-world intricacies and cross-component interactions. To address these limitations, we present \textbackslash textbf\{VulnSage\}, a comprehensive evaluation framework and a dataset curated from diverse, large-scale open-source system software projects developed in C/C++. Unlike prior datasets, it leverages a heuristic noise pre-filtering approach combined with LLM-based reasoning to ensure a representative and minimally noisy spectrum of vulnerabilities. The framework supports multi-granular analysis across function, file, and inter-function levels and employs four diverse zero-shot prompt strategies: Baseline, Chain-of-Thought, Think, and Think \& Verify. Through this evaluation, we uncover that structured reasoning prompts substantially improve LLM performance, with Think \& Verify reducing ambiguous responses from 20.3\% to 9.1\% while increasing accuracy. We further demonstrate that code-specialized models consistently outperform general-purpose alternatives, with performance varying significantly across vulnerability types, revealing that no single approach universally excels across all security contexts. Link to dataset and codes: https://github.com/Erroristotle/VulnSage.git},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering,llm fuzzing},
  annotation = {Read\_Status: In Progress\\
Read\_Status\_Date: 2025-05-06T12:01:14.135Z},
  file = {/home/kchou/HDD/Library/References/Zibaeirad and Vieira - 2025 - Reasoning with LLMs for Zero-Shot Vulnerability Detection - @zibaeiradReasoningLLMsZeroShot2025.pdf;/home/kchou/HDD/Library/References/2503 1.html}
}

@online{zotero-item-4182,
  title = {{{AI-Powered Fuzzing}}: {{Breaking}} the {{Bug Hunting Barrier}}},
  shorttitle = {{{AI-Powered Fuzzing}}},
  url = {https://security.googleblog.com/2023/08/ai-powered-fuzzing-breaking-bug-hunting.html},
  abstract = {Dongge Liu, Jonathan Metzman, Oliver Chang, Google Open Source Security Team~ Since 2016, OSS-Fuzz  has been at the forefront of automated v...},
  langid = {english},
  organization = {Google Online Security Blog},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-05-04T14:27:49.683Z},
  file = {/home/kchou/HDD/Library/References/ai-powered-fuzzing-breaking-bug-hunting.html}
}
