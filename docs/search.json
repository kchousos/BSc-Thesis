[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OverHAuL",
    "section": "",
    "text": "Preface\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.\nEtiam maximus accumsan gravida. Maecenas at nunc dignissim, euismod enim ac, bibendum ipsum. Maecenas vehicula velit in nisl aliquet ultricies. Nam eget massa interdum, maximus arcu vel, pretium erat. Maecenas sit amet tempor purus, vitae aliquet nunc. Vivamus cursus urna velit, eleifend dictum magna laoreet ut. Duis eu erat mollis, blandit magna id, tincidunt ipsum. Integer massa nibh, commodo eu ex vel, venenatis efficitur ligula. Integer convallis lacus elit, maximus eleifend lacus ornare ac. Vestibulum scelerisque viverra urna id lacinia. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget enim at diam bibendum tincidunt eu non purus. Nullam id magna ultrices, sodales metus viverra, tempus turpis.\n\n\n\nAcknowledgments\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\n\n\n\n\n\n\nCitation\n\n\n\nBibTeX citation:\n\n@thesis{chousosLLMDrivenFuzzing2025,\n  title = {LLM-Driven Fuzzing: Automatic Harness Generation for Crypto Libraries},\n  shorttitle = {LLM-Driven Fuzzing},\n  author = {Chousos, Konstantinos},\n  date = {2025-07},\n  institution = {{National and Kapodistrian University of Athens}},\n  location = {Athens, Greece},\n  url = {https://kchousos.github.io/thesis/},\n  langid = {en, el}\n}\n\nFor attribution, please cite this work as:\n\n\nK. Chousos, “LLM-Driven Fuzzing: Automatic Harness Generation for Crypto Libraries,” Bachelor Thesis, National and Kapodistrian University of Athens, Athens, Greece, 2025. [Online]. Available: https://kchousos.github.io/thesis/",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Motivation\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#preview-of-following-sections-rename",
    "href": "chapters/intro.html#preview-of-following-sections-rename",
    "title": "1  Introduction",
    "section": "1.2 Preview of following sections (rename)",
    "text": "1.2 Preview of following sections (rename)\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/background.html",
    "href": "chapters/background.html",
    "title": "2  Background",
    "section": "",
    "text": "2.1 Fuzzing\nWhat is fuzzing [1].\nWhy fuzz?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "chapters/background.html#fuzzing",
    "href": "chapters/background.html#fuzzing",
    "title": "2  Background",
    "section": "",
    "text": "2.1.1 Fuzzing examples\nHeartbleed [2], shellshock [3].\n\n\n2.1.2 Fuzzer engines\nC/C++: AFL [4] & AFL++ [4], ++. LibFuzzer [5].\nPython: Atheris [6].\nJava, Rust etc…\nAn example of a fuzz target/harness can be seen in Listing 2.1 [5].\n\n\n\nListing 2.1: A simple function that does something interesting if it receives the input “HI!”.\n\n\ncat &lt;&lt; EOF &gt; test_fuzzer.cc\n#include &lt;stdint.h&gt;\n#include &lt;stddef.h&gt;\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n  if (size &gt; 0 && data[0] == 'H')\n    if (size &gt; 1 && data[1] == 'I')\n       if (size &gt; 2 && data[2] == '!')\n       __builtin_trap();\n  return 0;\n}\nEOF\n# Build test_fuzzer.cc with asan and link against libFuzzer.\nclang++ -fsanitize=address,fuzzer test_fuzzer.cc\n# Run the fuzzer with no corpus.\n./a.out",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "chapters/background.html#large-language-models-llms",
    "href": "chapters/background.html#large-language-models-llms",
    "title": "2  Background",
    "section": "2.2 Large Language Models (LLMs)",
    "text": "2.2 Large Language Models (LLMs)\nTransformers [7], 2017–2025. ChatGPT/OpenAI history & context. Claude, Llama (1–3) etc.\n\n2.2.1 Prompting\nPrompting techniques.\n\nZero-shot.\nOne-shot.\nChain of Thought [8].\nReACt [9].\nTree of Thoughts [10].\n\nComparison, strengths weaknesses etc. [11].\n\n\n2.2.2 LLM Programming Libraries (?)\nLangchain & LangGraph, LlamaIndex [12], [13], [14]. DSPy [15].\nComparison, relevance to our usecase.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "chapters/background.html#neurosymbolic-ai",
    "href": "chapters/background.html#neurosymbolic-ai",
    "title": "2  Background",
    "section": "2.3 Neurosymbolic AI",
    "text": "2.3 Neurosymbolic AI\nTODO [16], [17], [18], [19], [20], [21].\n\n\n\n\n[1] V. J. M. Manes et al., “The Art, Science, and Engineering of Fuzzing: A Survey,” Apr. 07, 2019. doi: 10.48550/arXiv.1812.00140. Available: http://arxiv.org/abs/1812.00140\n\n\n[2] “Heartbleed Bug.” Available: https://heartbleed.com/\n\n\n[3] C. Meyer and J. Schwenk, “Lessons Learned From Previous SSL/TLS Attacks - A Brief Chronology Of Attacks And Weaknesses,” 2013. Available: https://eprint.iacr.org/2013/049\n\n\n[4] “American fuzzy lop.” Available: https://lcamtuf.coredump.cx/afl/\n\n\n[5] “libFuzzer – a library for coverage-guided fuzz testing. — LLVM 21.0.0git documentation.” Available: https://llvm.org/docs/LibFuzzer.html\n\n\n[6] “Google/atheris.” Google, Apr. 09, 2025. Available: https://github.com/google/atheris\n\n\n[7] A. Vaswani et al., “Attention Is All You Need,” Aug. 01, 2023. doi: 10.48550/arXiv.1706.03762. Available: http://arxiv.org/abs/1706.03762\n\n\n[8] J. Wei et al., “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,” Jan. 10, 2023. doi: 10.48550/arXiv.2201.11903. Available: http://arxiv.org/abs/2201.11903\n\n\n[9] S. Yao et al., “ReAct: Synergizing Reasoning and Acting in Language Models,” Mar. 10, 2023. doi: 10.48550/arXiv.2210.03629. Available: http://arxiv.org/abs/2210.03629\n\n\n[10] S. Yao et al., “Tree of Thoughts: Deliberate Problem Solving with Large Language Models,” Dec. 03, 2023. doi: 10.48550/arXiv.2305.10601. Available: http://arxiv.org/abs/2305.10601\n\n\n[11] P. Laban, H. Hayashi, Y. Zhou, and J. Neville, “LLMs Get Lost In Multi-Turn Conversation,” May 09, 2025. doi: 10.48550/arXiv.2505.06120. Available: http://arxiv.org/abs/2505.06120\n\n\n[12] H. Chase, “LangChain.” Oct. 2022. Available: https://github.com/langchain-ai/langchain\n\n\n[13] “Langchain-ai/langgraph.” LangChain, May 21, 2025. Available: https://github.com/langchain-ai/langgraph\n\n\n[14] J. Liu, “LlamaIndex.” Nov. 2022. doi: 10.5281/zenodo.1234. Available: https://github.com/jerryjliu/llama_index\n\n\n[15] O. Khattab et al., “DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines,” Oct. 05, 2023. doi: 10.48550/arXiv.2310.03714. Available: http://arxiv.org/abs/2310.03714\n\n\n[16] D. Ganguly, S. Iyengar, V. Chaudhary, and S. Kalyanaraman, “Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning,” Sep. 25, 2024. doi: 10.48550/arXiv.2409.17270. Available: http://arxiv.org/abs/2409.17270\n\n\n[17] A. d’Avila Garcez and L. C. Lamb, “Neurosymbolic AI: The 3rd Wave,” Dec. 16, 2020. doi: 10.48550/arXiv.2012.05876. Available: http://arxiv.org/abs/2012.05876\n\n\n[18] M. Gaur and A. Sheth, “Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety,” Dec. 05, 2023. doi: 10.48550/arXiv.2312.06798. Available: http://arxiv.org/abs/2312.06798\n\n\n[19] G. Grov, J. Halvorsen, M. W. Eckhoff, B. J. Hansen, M. Eian, and V. Mavroeidis, “On the use of neurosymbolic AI for defending against cyber attacks,” Aug. 09, 2024. doi: 10.48550/arXiv.2408.04996. Available: http://arxiv.org/abs/2408.04996\n\n\n[20] A. Sheth, K. Roy, and M. Gaur, “Neurosymbolic AI – Why, What, and How,” May 01, 2023. doi: 10.48550/arXiv.2305.00813. Available: http://arxiv.org/abs/2305.00813\n\n\n[21] D. Tilwani, R. Venkataramanan, and A. P. Sheth, “Neurosymbolic AI approach to Attribution in Large Language Models,” Sep. 30, 2024. doi: 10.48550/arXiv.2410.03726. Available: http://arxiv.org/abs/2410.03726",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "chapters/related-work.html",
    "href": "chapters/related-work.html",
    "title": "3  Related work",
    "section": "",
    "text": "3.1 Automatic Harnesses\nWhere we are right now. SOTA projects. Similar projects using LLMs in the fuzzing space [1], [2], [3].\nTODO",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Related work</span>"
    ]
  },
  {
    "objectID": "chapters/related-work.html#google",
    "href": "chapters/related-work.html#google",
    "title": "3  Related work",
    "section": "3.2 Google",
    "text": "3.2 Google\nFuzzGen, FUDGE, OSS-Fuzz-Gen [4], [5], [6], [7].\n\n3.2.1 OSS-Fuzz-Gen\nFeatures/caveats. from_scratch branch1.\n\n\ncommit 171aac2↩︎\n\n\n\n\n\n\n[1] Y. Deng, C. S. Xia, C. Yang, S. D. Zhang, S. Yang, and L. Zhang, “Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT,” Apr. 04, 2023. doi: 10.48550/arXiv.2304.02014. Available: http://arxiv.org/abs/2304.02014\n\n\n[2] Y. Deng, C. S. Xia, H. Peng, C. Yang, and L. Zhang, “Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models,” in Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis, in ISSTA 2023. New York, NY, USA: Association for Computing Machinery, Jul. 2023, pp. 423–435. doi: 10.1145/3597926.3598067. Available: https://dl.acm.org/doi/10.1145/3597926.3598067\n\n\n[3] Z. Li, S. Dutta, and M. Naik, “IRIS: LLM-Assisted Static Analysis for Detecting Security Vulnerabilities,” Apr. 06, 2025. doi: 10.48550/arXiv.2405.17238. Available: http://arxiv.org/abs/2405.17238\n\n\n[4] K. Ispoglou, D. Austin, V. Mohan, and M. Payer, “FuzzGen: Automatic fuzzer generation,” in 29th USENIX Security Symposium (USENIX Security 20), 2020, pp. 2271–2287. Available: https://www.usenix.org/conference/usenixsecurity20/presentation/ispoglou\n\n\n[5] D. Babić et al., “FUDGE: Fuzz driver generation at scale,” in Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Tallinn Estonia: ACM, Aug. 2019, pp. 975–985. doi: 10.1145/3338906.3340456. Available: https://dl.acm.org/doi/10.1145/3338906.3340456\n\n\n[6] A. Arya, O. Chang, J. Metzman, K. Serebryany, and D. Liu, “OSS-Fuzz.” Apr. 08, 2025. Available: https://github.com/google/oss-fuzz\n\n\n[7] D. Liu, O. Chang, J. metzman, M. Sablotny, and M. Maruseac, “OSS-fuzz-gen: Automated fuzz target generation.” May 2024. Available: https://github.com/google/oss-fuzz-gen",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Related work</span>"
    ]
  },
  {
    "objectID": "chapters/overview.html",
    "href": "chapters/overview.html",
    "title": "4  Overview",
    "section": "",
    "text": "4.1 Architecture",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "chapters/overview.html#architecture",
    "href": "chapters/overview.html#architecture",
    "title": "4  Overview",
    "section": "",
    "text": "System diagram\nMain Library Architecture/Structure\nLLM usage\n\nPrompting techniques used (callback to Section 2.2.1).\n\nStatic analysis\nCode localization(?)\nFuzzers\nGitHub Workflow/Usage",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "chapters/implementation.html",
    "href": "chapters/implementation.html",
    "title": "5  Implementation",
    "section": "",
    "text": "Tools\nLibraries",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Implementation</span>"
    ]
  },
  {
    "objectID": "chapters/evaluation.html",
    "href": "chapters/evaluation.html",
    "title": "6  Evaluation",
    "section": "",
    "text": "6.1 Benchmarks\nResults from integration with 10/100 open-source C/C++ projects.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chapters/evaluation.html#performance",
    "href": "chapters/evaluation.html#performance",
    "title": "6  Evaluation",
    "section": "6.2 Performance",
    "text": "6.2 Performance",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chapters/evaluation.html#issues",
    "href": "chapters/evaluation.html#issues",
    "title": "6  Evaluation",
    "section": "6.3 Issues",
    "text": "6.3 Issues",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chapters/evaluation.html#future-work",
    "href": "chapters/evaluation.html#future-work",
    "title": "6  Evaluation",
    "section": "6.4 Future work",
    "text": "6.4 Future work\n\n6.4.1 Technical future work\n\n\n6.4.2 Architectural future work/extensions\n\nBuild system\nMore (static) analysis tolls integrations\nGeneral localization problem",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chapters/conclusion.html",
    "href": "chapters/conclusion.html",
    "title": "7  Conclusion",
    "section": "",
    "text": "7.1 Acknowledgements\nRecap\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/refs.html",
    "href": "chapters/refs.html",
    "title": "Bibliography",
    "section": "",
    "text": "[1] “American fuzzy lop.” Available:\nhttps://lcamtuf.coredump.cx/afl/\n\n\n[2] “Google/atheris.” Google, Apr. 09,\n2025. Available: https://github.com/google/atheris\n\n\n[3] J.\nWei et al., “Chain-of-Thought Prompting Elicits\nReasoning in Large Language Models,” Jan. 10,\n2023. doi: 10.48550/arXiv.2201.11903.\nAvailable: http://arxiv.org/abs/2201.11903\n\n\n[4] O.\nKhattab et al., “DSPy: Compiling\nDeclarative Language Model Calls into Self-Improving\nPipelines,” Oct. 05, 2023. doi: 10.48550/arXiv.2310.03714.\nAvailable: http://arxiv.org/abs/2310.03714\n\n\n[5] D.\nBabić et al., “FUDGE: Fuzz driver generation\nat scale,” in Proceedings of the 2019 27th ACM Joint\nMeeting on European Software Engineering Conference\nand Symposium on the Foundations of\nSoftware Engineering, Tallinn Estonia: ACM, Aug. 2019,\npp. 975–985. doi: 10.1145/3338906.3340456.\nAvailable: https://dl.acm.org/doi/10.1145/3338906.3340456\n\n\n[6] K.\nIspoglou, D. Austin, V. Mohan, and M. Payer,\n“FuzzGen: Automatic fuzzer\ngeneration,” in 29th USENIX Security Symposium\n(USENIX Security 20), 2020, pp. 2271–2287. Available:\nhttps://www.usenix.org/conference/usenixsecurity20/presentation/ispoglou\n\n\n[7] Y.\nDeng, C. S. Xia, C. Yang, S. D. Zhang, S. Yang, and L. Zhang,\n“Large Language Models are Edge-Case\nFuzzers: Testing Deep Learning Libraries via\nFuzzGPT,” Apr. 04, 2023. doi: 10.48550/arXiv.2304.02014.\nAvailable: http://arxiv.org/abs/2304.02014\n\n\n[8] D.\nGanguly, S. Iyengar, V. Chaudhary, and S. Kalyanaraman, “Proof of\nThought : Neurosymbolic Program Synthesis\nallows Robust and Interpretable\nReasoning,” Sep. 25, 2024. doi: 10.48550/arXiv.2409.17270.\nAvailable: http://arxiv.org/abs/2409.17270\n\n\n[9] A.\nd’Avila Garcez and L. C. Lamb, “Neurosymbolic AI:\nThe 3rd Wave,” Dec. 16, 2020. doi: 10.48550/arXiv.2012.05876.\nAvailable: http://arxiv.org/abs/2012.05876\n\n\n[10] M.\nGaur and A. Sheth, “Building Trustworthy NeuroSymbolic AI\nSystems: Consistency, Reliability,\nExplainability, and Safety,” Dec. 05,\n2023. doi: 10.48550/arXiv.2312.06798.\nAvailable: http://arxiv.org/abs/2312.06798\n\n\n[11] G.\nGrov, J. Halvorsen, M. W. Eckhoff, B. J. Hansen, M. Eian, and V.\nMavroeidis, “On the use of neurosymbolic AI for\ndefending against cyber attacks,” Aug. 09, 2024. doi: 10.48550/arXiv.2408.04996.\nAvailable: http://arxiv.org/abs/2408.04996\n\n\n[12] “Heartbleed Bug.”\nAvailable: https://heartbleed.com/\n\n\n[13] Z.\nLi, S. Dutta, and M. Naik, “IRIS: LLM-Assisted\nStatic Analysis for Detecting Security\nVulnerabilities,” Apr. 06, 2025. doi: 10.48550/arXiv.2405.17238.\nAvailable: http://arxiv.org/abs/2405.17238\n\n\n[14] P.\nLaban, H. Hayashi, Y. Zhou, and J. Neville, “LLMs Get Lost\nIn Multi-Turn Conversation,” May 09, 2025. doi: 10.48550/arXiv.2505.06120.\nAvailable: http://arxiv.org/abs/2505.06120\n\n\n[15] H.\nChase, “LangChain.” Oct. 2022. Available: https://github.com/langchain-ai/langchain\n\n\n[16] “Langchain-ai/langgraph.”\nLangChain, May 21, 2025. Available: https://github.com/langchain-ai/langgraph\n\n\n[17] “libFuzzer –\na library for coverage-guided fuzz testing. — LLVM\n21.0.0git documentation.” Available: https://llvm.org/docs/LibFuzzer.html\n\n\n[18] J.\nLiu, “LlamaIndex.” Nov. 2022. doi: 10.5281/zenodo.1234.\nAvailable: https://github.com/jerryjliu/llama_index\n\n\n[19] V.\nJ. M. Manes et al., “The Art,\nScience, and Engineering of\nFuzzing: A Survey,” Apr. 07, 2019. doi:\n10.48550/arXiv.1812.00140.\nAvailable: http://arxiv.org/abs/1812.00140\n\n\n[20] C.\nMeyer and J. Schwenk, “Lessons Learned From Previous\nSSL/TLS Attacks - A Brief Chronology Of\nAttacks And Weaknesses,” 2013. Available: https://eprint.iacr.org/2013/049\n\n\n[21] A.\nArya, O. Chang, J. Metzman, K. Serebryany, and D. Liu,\n“OSS-Fuzz.” Apr. 08, 2025. Available: https://github.com/google/oss-fuzz\n\n\n[22] D.\nLiu, O. Chang, J. metzman, M. Sablotny, and M. Maruseac, “OSS-fuzz-gen: Automated fuzz target\ngeneration.” May 2024. Available: https://github.com/google/oss-fuzz-gen\n\n\n[23] S.\nYao et al., “ReAct: Synergizing\nReasoning and Acting in Language\nModels,” Mar. 10, 2023. doi: 10.48550/arXiv.2210.03629.\nAvailable: http://arxiv.org/abs/2210.03629\n\n\n[24] A.\nSheth, K. Roy, and M. Gaur, “Neurosymbolic AI –\nWhy, What, and How,” May\n01, 2023. doi: 10.48550/arXiv.2305.00813.\nAvailable: http://arxiv.org/abs/2305.00813\n\n\n[25] D.\nTilwani, R. Venkataramanan, and A. P. Sheth, “Neurosymbolic\nAI approach to Attribution in Large\nLanguage Models,” Sep. 30, 2024. doi: 10.48550/arXiv.2410.03726.\nAvailable: http://arxiv.org/abs/2410.03726\n\n\n[26] Y.\nDeng, C. S. Xia, H. Peng, C. Yang, and L. Zhang, “Large\nLanguage Models Are Zero-Shot Fuzzers: Fuzzing\nDeep-Learning Libraries via Large Language\nModels,” in Proceedings of the 32nd ACM SIGSOFT\nInternational Symposium on Software Testing and\nAnalysis, in ISSTA 2023. New York, NY,\nUSA: Association for Computing Machinery, Jul. 2023, pp. 423–435. doi:\n10.1145/3597926.3598067.\nAvailable: https://dl.acm.org/doi/10.1145/3597926.3598067\n\n\n[27] A.\nVaswani et al., “Attention Is All You\nNeed,” Aug. 01, 2023. doi: 10.48550/arXiv.1706.03762.\nAvailable: http://arxiv.org/abs/1706.03762\n\n\n[28] S.\nYao et al., “Tree of Thoughts:\nDeliberate Problem Solving with Large Language\nModels,” Dec. 03, 2023. doi: 10.48550/arXiv.2305.10601.\nAvailable: http://arxiv.org/abs/2305.10601",
    "crumbs": [
      "Bibliography"
    ]
  },
  {
    "objectID": "chapters/appendix.html",
    "href": "chapters/appendix.html",
    "title": "Appendix A — Failed Techniques",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nNunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.\nEtiam maximus accumsan gravida. Maecenas at nunc dignissim, euismod enim ac, bibendum ipsum. Maecenas vehicula velit in nisl aliquet ultricies. Nam eget massa interdum, maximus arcu vel, pretium erat. Maecenas sit amet tempor purus, vitae aliquet nunc. Vivamus cursus urna velit, eleifend dictum magna laoreet ut. Duis eu erat mollis, blandit magna id, tincidunt ipsum. Integer massa nibh, commodo eu ex vel, venenatis efficitur ligula. Integer convallis lacus elit, maximus eleifend lacus ornare ac. Vestibulum scelerisque viverra urna id lacinia. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget enim at diam bibendum tincidunt eu non purus. Nullam id magna ultrices, sodales metus viverra, tempus turpis.\nDuis ornare ex ac iaculis pretium. Maecenas sagittis odio id erat pharetra, sit amet consectetur quam sollicitudin. Vivamus pharetra quam purus, nec sagittis risus pretium at. Nullam feugiat, turpis ac accumsan interdum, sem tellus blandit neque, id vulputate diam quam semper nisl. Donec sit amet enim at neque porttitor aliquet. Phasellus facilisis nulla eget placerat eleifend. Vestibulum non egestas eros, eget lobortis ipsum. Nulla rutrum massa eget enim aliquam, id porttitor erat luctus. Nunc sagittis quis eros eu sagittis. Pellentesque dictum, erat at pellentesque sollicitudin, justo augue pulvinar metus, quis rutrum est mi nec felis. Vestibulum efficitur mi lorem, at elementum purus tincidunt a. Aliquam finibus enim magna, vitae pellentesque erat faucibus at. Nulla mauris tellus, imperdiet id lobortis et, dignissim condimentum ipsum. Morbi nulla orci, varius at aliquet sed, facilisis id tortor. Donec ut urna nisi.\nAenean placerat luctus tortor vitae molestie. Nulla at aliquet nulla. Sed efficitur tellus orci, sed fringilla lectus laoreet eget. Vivamus maximus quam sit amet arcu dignissim, sed accumsan massa ullamcorper. Sed iaculis tincidunt feugiat. Nulla in est at nunc ultricies dictum ut vitae nunc. Aenean convallis vel diam at malesuada. Suspendisse arcu libero, vehicula tempus ultrices a, placerat sit amet tortor. Sed dictum id nulla commodo mattis. Aliquam mollis, nunc eu tristique faucibus, purus lacus tincidunt nulla, ac pretium lorem nunc ut enim. Curabitur eget mattis nisl, vitae sodales augue. Nam felis massa, bibendum sit amet nulla vel, vulputate rutrum lacus. Aenean convallis odio pharetra nulla mattis consequat.\nUt ut condimentum augue, nec eleifend nisl. Sed facilisis egestas odio ac pretium. Pellentesque consequat magna sed venenatis sagittis. Vivamus feugiat lobortis magna vitae accumsan. Pellentesque euismod malesuada hendrerit. Ut non mauris non arcu condimentum sodales vitae vitae dolor. Nullam dapibus, velit eget lacinia rutrum, ipsum justo malesuada odio, et lobortis sapien magna vel lacus. Nulla purus neque, hendrerit non malesuada eget, mattis vel erat. Suspendisse potenti.\nNullam dapibus cursus dolor sit amet consequat. Nulla facilisi. Curabitur vel nulla non magna lacinia tincidunt. Duis porttitor quam leo, et blandit velit efficitur ut. Etiam auctor tincidunt porttitor. Phasellus sed accumsan mi. Fusce ut erat dui. Suspendisse eu augue eget turpis condimentum finibus eu non lorem. Donec finibus eros eu ante condimentum, sed pharetra sapien sagittis. Phasellus non dolor ac ante mollis auctor nec et sapien. Pellentesque vulputate at nisi eu tincidunt. Vestibulum at dolor aliquam, hendrerit purus eu, eleifend massa. Morbi consectetur eros id tincidunt gravida. Fusce ut enim quis orci hendrerit lacinia sed vitae enim.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Failed Techniques</span>"
    ]
  }
]