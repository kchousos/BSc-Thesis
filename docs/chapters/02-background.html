<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Background – OverHAuL</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/03-related.html" rel="next">
<link href="../chapters/01-intro.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-fc28e9b749f75a4a381771fbe9d42b43.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-450b7d896efee5edec3f767475d1ea0a.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-fc28e9b749f75a4a381771fbe9d42b43.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-59deb8712cfd670027f81299959788f9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-3fc190bb73c398b54bbb1660cc7262c8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-59deb8712cfd670027f81299959788f9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script src="../site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://tinylytics.app/embed/rSbhZ_sMtsVibUKrZtZ2/min.js" defer=""></script>
<script>
MathJax = {
  loader: {
    load: ['[tex]/boldsymbol']
  },
  tex: {
    tags: "all",
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    packages: {
      '[+]': ['boldsymbol']
    }
  }
};
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>


</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/02-background.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Background</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">OverHAuL</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/kchousos/BSc-Thesis/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../thesis.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-background.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Background</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-related.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Related work</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-overhaul.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">OverHAuL’s Design</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05-evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Evaluation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Results</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-implementation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Implementation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/08-discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/09-future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Future Work</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10-conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/refs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/abandoned.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Abandoned Techniques</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/prompts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">DSPy Custom Signatures</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#fuzz-testing" id="toc-fuzz-testing" class="nav-link active" data-scroll-target="#fuzz-testing"><span class="header-section-number">2.1</span> Fuzz Testing</a>
  <ul class="collapse">
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation"><span class="header-section-number">2.1.1</span> Motivation</a></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology"><span class="header-section-number">2.1.2</span> Methodology</a></li>
  <li><a href="#challenges-in-adoption" id="toc-challenges-in-adoption" class="nav-link" data-scroll-target="#challenges-in-adoption"><span class="header-section-number">2.1.3</span> Challenges in Adoption</a></li>
  </ul></li>
  <li><a href="#large-language-models" id="toc-large-language-models" class="nav-link" data-scroll-target="#large-language-models"><span class="header-section-number">2.2</span> Large Language Models</a>
  <ul class="collapse">
  <li><a href="#biggest-gpts" id="toc-biggest-gpts" class="nav-link" data-scroll-target="#biggest-gpts"><span class="header-section-number">2.2.1</span> Biggest GPTs</a></li>
  <li><a href="#sec-prompting" id="toc-sec-prompting" class="nav-link" data-scroll-target="#sec-prompting"><span class="header-section-number">2.2.2</span> Prompting</a></li>
  <li><a href="#sec-llm-coding" id="toc-sec-llm-coding" class="nav-link" data-scroll-target="#sec-llm-coding"><span class="header-section-number">2.2.3</span> LLMs for Coding</a></li>
  <li><a href="#llms-for-fuzzing" id="toc-llms-for-fuzzing" class="nav-link" data-scroll-target="#llms-for-fuzzing"><span class="header-section-number">2.2.4</span> LLMs for Fuzzing</a></li>
  </ul></li>
  <li><a href="#sec-nesy" id="toc-sec-nesy" class="nav-link" data-scroll-target="#sec-nesy"><span class="header-section-number">2.3</span> Neurosymbolic AI</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-background" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Background</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This chapter provides the foundational and necessary background for this thesis by exploring the core concepts and technological advances central to modern fuzzing and Large Language Models (LLMs). It begins with an in-depth overview of fuzz testing, an automated technique for uncovering software bugs and vulnerabilities through randomized input generation, highlighting its methodology, tools, and impact. What follows is a discussion on LLMs and their transformative influence on natural language processing, programming, and code generation. Challenges and opportunities in applying LLMs to tasks such as fuzzing harness generation are examined, leading to a discussion of Neurosymbolic AI, an emerging approach that combines neural and symbolic reasoning to address the limitations of current AI systems. This multifaceted background establishes the context necessary for understanding the research and innovations presented in subsequent chapters.</p>
<section id="fuzz-testing" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="fuzz-testing"><span class="header-section-number">2.1</span> Fuzz Testing</h2>
<p><em>Fuzzing</em> is an automated software-testing technique in which a <em>Program Under Test</em> (PUT) is executed with (pseudo-)random inputs in the hope of exposing undefined behavior. When such behavior manifests as a crash, hang, or memory-safety violation, the corresponding input constitutes a <em>test-case</em> that reveals a bug and often a vulnerability <span class="citation" data-cites="manes2019"><a href="refs.html#ref-manes2019" role="doc-biblioref">[1]</a></span>. In essence, fuzzing is a form of adversarial, penetration-style testing carried out by the defender before the adversary has an opportunity to do so. Interest in the technique surged after the publication of three practitioner-oriented books in 2007–2008 <span class="citation" data-cites="takanen2018 sutton2007 rathaus2007"><a href="refs.html#ref-takanen2018" role="doc-biblioref">[2]</a>, <a href="refs.html#ref-sutton2007" role="doc-biblioref">[3]</a>, <a href="refs.html#ref-rathaus2007" role="doc-biblioref">[4]</a></span>.</p>
<p>Historically, the term was coined by Miller et al.&nbsp;in 1990, who used “fuzz” to describe a program that “generates a stream of random characters to be consumed by a target program” <span class="citation" data-cites="miller1990"><a href="refs.html#ref-miller1990" role="doc-biblioref">[5]</a></span>. This informal usage captured the essence of what fuzzing aims to do: stress test software by bombarding it with unexpected inputs to reveal bugs. To formalize this concept, we adopt Manes et al.’s rigorous definitions <span class="citation" data-cites="manes2019"><a href="refs.html#ref-manes2019" role="doc-biblioref">[1]</a></span>:</p>
<div id="def-fuzzing" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.1 (Fuzzing)</strong></span> Fuzzing is the execution of a Program Under Test (PUT) using input(s) sampled from an input space (the <em>fuzz input space</em>) that protrudes the expected input space of the PUT.</p>
</div>
<p>This means fuzzing involves running the target program on inputs that go beyond those it is typically designed to handle, aiming to uncover hidden issues. An individual instance of such execution—or a bounded sequence thereof—is called a <em>fuzzing run</em>. When these runs are conducted systematically and at scale with the specific goal of detecting violations of a security policy, the activity is known as <em>fuzz testing</em> (or simply <em>fuzzing</em>):</p>
<div id="def-fuzz-testing" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.2 (Fuzz Testing)</strong></span> Fuzz testing is the use of fuzzing to test whether a PUT violates a security policy.</p>
</div>
<p>This distinction highlights that fuzz testing is fuzzing with an explicit focus on security properties and policy enforcement. Central to managing this process is the <em>fuzzer engine</em>, which orchestrates the execution of one or more fuzzing runs as part of a <em>fuzz campaign</em>. A fuzz campaign represents a concrete instance of fuzz testing tailored to a particular program and security policy:</p>
<div id="def-fuzzer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.3 (Fuzzer, Fuzzer Engine)</strong></span> A fuzzer is a program that performs fuzz testing on a PUT.</p>
</div>
<div id="def-campaign" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.4 (Fuzz Campaign)</strong></span> A fuzz campaign is a specific execution of a fuzzer on a PUT with a specific security policy.</p>
</div>
<p>Throughout each execution within a campaign, a <em>bug oracle</em> plays a critical role in evaluating the program’s behavior to determine whether it violates the defined security policy:</p>
<div id="def-oracle" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.5 (Bug Oracle)</strong></span> A bug oracle is a component (often inside the fuzzer) that determines whether a given execution of the PUT violates a specific security policy.</p>
</div>
<p>In practice, bug oracles often rely on runtime instrumentation techniques, such as monitoring for fatal POSIX signals (e.g., <code>SIGSEGV</code>) or using sanitizers like AddressSanitizer (ASan) <span class="citation" data-cites="serebryany2012"><a href="refs.html#ref-serebryany2012" role="doc-biblioref">[6]</a></span>. Tools like LibFuzzer <span class="citation" data-cites="libfuzzer"><a href="refs.html#ref-libfuzzer" role="doc-biblioref">[7]</a></span> commonly incorporate such instrumentation to reliably identify crashes or memory errors during fuzzing.</p>
<p>Most fuzz campaigns begin with a set of <em>seeds</em>—inputs that are well-formed and belong to the PUT’s expected input space—called a <em>seed corpus</em>. These seeds serve as starting points from which the fuzzer generates new test cases by applying transformations or mutations, thereby exploring a broader input space:</p>
<div id="def-seed" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.6 (Seed)</strong></span> An input given to the PUT that is mutated by the fuzzer to produce new test cases. During a fuzz campaign (<a href="#def-campaign" class="quarto-xref">Definition&nbsp;<span>2.4</span></a>) all seeds are stored in a seed <em>pool</em> or <em>corpus</em>.</p>
</div>
<p>The process of selecting an effective initial corpus is crucial because it directly impacts how quickly and thoroughly the fuzzer can cover the target program’s code. This challenge—studied as the <em>seed-selection problem</em>—involves identifying seeds that enable rapid discovery of diverse execution paths and is non-trivial <span class="citation" data-cites="rebert2014"><a href="refs.html#ref-rebert2014" role="doc-biblioref">[8]</a></span>. A well-chosen seed set often accelerates bug discovery and improves overall fuzzing efficiency.</p>
<!-- ### Taxonomies of Fuzzing -->
<!-- To better understand fuzzers, researchers traditionally classify them along two orthogonal axes: the level of knowledge about the PUT that they possess, and the strategy they use to generate test inputs. -->
<!-- #### Knowledge of the PUT {.unnumbered} -->
<!-- Fuzzers differ in how much information they leverage about the program under test: -->
<!-- ::: {#def-blackbox} -->
<!-- ###### Black-box fuzzer -->
<!-- Operates solely on program binaries, with no knowledge of internal structure; input generation is guided only by external observations. -->
<!-- ::: -->
<!-- Black-box fuzzers treat the PUT as a black box, generating inputs without insights into program internals. This makes them simple but often less efficient in uncovering deep bugs. -->
<!-- ::: {#def-greybox} -->
<!-- ###### Grey-box fuzzer -->
<!-- Gains limited insight---typically lightweight coverage metrics---via instrumentation, allowing more informed mutations while retaining scalability. -->
<!-- ::: -->
<!-- Grey-box fuzzers strike a balance by collecting partial information, such as execution coverage via lightweight instrumentation, enabling more targeted input mutations that improve effectiveness. -->
<!-- ::: {#def-whitebox} -->
<!-- ###### White-box fuzzer -->
<!-- Has full source-level visibility and employs heavy program analysis (symbolic execution, constraint solving, etc.) to systematically enumerate paths. -->
<!-- ::: -->
<!-- White-box fuzzers exploit full program knowledge, using advanced techniques like symbolic execution to methodically explore program paths, but often at the cost of reduced scalability. -->
<!-- #### Test-case Generation Strategy {.unnumbered} -->
<!-- The second axis concerns how fuzzers generate test inputs: -->
<!-- ::: {#def-generational} -->
<!-- ###### Generational fuzzing -->
<!-- Produces inputs from a structural model or protocol description, ensuring that test-cases are syntactically valid yet semantically diverse. -->
<!-- ::: -->
<!-- Generational fuzzing leverages knowledge of input formats (e.g., a BNF grammar [@backus1959]) to produce well-formed test cases derived from formal specifications or models, improving the likelihood of meaningful program behavior. -->
<!-- ::: {#def-mutational} -->
<!-- ###### Mutational fuzzing -->
<!-- Starts from existing seeds and applies stochastic mutations (bit-flips, block insertions, splice operations). Coverage-guided mutational fuzzers such as AFL have proved especially effective. -->
<!-- ::: -->
<!-- Mutational fuzzing begins with seeds and applies random or guided mutations to explore nearby input space regions. Techniques like coverage-guided fuzzing have greatly enhanced the efficiency of this approach. -->
<!-- These two dimensions are often combined to tailor fuzzers to specific scenarios. For example, AFL [@afl] is a grey-box, mutational fuzzer that uses coverage feedback to guide input mutations, while Honggfuzz [@honggfuzz] can operate as a grey-box generational fuzzer when provided with grammar-based input models. This flexibility allows fuzzers to adapt to varied testing goals and program characteristics. -->
<section id="motivation" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="motivation"><span class="header-section-number">2.1.1</span> Motivation</h3>
<blockquote class="blockquote">
<p>The purpose of fuzzing relies on the assumption that there are bugs within every program, which are waiting to be discovered. Therefore, a systematic approach should find them sooner or later.</p>
<p>— OWASP Foundation <span class="citation" data-cites="owaspfoundation"><a href="refs.html#ref-owaspfoundation" role="doc-biblioref">[9]</a></span></p>
</blockquote>
<p>Fuzz testing offers several tangible benefits:</p>
<ol type="1">
<li><strong>Early vulnerability discovery</strong>: Detecting defects during development is cheaper and safer than addressing exploits in production.</li>
<li><strong>Adversary-parity</strong>: Performing the same randomised stress that attackers employ allows defenders to pre-empt zero-days.</li>
<li><strong>Robustness and correctness</strong>: Beyond security, fuzzing exposes logic errors and stability issues in complex, high-throughput APIs (e.g., decompressors) even when inputs are <em>expected</em> to be well-formed.</li>
<li><strong>Regression prevention</strong>: Re-running a corpus of crashing inputs as part of continuous integration ensures that fixed bugs remain fixed.</li>
</ol>
<section id="success-stories" class="level4" data-number="2.1.1.1">
<h4 data-number="2.1.1.1" class="anchored" data-anchor-id="success-stories"><span class="header-section-number">2.1.1.1</span> Success Stories</h4>
<p><em>Heartbleed</em> (CVE-2014-0160) <span class="citation" data-cites="heartbleed heartbleed-cve"><a href="refs.html#ref-heartbleed" role="doc-biblioref">[10]</a>, <a href="refs.html#ref-heartbleed-cve" role="doc-biblioref">[11]</a></span> arose from a buffer over-read<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> in OpenSSL <span class="citation" data-cites="theopensslproject2025"><a href="refs.html#ref-theopensslproject2025" role="doc-biblioref">[12]</a></span> introduced on 1 February 2012 and unnoticed until 1 April 2014. Post-mortem analyses showed that a simple fuzz campaign exercising the TLS heartbeat extension would have revealed the defect almost immediately <span class="citation" data-cites="wheeler2014"><a href="refs.html#ref-wheeler2014" role="doc-biblioref">[13]</a></span>.</p>
<aside id="footnotes" class="footnotes footnotes-end-of-block" role="doc-footnote">
<ol>
<li id="fn1"><p><a href="https://xkcd.com/1354/" class="uri">https://xkcd.com/1354/</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
<p>Likewise, the <em>Shellshock</em> (or <em>Bashdoor</em>) family of bugs in GNU Bash <span class="citation" data-cites="bash"><a href="refs.html#ref-bash" role="doc-biblioref">[14]</a></span> enabled arbitrary command execution on many UNIX systems. While the initial flaw was fixed promptly, subsequent bug variants were discovered by Google’s Michał Zalewski using his own fuzzer <span class="citation" data-cites="afl"><a href="refs.html#ref-afl" role="doc-biblioref">[15]</a></span> in late 2014 <span class="citation" data-cites="saarinen2014"><a href="refs.html#ref-saarinen2014" role="doc-biblioref">[16]</a></span>.</p>
<p>On the defensive tooling side, the security tool named <em>Mayhem</em>—developed by the company of the same name—has since been adopted by the US Air Force, the Pentagon, Cloudflare, and numerous open-source communities. It has found and facilitated the remediation of thousands of previously unknown vulnerabilities <span class="citation" data-cites="simonite2020mayhem"><a href="refs.html#ref-simonite2020mayhem" role="doc-biblioref">[17]</a></span>.</p>
<p>These cases underscore the central thesis of fuzz testing: exhaustive manual review is infeasible, but scalable stochastic exploration reliably surfaces the critical few defects that matter most.</p>
</section>
</section>
<section id="methodology" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="methodology"><span class="header-section-number">2.1.2</span> Methodology</h3>
<p>As previously discussed, fuzz testing of a program under test (PUT) is typically conducted using a dedicated fuzzing engine (see <a href="#def-fuzzer" class="quarto-xref">Definition&nbsp;<span>2.3</span></a>). Among the most widely adopted fuzzers for C and C++ projects and libraries are AFL <span class="citation" data-cites="afl"><a href="refs.html#ref-afl" role="doc-biblioref">[15]</a></span>—which has since evolved into AFL++ <span class="citation" data-cites="aflpp"><a href="refs.html#ref-aflpp" role="doc-biblioref">[18]</a></span>—and LibFuzzer <span class="citation" data-cites="libfuzzer"><a href="refs.html#ref-libfuzzer" role="doc-biblioref">[7]</a></span>. Within the OverHAuL framework, LibFuzzer is preferred owing to its superior suitability for library fuzzing, whereas AFL++ predominantly targets executables and binary fuzzing.</p>
<section id="libfuzzer" class="level4" data-number="2.1.2.1">
<h4 data-number="2.1.2.1" class="anchored" data-anchor-id="libfuzzer"><span class="header-section-number">2.1.2.1</span> LibFuzzer</h4>
<p>LibFuzzer <span class="citation" data-cites="libfuzzer"><a href="refs.html#ref-libfuzzer" role="doc-biblioref">[7]</a></span> is an in-process, coverage-guided evolutionary fuzzing engine primarily designed for testing libraries. It forms part of the LLVM ecosystem <span class="citation" data-cites="llvm"><a href="refs.html#ref-llvm" role="doc-biblioref">[19]</a></span> and operates by linking directly with the library under evaluation. The fuzzer delivers mutated input data to the library through a designated fuzzing entry point, commonly referred to as the <em>fuzz target</em>.</p>
<div id="def-target" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2.7 (Fuzz target)</strong></span> A function that accepts a byte array as input and exercises the application programming interface (API) under test using these inputs <span class="citation" data-cites="libfuzzer"><a href="refs.html#ref-libfuzzer" role="doc-biblioref">[7]</a></span>. This construct is also known as a <em>fuzz driver</em>, <em>fuzzer entry point</em>, or <em>fuzzing harness</em>.</p>
</div>
<p>For the remainder of this thesis, the terms presented in <a href="#def-target" class="quarto-xref">Definition&nbsp;<span>2.7</span></a> will be used interchangeably.</p>
<p>To effectively validate an implementation or library, developers are required to author a fuzzing harness that invokes the target library’s API functions utilizing the fuzz-generated inputs. This harness serves as the principal interface for the fuzzer and is executed iteratively, each time with mutated input designed to maximize code coverage and uncover defects. To comply with LibFuzzer’s interface requirements, a harness must conform to the following function signature:</p>
<div id="lst-basic-example" class="listing quarto-float quarto-figure quarto-figure-left anchored" data-fig-scap="Fuzzing harness format">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-basic-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;2.1: This function receives the fuzzing input via a pointer to an array of bytes (<code>Data</code>) and its associated size (<code>Size</code>). Efficiency in fuzzing is achieved by invoking the API of interest within the body of this function, thereby allowing the fuzzer to explore a broad spectrum of behavior through systematic input mutation.
</figcaption>
<div aria-describedby="lst-basic-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource c number-lines code-with-copy"><code class="sourceCode c"><span id="cb1-1"><a href="#cb1-1"></a><span class="dt">int</span> LLVMFuzzerTestOneInput<span class="op">(</span><span class="dt">const</span> <span class="dt">uint8_t</span> <span class="op">*</span>Data<span class="op">,</span> <span class="dt">size_t</span> Size<span class="op">)</span> <span class="op">{</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>  DoSomethingInterestingWithData<span class="op">(</span>Data<span class="op">,</span> Size<span class="op">);</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>  <span class="cf">return</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
<p>A more illustrative example of such a harness is provided in <a href="#lst-fuzzing-example" class="quarto-xref">Listing&nbsp;<span>2.2</span></a>.</p>
<div id="lst-fuzzing-example" class="listing quarto-float quarto-figure quarto-figure-left anchored" data-fig-scap="Example fuzzing harness">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-fuzzing-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;2.2: This example demonstrates a minimal harness that triggers a controlled crash upon receiving <code>HI!</code> as input.
</figcaption>
<div aria-describedby="lst-fuzzing-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource cpp number-lines code-with-copy"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1"></a><span class="co">// test_fuzzer.cpp</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="pp">#include </span><span class="im">&lt;stdint.h&gt;</span></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="pp">#include </span><span class="im">&lt;stddef.h&gt;</span></span>
<span id="cb2-4"><a href="#cb2-4"></a></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="at">extern</span> <span class="st">"C"</span> <span class="dt">int</span> LLVMFuzzerTestOneInput<span class="op">(</span><span class="at">const</span> <span class="dt">uint8_t</span> <span class="op">*</span>data<span class="op">,</span> <span class="dt">size_t</span> size<span class="op">)</span> <span class="op">{</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>  <span class="cf">if</span> <span class="op">(</span>size <span class="op">&gt;</span> <span class="dv">0</span> <span class="op">&amp;&amp;</span> data<span class="op">[</span><span class="dv">0</span><span class="op">]</span> <span class="op">==</span> <span class="ch">'H'</span><span class="op">)</span></span>
<span id="cb2-7"><a href="#cb2-7"></a>    <span class="cf">if</span> <span class="op">(</span>size <span class="op">&gt;</span> <span class="dv">1</span> <span class="op">&amp;&amp;</span> data<span class="op">[</span><span class="dv">1</span><span class="op">]</span> <span class="op">==</span> <span class="ch">'I'</span><span class="op">)</span></span>
<span id="cb2-8"><a href="#cb2-8"></a>      <span class="cf">if</span> <span class="op">(</span>size <span class="op">&gt;</span> <span class="dv">2</span> <span class="op">&amp;&amp;</span> data<span class="op">[</span><span class="dv">2</span><span class="op">]</span> <span class="op">==</span> <span class="ch">'!'</span><span class="op">)</span></span>
<span id="cb2-9"><a href="#cb2-9"></a>        <span class="fu">__builtin_trap</span><span class="op">();</span></span>
<span id="cb2-10"><a href="#cb2-10"></a>  <span class="cf">return</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
<p>To compile and link such a harness with LibFuzzer, the Clang compiler—also part of the LLVM project <span class="citation" data-cites="llvm"><a href="refs.html#ref-llvm" role="doc-biblioref">[19]</a></span>—must be used alongside appropriate compiler flags. For instance, compiling the harness in <a href="#lst-fuzzing-example" class="quarto-xref">Listing&nbsp;<span>2.2</span></a> can be achieved as shown in <a href="#lst-harness-compilation" class="quarto-xref">Listing&nbsp;<span>2.3</span></a>.</p>
<div id="lst-harness-compilation" class="listing quarto-float quarto-figure quarto-figure-left anchored" data-fig-scap="Compilation of harness">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-harness-compilation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;2.3: This example illustrates the compilation and execution workflow necessary for deploying a LibFuzzer-based fuzzing harness.
</figcaption>
<div aria-describedby="lst-harness-compilation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource sh number-lines code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># Compile test_fuzzer.cc with AddressSanitizer and link against LibFuzzer.</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="fu">clang</span>++ <span class="at">-fsanitize</span><span class="op">=</span>address,fuzzer test_fuzzer.cc</span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co"># Execute the fuzzer without any pre-existing seed corpus.</span></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="ex">./a.out</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
</section>
<section id="afl-and-afl" class="level4" data-number="2.1.2.2">
<h4 data-number="2.1.2.2" class="anchored" data-anchor-id="afl-and-afl"><span class="header-section-number">2.1.2.2</span> AFL and AFL++</h4>
<p><em>American Fuzzy Lop</em> (AFL) <span class="citation" data-cites="afl"><a href="refs.html#ref-afl" role="doc-biblioref">[15]</a></span>, developed by Michał Zalewski, is a seminal fuzzer targeting C and C++ applications. Its core methodology relies on instrumented binaries to provide edge coverage feedback, thereby guiding input mutation towards unexplored program paths. AFL supports several emulation backends including QEMU <span class="citation" data-cites="bellard2025"><a href="refs.html#ref-bellard2025" role="doc-biblioref">[20]</a></span>—an open-source CPU emulator facilitating fuzzing on diverse architectures—and Unicorn <span class="citation" data-cites="unicornengine2025"><a href="refs.html#ref-unicornengine2025" role="doc-biblioref">[21]</a></span>, a lightweight multi-platform CPU emulator. While AFL established itself as a foundational tool within the fuzzing community, its successor AFL++ <span class="citation" data-cites="aflpp"><a href="refs.html#ref-aflpp" role="doc-biblioref">[18]</a></span> incorporates numerous enhancements and additional features to improve fuzzing efficacy.</p>
<p>AFL operates by ingesting seed inputs from a specified directory (<code>seeds_dir</code>), applying mutations, and then executing the target binary to discover novel execution paths. Execution can be initiated using the following command-line syntax:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1"></a><span class="ex">./afl-fuzz</span> <span class="at">-i</span> seeds_dir <span class="at">-o</span> output_dir <span class="at">--</span> /path/to/tested/program</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>AFL is capable of fuzzing both black-box and instrumented binaries, employing a fork-server mechanism to optimize performance. It additionally supports persistent mode execution as well as modes leveraging QEMU and Unicorn emulators, thereby providing extensive flexibility for different testing environments.</p>
<p>Although AFL is traditionally utilized for fuzzing standalone programs or binaries, it is also capable of fuzzing libraries and other software components. In such scenarios, rather than implementing the <code>LLVMFuzzerTestOneInput</code> style harness, AFL can use the standard <code>main()</code> function as the fuzzing entry point. Nonetheless, AFL also accommodates integration with <code>LLVMFuzzerTestOneInput</code>-based harnesses, underscoring its adaptability across varied fuzzing use cases.</p>
</section>
</section>
<section id="challenges-in-adoption" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3" class="anchored" data-anchor-id="challenges-in-adoption"><span class="header-section-number">2.1.3</span> Challenges in Adoption</h3>
<p>Despite its potential for uncovering software vulnerabilities, fuzzing remains a relatively underutilized testing technique compared to more established methodologies such as Test-Driven Development (TDD). This limited adoption can be attributed, in part, to the substantial initial investment required to design and implement appropriate test harnesses that enable effective fuzzing processes. Furthermore, the interpretation of fuzzing outcomes—particularly the identification, diagnostic analysis, and prioritization of program crashes—demands considerable resources and specialized expertise. These factors collectively pose significant barriers to the widespread integration of fuzzing within standard software development and testing practices.</p>
</section>
</section>
<section id="large-language-models" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="large-language-models"><span class="header-section-number">2.2</span> Large Language Models</h2>
<p>Natural Language Processing (NLP), a subfield of Artificial Intelligence (AI), has a rich and ongoing history that has evolved significantly since its beginning in the 1990s <span class="citation" data-cites="li2022 wang2025"><a href="refs.html#ref-li2022" role="doc-biblioref">[22]</a>, <a href="refs.html#ref-wang2025" role="doc-biblioref">[23]</a></span>. Among the most notable—and recent—advancements in this domain are Large Language Models (LLMs), which have transformed the landscape of NLP and AI in general.</p>
<p>At the core of many LLMs is the attention mechanism, which was introduced by Bahdanau et al.&nbsp;in 2014 <span class="citation" data-cites="bahdanau2016"><a href="refs.html#ref-bahdanau2016" role="doc-biblioref">[24]</a></span>. This pivotal innovation enabled models to focus on relevant parts of the input sequence when making predictions, significantly improving language understanding and generation tasks. Building on this foundation, the Transformer architecture was proposed by Vaswani et al.&nbsp;in 2017 <span class="citation" data-cites="vaswani2023"><a href="refs.html#ref-vaswani2023" role="doc-biblioref">[25]</a></span>. This architecture has become the backbone of most contemporary LLMs, as it efficiently processes sequences of data, capturing long-range dependencies without being hindered by sequential processing limitations.</p>
<p>One of the first major breakthroughs utilizing the Transformer architecture was BERT (Bidirectional Encoder Representations from Transformers), developed by Devlin et al.&nbsp;in 2019 <span class="citation" data-cites="devlin2019"><a href="refs.html#ref-devlin2019" role="doc-biblioref">[26]</a></span>. BERT’s bi-directional understanding allowed it to capture the context of words from both directions, which improved the accuracy of various NLP tasks. Following this, the Generative Pre-trained Transformer (GPT) series, initiated by OpenAI with the original GPT model in 2018 <span class="citation" data-cites="radford2018"><a href="refs.html#ref-radford2018" role="doc-biblioref">[27]</a></span>, further pushed the boundaries. Subsequent iterations, including GPT-2 <span class="citation" data-cites="radford2019"><a href="refs.html#ref-radford2019" role="doc-biblioref">[28]</a></span>, GPT-3 <span class="citation" data-cites="brown2020"><a href="refs.html#ref-brown2020" role="doc-biblioref">[29]</a></span>, and the most current GPT-4 <span class="citation" data-cites="openai2024"><a href="refs.html#ref-openai2024" role="doc-biblioref">[30]</a></span>, have continued to enhance performance by scaling model size, data, and training techniques.</p>
<p>In addition to OpenAI’s contributions, other significant models have emerged, such as Claude, DeepSeek-R1 and the Llama series (1 through 3) <span class="citation" data-cites="claude deepseek-ai2025 grattafiori2024"><a href="refs.html#ref-claude" role="doc-biblioref">[31]</a>, <a href="refs.html#ref-deepseek-ai2025" role="doc-biblioref">[32]</a>, <a href="refs.html#ref-grattafiori2024" role="doc-biblioref">[33]</a></span>. The proliferation of LLMs has sparked an active discourse about their capabilities, applications, and implications in various fields.</p>
<section id="biggest-gpts" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="biggest-gpts"><span class="header-section-number">2.2.1</span> Biggest GPTs</h3>
<p>User-facing LLMs are generally categorized between closed-source and open-source models. Closed-source LLMs like ChatGPT, Claude, and Gemini <span class="citation" data-cites="chatgpt claude gemini"><a href="refs.html#ref-claude" role="doc-biblioref">[31]</a>, <a href="refs.html#ref-chatgpt" role="doc-biblioref">[34]</a>, <a href="refs.html#ref-gemini" role="doc-biblioref">[35]</a></span> represent commercially developed systems often optimized for specific tasks without public access to their underlying weights. In contrast, open-source models<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, including the Llama series <span class="citation" data-cites="grattafiori2024"><a href="refs.html#ref-grattafiori2024" role="doc-biblioref">[33]</a></span> and Deepseek <span class="citation" data-cites="deepseek-ai2025"><a href="refs.html#ref-deepseek-ai2025" role="doc-biblioref">[32]</a></span>, provide researchers and practitioners with access to model weights, allowing for greater transparency and adaptability.</p>
<aside id="footnotes-2" class="footnotes footnotes-end-of-block" role="doc-footnote">
<ol start="2">
<li id="fn2"><p>The term “open-source” models is somewhat misleading, since these are better termed as <em>open-weights</em> models. While their weights are publicly available, their training data and underlying code are often proprietary. This terminology reflects community usage but fails to capture the limitations of transparency and accessibility inherent in these models.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
</section>
<section id="sec-prompting" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="sec-prompting"><span class="header-section-number">2.2.2</span> Prompting</h3>
<p>Interaction with LLMs typically occurs through chat-like interfaces, a process commonly referred to as <em>prompting</em>. A critical aspect of effective engagement with LLMs is the usage of different prompting strategies, which can significantly influence the quality and relevance of the generated outputs. Various approaches to prompting have been developed and studied, including zero-shot and few-shot prompting. In zero-shot prompting, the model is expected to perform a specific task without any examples, while in few-shot prompting, the user provides a limited number of examples to guide the model’s responses <span class="citation" data-cites="brown2020"><a href="refs.html#ref-brown2020" role="doc-biblioref">[29]</a></span>.</p>
<p>To enhance performance on more complex tasks, several advanced prompting techniques have emerged. One notable strategy is the <em>Chain of Thought</em> approach <span class="citation" data-cites="chainofthought"><a href="refs.html#ref-chainofthought" role="doc-biblioref">[36]</a></span>, which entails presenting the model with sample thought processes for solving a given task. This method encourages the model to generate more coherent and logical reasoning by mimicking human-like cognitive pathways. A refined variant of this approach is the <em>Tree of Thoughts</em> technique <span class="citation" data-cites="yao2023"><a href="refs.html#ref-yao2023" role="doc-biblioref">[37]</a></span>, which enables the LLM to explore multiple lines of reasoning concurrently, thereby facilitating the selection of the most promising train of thought for further exploration.</p>
<p>In addition to these cognitive strategies, Retrieval-Augmented Generation (RAG) <span class="citation" data-cites="lewis2021"><a href="refs.html#ref-lewis2021" role="doc-biblioref">[38]</a></span> is another innovative technique that enhances the model’s capacity to provide accurate information by incorporating external knowledge not present in its training dataset. RAG operates by integrating the LLM with an external storage system—often a vector store containing relevant documents—that the model can query in real-time. This allows the LLM to pull up pertinent and/or proprietary information in response to user queries, resulting in more comprehensive and accurate answers.</p>
<p>Moreover, the ReAct framework <span class="citation" data-cites="reAct"><a href="refs.html#ref-reAct" role="doc-biblioref">[39]</a></span>, which stands for Reasoning and Acting, empowers LLMs by granting access to external tools. This capability allows LLM instances to function as intelligent agents that can interact meaningfully with their environment through user-defined tools. For instance, a ReAct tool could be a function that returns a weather forecast based on the user’s current location. In this scenario, the LLM can provide accurate and truthful predictions, thereby mitigating risks associated with hallucinated responses.</p>
</section>
<section id="sec-llm-coding" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="sec-llm-coding"><span class="header-section-number">2.2.3</span> LLMs for Coding</h3>
<p>The impact of LLMs in software development in recent years is apparent, with hundreds of LLM-assistance extensions and Integrated Development Environments (IDEs) being published. Notable instances include tools like GitHub Copilot and IDEs such as Cursor, which leverage LLM capabilities to provide developers with coding suggestions, auto-completions, and even real-time debugging assistance <span class="citation" data-cites="cursor ghcopilot"><a href="refs.html#ref-cursor" role="doc-biblioref">[40]</a>, <a href="refs.html#ref-ghcopilot" role="doc-biblioref">[41]</a></span>. Such innovations have introduced a layer of interaction that enhances productivity and fosters a more intuitive coding experience. Simultaneously, certain LLMs are trained themselves with the code-generation task in mind <span class="citation" data-cites="nijkamp2023a nijkamp2023 openai2025a"><a href="refs.html#ref-nijkamp2023a" role="doc-biblioref">[42]</a>, <a href="refs.html#ref-nijkamp2023" role="doc-biblioref">[43]</a>, <a href="refs.html#ref-openai2025a" role="doc-biblioref">[44]</a></span>.</p>
<p>One exemplary product of this innovation is <em>vibecoding</em> and the no-code movement, which describe the development of software by only prompting and tasking an LLM, i.e.&nbsp;without any actual programming required by the user. This constitutes a showcase of how LLMs can be harnessed to elevate the coding experience by supporting developers as they navigate complex programming tasks <span class="citation" data-cites="sarkar2025"><a href="refs.html#ref-sarkar2025" role="doc-biblioref">[45]</a></span>. By analyzing the context of the code being written, these sophisticated models can provide contextualized insights and relevant snippets, effectively streamlining the development process. Developers can benefit from reduced cognitive load, as they receive suggestions that not only cater to immediate coding needs but also promote adherence to best practices and coding standards.</p>
<p>Despite these advancements, it is crucial to recognize the inherent limitations of LLMs when applied to software development. While they can help in many aspects of coding, they are not immune to generating erroneous outputs—a phenomenon often referred to as “hallucination”. Hallucinations occur when LLMs produce information that is unfounded or inaccurate, which can stem from several factors, including the limitations of their training data and the constrained context window within which they operate. As LLMs generate code suggestions based on the patterns learned from vast datasets, they may inadvertently propose solutions that do not align with the specific requirements of a task or that utilize outdated programming paradigms.</p>
<p>Moreover, the challenge of limited context windows can lead to suboptimal suggestions. LLMs generally process a fixed amount of text when generating responses, which can impact their ability to fully grasp the nuances of complex coding scenarios. This may result in outputs that lack the necessary depth and specificity required for successful implementation. As a consequence, developers must exercise caution and critically evaluate the suggestions offered by these models, as reliance on them without due diligence could lead to the introduction of bugs or other issues in the code.</p>
</section>
<section id="llms-for-fuzzing" class="level3" data-number="2.2.4">
<h3 data-number="2.2.4" class="anchored" data-anchor-id="llms-for-fuzzing"><span class="header-section-number">2.2.4</span> LLMs for Fuzzing</h3>
<p>While large language models (LLMs) demonstrate significant potential in enhancing the software development process, the challenges highlighted in <a href="#sec-llm-coding" class="quarto-xref"><span>Section 2.2.3</span></a> become even more pronounced and troublesome when these models are employed to generate fuzzing harnesses. The task of writing a fuzzing harness inherently demands an in-depth comprehension of both the library being tested and the intricate interactions expected among its various components. This level of understanding is often beyond the capabilities of LLMs, primarily due to their context window limitations, which restrict the amount of information they can effectively process and retain during code generation.</p>
<p>In addition to this issue, the risk of error-prone code produced by LLMs further complicates the fuzzing workflow. When a crash occurs during the fuzzing process, it becomes imperative for developers to ascertain that the root cause of the failure is not attributable to deficiencies or bugs within the harness itself. This additional layer of verification adds to the cognitive load placed upon developers, potentially detracting from their ability to focus on testing and improving the underlying software.</p>
<p>To enhance the reliability of LLM-generated harnesses in fuzzing contexts, it is essential that these generated artifacts undergo thorough evaluation and validation through programmatic means. This involves the implementation of systematic techniques that assess the accuracy and robustness of the generated code, ensuring that it aligns with the expected behavior of the components it is intended to interact with. This strategy can be conceptualized within the framework of Neurosymbolic AI (<a href="#sec-nesy" class="quarto-xref"><span>Section 2.3</span></a>), which seeks to integrate the strengths of neural networks with symbolic reasoning capabilities. By marrying these two paradigms, it may be possible to improve the reliability and efficacy of LLMs in the creation of fuzzing harnesses, ultimately leading to a more seamless integration of automated testing methodologies into the software development lifecycle.</p>
</section>
</section>
<section id="sec-nesy" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="sec-nesy"><span class="header-section-number">2.3</span> Neurosymbolic AI</h2>
<p>Neurosymbolic AI (NeSy AI) represents a groundbreaking fusion of neural network methodologies with symbolic execution techniques and tools, providing a multi-faceted approach to overcoming the inherent limitations of traditional AI paradigms <span class="citation" data-cites="sheth2023 garcez2020"><a href="refs.html#ref-sheth2023" role="doc-biblioref">[46]</a>, <a href="refs.html#ref-garcez2020" role="doc-biblioref">[47]</a></span>. This innovative synthesis seeks to combine the strengths of both neural networks, which excel in pattern recognition and data-driven learning, and symbolic systems, which offer structured reasoning and interpretability. By integrating these two approaches, NeSy AI aims to create cognitive models that are not only more accurate but also more robust in problem-solving contexts.</p>
<p>At its core, NeSy AI facilitates the development of AI systems that are capable of understanding and interpreting feedback in real-world scenarios <span class="citation" data-cites="ganguly2024"><a href="refs.html#ref-ganguly2024" role="doc-biblioref">[48]</a></span>. This characteristic is particularly significant in the current landscape of artificial intelligence, where LLMs are predominant. In this context, NeSy AI is increasingly viewed as a critical solution to pressing issues related to explainability, attribution, and reliability in AI systems <span class="citation" data-cites="gaur2023 tilwani2024"><a href="refs.html#ref-gaur2023" role="doc-biblioref">[49]</a>, <a href="refs.html#ref-tilwani2024" role="doc-biblioref">[50]</a></span>. These challenges are essential for ensuring that AI systems can be trusted and effectively utilized in various applications, from business to healthcare.</p>
<p>The burgeoning field of neurosymbolic AI is still in its nascent stages, with ongoing research and development actively exploring its potential to enhance attribution methodologies within large language models. By addressing these critical challenges, NeSy AI can significantly contribute to the broader landscape of trustworthy AI systems, allowing for more transparent and accountable decision-making processes <span class="citation" data-cites="sheth2023 gaur2023 tilwani2024"><a href="refs.html#ref-sheth2023" role="doc-biblioref">[46]</a>, <a href="refs.html#ref-gaur2023" role="doc-biblioref">[49]</a>, <a href="refs.html#ref-tilwani2024" role="doc-biblioref">[50]</a></span>.</p>
<p>Moreover, the application of neurosymbolic AI within the domain of fuzzing is gaining traction, paving the way for innovative explorations. This integration of LLMs with symbolic systems opens up new avenues for research. Currently, there are only a limited number of tools that support such hybrid approaches (<a href="03-related.html" class="quarto-xref"><span>Chapter 3</span></a>). Among these, OverHAuL constitutes a Neuro[Symbolic] tool, as classified by Henry Kautz’s taxonomy <span class="citation" data-cites="sarker2022 kautz2020"><a href="refs.html#ref-sarker2022" role="doc-biblioref">[51]</a>, <a href="refs.html#ref-kautz2020" role="doc-biblioref">[52]</a></span>. This means that the neural model—specifically the LLM—can leverage symbolic reasoning tools—in this case a source code explorer (<a href="07-implementation.html" class="quarto-xref"><span>Chapter 7</span></a>)—to augment its reasoning capabilities. This symbiotic relationship enhances the overall efficacy and versatility of LLMs for fuzzing harnesses generation, demonstrating the profound potential held by the fusion of neural and symbolic methodologies.</p>


<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-manes2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">V. J. M. Manes <em>et al.</em>, <span>“The <span>Art</span>, <span>Science</span>, and <span>Engineering</span> of <span>Fuzzing</span>: <span>A Survey</span>,”</span> Apr. 07, 2019. doi: <a href="https://doi.org/10.48550/arXiv.1812.00140">10.48550/arXiv.1812.00140</a>. Available: <a href="http://arxiv.org/abs/1812.00140">http://arxiv.org/abs/1812.00140</a></div>
</div>
<div id="ref-takanen2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">A. Takanen, J. DeMott, C. Miller, and A. Kettunen, <em>Fuzzing for software security testing and quality assurance</em>, Second edition. in Information security and privacy library. Boston London Norwood, MA: Artech House, 2018.</div>
</div>
<div id="ref-sutton2007" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">M. Sutton, A. Greene, and P. Amini, <em>Fuzzing: Brute force vulnerabilty discovery</em>. Upper Saddle River, NJ: Addison-Wesley, 2007.</div>
</div>
<div id="ref-rathaus2007" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">N. Rathaus and G. Evron, <em>Open source fuzzing tools</em>. Burlington, MA: Syngress Pub, 2007.</div>
</div>
<div id="ref-miller1990" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">B. P. Miller, L. Fredriksen, and B. So, <span>“An empirical study of the reliability of <span>UNIX</span> utilities,”</span> <em>Commun. ACM</em>, vol. 33, no. 12, pp. 32–44, Dec. 1990, doi: <a href="https://doi.org/10.1145/96267.96279">10.1145/96267.96279</a>. Available: <a href="https://dl.acm.org/doi/10.1145/96267.96279">https://dl.acm.org/doi/10.1145/96267.96279</a></div>
</div>
<div id="ref-serebryany2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov, <span>“<span>AddressSanitizer</span>: <span>A</span> fast address sanity checker,”</span> in <em>2012 <span>USENIX</span> annual technical conference (<span>USENIX ATC</span> 12)</em>, 2012, pp. 309–318. Available: <a href="https://www.usenix.org/conference/atc12/technical-sessions/presentation/serebryany">https://www.usenix.org/conference/atc12/technical-sessions/presentation/serebryany</a></div>
</div>
<div id="ref-libfuzzer" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">LLVM Project, <span>“<span class="nocase">libFuzzer</span> – a library for coverage-guided fuzz testing. — <span>LLVM</span> 21.0.0git documentation,”</span> 2025. Available: <a href="https://llvm.org/docs/LibFuzzer.html">https://llvm.org/docs/LibFuzzer.html</a></div>
</div>
<div id="ref-rebert2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">A. Rebert <em>et al.</em>, <span>“Optimizing seed selection for fuzzing,”</span> in <em>Proceedings of the 23rd <span>USENIX</span> conference on <span>Security Symposium</span></em>, in <span>SEC</span>’14. USA: USENIX Association, Aug. 2014, pp. 861–875.</div>
</div>
<div id="ref-owaspfoundation" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">OWASP Foundation, <span>“Fuzzing.”</span> Available: <a href="https://owasp.org/www-community/Fuzzing">https://owasp.org/www-community/Fuzzing</a></div>
</div>
<div id="ref-heartbleed" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">Blackduck, Inc., <span>“Heartbleed <span>Bug</span>,”</span> Mar. 07, 2025. Available: <a href="https://heartbleed.com/">https://heartbleed.com/</a></div>
</div>
<div id="ref-heartbleed-cve" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">CVE Program, <span>“<span>CVE</span> - <span>CVE-2014-0160</span>,”</span> 2014. Available: <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=cve-2014-0160">https://cve.mitre.org/cgi-bin/cvename.cgi?name=cve-2014-0160</a></div>
</div>
<div id="ref-theopensslproject2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">The OpenSSL Project, <span>“Openssl/openssl.”</span> OpenSSL, Jul. 15, 2025. Available: <a href="https://github.com/openssl/openssl">https://github.com/openssl/openssl</a></div>
</div>
<div id="ref-wheeler2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">D. Wheeler, <span>“How to <span>Prevent</span> the next <span>Heartbleed</span>,”</span> 2014. Available: <a href="https://dwheeler.com/essays/heartbleed.html">https://dwheeler.com/essays/heartbleed.html</a></div>
</div>
<div id="ref-bash" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">GNU Project, <span>“Bash - <span>GNU Project</span> - <span>Free Software Foundation</span>.”</span> Available: <a href="https://www.gnu.org/software/bash/">https://www.gnu.org/software/bash/</a></div>
</div>
<div id="ref-afl" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">M. Zalewski, <span>“American fuzzy lop.”</span> Available: <a href="https://lcamtuf.coredump.cx/afl/">https://lcamtuf.coredump.cx/afl/</a></div>
</div>
<div id="ref-saarinen2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">J. Saarinen, <span>“Further flaws render <span>Shellshock</span> patch ineffective,”</span> Sep. 29, 2014. Available: <a href="https://www.itnews.com.au/news/further-flaws-render-shellshock-patch-ineffective-396256">https://www.itnews.com.au/news/further-flaws-render-shellshock-patch-ineffective-396256</a></div>
</div>
<div id="ref-simonite2020mayhem" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">T. Simonite, <span>“This <span>Bot Hunts Software Bugs</span> for the <span>Pentagon</span>,”</span> <em>Wired</em>, Jun. 01, 2020. Available: <a href="https://www.wired.com/story/bot-hunts-software-bugs-pentagon/">https://www.wired.com/story/bot-hunts-software-bugs-pentagon/</a></div>
</div>
<div id="ref-aflpp" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">M. Heuse, H. Eißfeldt, A. Fioraldi, and D. Maier, <span>“<span>AFL</span>++.”</span> Jan. 2022. Available: <a href="https://github.com/AFLplusplus/AFLplusplus">https://github.com/AFLplusplus/AFLplusplus</a></div>
</div>
<div id="ref-llvm" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">LLVM Project, <span>“The <span>LLVM Compiler Infrastructure Project</span>,”</span> 2025. Available: <a href="https://llvm.org/">https://llvm.org/</a></div>
</div>
<div id="ref-bellard2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">F. Bellard, P. Maydell, and QEMU Team, <span>“<span>QEMU</span>.”</span> May 29, 2025. Available: <a href="https://www.qemu.org/">https://www.qemu.org/</a></div>
</div>
<div id="ref-unicornengine2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">Unicorn Engine, <span>“Unicorn-engine/unicorn.”</span> Unicorn Engine, Jul. 15, 2025. Available: <a href="https://github.com/unicorn-engine/unicorn">https://github.com/unicorn-engine/unicorn</a></div>
</div>
<div id="ref-li2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">H. Li, <span>“Language models: Past, present, and future,”</span> <em>Commun. ACM</em>, vol. 65, no. 7, pp. 56–63, Jun. 2022, doi: <a href="https://doi.org/10.1145/3490443">10.1145/3490443</a>. Available: <a href="https://dl.acm.org/doi/10.1145/3490443">https://dl.acm.org/doi/10.1145/3490443</a></div>
</div>
<div id="ref-wang2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">Z. Wang, Z. Chu, T. V. Doan, S. Ni, M. Yang, and W. Zhang, <span>“History, development, and principles of large language models: An introductory survey,”</span> <em>AI Ethics</em>, vol. 5, no. 3, pp. 1955–1971, Jun. 2025, doi: <a href="https://doi.org/10.1007/s43681-024-00583-7">10.1007/s43681-024-00583-7</a>. Available: <a href="https://doi.org/10.1007/s43681-024-00583-7">https://doi.org/10.1007/s43681-024-00583-7</a></div>
</div>
<div id="ref-bahdanau2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">D. Bahdanau, K. Cho, and Y. Bengio, <span>“Neural <span>Machine Translation</span> by <span>Jointly Learning</span> to <span>Align</span> and <span>Translate</span>,”</span> May 19, 2016. doi: <a href="https://doi.org/10.48550/arXiv.1409.0473">10.48550/arXiv.1409.0473</a>. Available: <a href="http://arxiv.org/abs/1409.0473">http://arxiv.org/abs/1409.0473</a></div>
</div>
<div id="ref-vaswani2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">A. Vaswani <em>et al.</em>, <span>“Attention <span>Is All You Need</span>,”</span> Aug. 01, 2023. doi: <a href="https://doi.org/10.48550/arXiv.1706.03762">10.48550/arXiv.1706.03762</a>. Available: <a href="http://arxiv.org/abs/1706.03762">http://arxiv.org/abs/1706.03762</a></div>
</div>
<div id="ref-devlin2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, <span>“<span>BERT</span>: <span class="nocase">Pre-training</span> of <span>Deep Bidirectional Transformers</span> for <span>Language Understanding</span>,”</span> May 24, 2019. doi: <a href="https://doi.org/10.48550/arXiv.1810.04805">10.48550/arXiv.1810.04805</a>. Available: <a href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a></div>
</div>
<div id="ref-radford2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, <span>“Improving language understanding by generative pre-training,”</span> 2018, Available: <a href="https://www.mikecaptain.com/resources/pdf/GPT-1.pdf">https://www.mikecaptain.com/resources/pdf/GPT-1.pdf</a></div>
</div>
<div id="ref-radford2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[28] </div><div class="csl-right-inline">A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, <span>“Language models are unsupervised multitask learners,”</span> <em>OpenAI blog</em>, vol. 1, no. 8, p. 9, 2019, Available: <a href="https://storage.prod.researchhub.com/uploads/papers/2020/06/01/language-models.pdf">https://storage.prod.researchhub.com/uploads/papers/2020/06/01/language-models.pdf</a></div>
</div>
<div id="ref-brown2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[29] </div><div class="csl-right-inline">T. B. Brown <em>et al.</em>, <span>“Language <span>Models</span> are <span>Few-Shot Learners</span>,”</span> Jul. 22, 2020. doi: <a href="https://doi.org/10.48550/arXiv.2005.14165">10.48550/arXiv.2005.14165</a>. Available: <a href="http://arxiv.org/abs/2005.14165">http://arxiv.org/abs/2005.14165</a></div>
</div>
<div id="ref-openai2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[30] </div><div class="csl-right-inline">OpenAI <em>et al.</em>, <span>“<span>GPT-4 Technical Report</span>,”</span> Mar. 04, 2024. doi: <a href="https://doi.org/10.48550/arXiv.2303.08774">10.48550/arXiv.2303.08774</a>. Available: <a href="http://arxiv.org/abs/2303.08774">http://arxiv.org/abs/2303.08774</a></div>
</div>
<div id="ref-claude" class="csl-entry" role="listitem">
<div class="csl-left-margin">[31] </div><div class="csl-right-inline">Anthropic, <span>“Claude,”</span> 2025. Available: <a href="https://claude.ai/new">https://claude.ai/new</a></div>
</div>
<div id="ref-deepseek-ai2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">[32] </div><div class="csl-right-inline">DeepSeek-AI <em>et al.</em>, <span>“<span>DeepSeek-R1</span>: <span>Incentivizing Reasoning Capability</span> in <span>LLMs</span> via <span>Reinforcement Learning</span>,”</span> Jan. 22, 2025. doi: <a href="https://doi.org/10.48550/arXiv.2501.12948">10.48550/arXiv.2501.12948</a>. Available: <a href="http://arxiv.org/abs/2501.12948">http://arxiv.org/abs/2501.12948</a></div>
</div>
<div id="ref-grattafiori2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[33] </div><div class="csl-right-inline">A. Grattafiori <em>et al.</em>, <span>“The <span>Llama</span> 3 <span>Herd</span> of <span>Models</span>,”</span> Nov. 23, 2024. doi: <a href="https://doi.org/10.48550/arXiv.2407.21783">10.48550/arXiv.2407.21783</a>. Available: <a href="http://arxiv.org/abs/2407.21783">http://arxiv.org/abs/2407.21783</a></div>
</div>
<div id="ref-chatgpt" class="csl-entry" role="listitem">
<div class="csl-left-margin">[34] </div><div class="csl-right-inline">OpenAI, <span>“<span>ChatGPT</span>,”</span> 2025. Available: <a href="https://chatgpt.com">https://chatgpt.com</a></div>
</div>
<div id="ref-gemini" class="csl-entry" role="listitem">
<div class="csl-left-margin">[35] </div><div class="csl-right-inline">Google, <span>“‎<span>Google Gemini</span>,”</span> 2025. Available: <a href="https://gemini.google.com">https://gemini.google.com</a></div>
</div>
<div id="ref-chainofthought" class="csl-entry" role="listitem">
<div class="csl-left-margin">[36] </div><div class="csl-right-inline">J. Wei <em>et al.</em>, <span>“Chain-of-<span>Thought Prompting Elicits Reasoning</span> in <span>Large Language Models</span>,”</span> Jan. 10, 2023. doi: <a href="https://doi.org/10.48550/arXiv.2201.11903">10.48550/arXiv.2201.11903</a>. Available: <a href="http://arxiv.org/abs/2201.11903">http://arxiv.org/abs/2201.11903</a></div>
</div>
<div id="ref-yao2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[37] </div><div class="csl-right-inline">S. Yao <em>et al.</em>, <span>“Tree of <span>Thoughts</span>: <span>Deliberate Problem Solving</span> with <span>Large Language Models</span>,”</span> Dec. 03, 2023. doi: <a href="https://doi.org/10.48550/arXiv.2305.10601">10.48550/arXiv.2305.10601</a>. Available: <a href="http://arxiv.org/abs/2305.10601">http://arxiv.org/abs/2305.10601</a></div>
</div>
<div id="ref-lewis2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">[38] </div><div class="csl-right-inline">P. Lewis <em>et al.</em>, <span>“Retrieval-<span>Augmented Generation</span> for <span>Knowledge-Intensive NLP Tasks</span>,”</span> Apr. 12, 2021. doi: <a href="https://doi.org/10.48550/arXiv.2005.11401">10.48550/arXiv.2005.11401</a>. Available: <a href="http://arxiv.org/abs/2005.11401">http://arxiv.org/abs/2005.11401</a></div>
</div>
<div id="ref-reAct" class="csl-entry" role="listitem">
<div class="csl-left-margin">[39] </div><div class="csl-right-inline">S. Yao <em>et al.</em>, <span>“<span>ReAct</span>: <span>Synergizing Reasoning</span> and <span>Acting</span> in <span>Language Models</span>,”</span> Mar. 10, 2023. doi: <a href="https://doi.org/10.48550/arXiv.2210.03629">10.48550/arXiv.2210.03629</a>. Available: <a href="http://arxiv.org/abs/2210.03629">http://arxiv.org/abs/2210.03629</a></div>
</div>
<div id="ref-cursor" class="csl-entry" role="listitem">
<div class="csl-left-margin">[40] </div><div class="csl-right-inline">Anysphere, <span>“Cursor - <span>The AI Code Editor</span>,”</span> 2025. Available: <a href="https://cursor.com/">https://cursor.com/</a></div>
</div>
<div id="ref-ghcopilot" class="csl-entry" role="listitem">
<div class="csl-left-margin">[41] </div><div class="csl-right-inline">Microsoft, <span>“<span>GitHub Copilot</span> · <span>Your AI</span> pair programmer,”</span> 2025. Available: <a href="https://github.com/features/copilot">https://github.com/features/copilot</a></div>
</div>
<div id="ref-nijkamp2023a" class="csl-entry" role="listitem">
<div class="csl-left-margin">[42] </div><div class="csl-right-inline">E. Nijkamp <em>et al.</em>, <span>“<span>CodeGen</span>: <span>An</span> open large language model for code with multi-turn program synthesis,”</span> <em>ICLR</em>, 2023.</div>
</div>
<div id="ref-nijkamp2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[43] </div><div class="csl-right-inline">E. Nijkamp, H. Hayashi, C. Xiong, S. Savarese, and Y. Zhou, <span>“<span>CodeGen2</span>: <span>Lessons</span> for training llms on programming and natural languages,”</span> <em>ICLR</em>, 2023.</div>
</div>
<div id="ref-openai2025a" class="csl-entry" role="listitem">
<div class="csl-left-margin">[44] </div><div class="csl-right-inline">OpenAI, <span>“Introducing <span>GPT-4</span>.1 in the <span>API</span>,”</span> Apr. 14, 2025. Available: <a href="https://openai.com/index/gpt-4-1/">https://openai.com/index/gpt-4-1/</a></div>
</div>
<div id="ref-sarkar2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">[45] </div><div class="csl-right-inline">A. Sarkar and I. Drosos, <span>“Vibe coding: Programming through conversation with artificial intelligence,”</span> Jun. 29, 2025. doi: <a href="https://doi.org/10.48550/arXiv.2506.23253">10.48550/arXiv.2506.23253</a>. Available: <a href="http://arxiv.org/abs/2506.23253">http://arxiv.org/abs/2506.23253</a></div>
</div>
<div id="ref-sheth2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[46] </div><div class="csl-right-inline">A. Sheth, K. Roy, and M. Gaur, <span>“Neurosymbolic <span>AI</span> – <span>Why</span>, <span>What</span>, and <span>How</span>,”</span> May 01, 2023. doi: <a href="https://doi.org/10.48550/arXiv.2305.00813">10.48550/arXiv.2305.00813</a>. Available: <a href="http://arxiv.org/abs/2305.00813">http://arxiv.org/abs/2305.00813</a></div>
</div>
<div id="ref-garcez2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[47] </div><div class="csl-right-inline">A. d’Avila Garcez and L. C. Lamb, <span>“Neurosymbolic <span>AI</span>: <span>The</span> 3rd <span>Wave</span>,”</span> Dec. 16, 2020. doi: <a href="https://doi.org/10.48550/arXiv.2012.05876">10.48550/arXiv.2012.05876</a>. Available: <a href="http://arxiv.org/abs/2012.05876">http://arxiv.org/abs/2012.05876</a></div>
</div>
<div id="ref-ganguly2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[48] </div><div class="csl-right-inline">D. Ganguly, S. Iyengar, V. Chaudhary, and S. Kalyanaraman, <span>“Proof of <span>Thought</span> : <span>Neurosymbolic Program Synthesis</span> allows <span>Robust</span> and <span>Interpretable Reasoning</span>,”</span> Sep. 25, 2024. doi: <a href="https://doi.org/10.48550/arXiv.2409.17270">10.48550/arXiv.2409.17270</a>. Available: <a href="http://arxiv.org/abs/2409.17270">http://arxiv.org/abs/2409.17270</a></div>
</div>
<div id="ref-gaur2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[49] </div><div class="csl-right-inline">M. Gaur and A. Sheth, <span>“Building <span>Trustworthy NeuroSymbolic AI Systems</span>: <span>Consistency</span>, <span>Reliability</span>, <span>Explainability</span>, and <span>Safety</span>,”</span> Dec. 05, 2023. doi: <a href="https://doi.org/10.48550/arXiv.2312.06798">10.48550/arXiv.2312.06798</a>. Available: <a href="http://arxiv.org/abs/2312.06798">http://arxiv.org/abs/2312.06798</a></div>
</div>
<div id="ref-tilwani2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[50] </div><div class="csl-right-inline">D. Tilwani, R. Venkataramanan, and A. P. Sheth, <span>“Neurosymbolic <span>AI</span> approach to <span>Attribution</span> in <span>Large Language Models</span>,”</span> Sep. 30, 2024. doi: <a href="https://doi.org/10.48550/arXiv.2410.03726">10.48550/arXiv.2410.03726</a>. Available: <a href="http://arxiv.org/abs/2410.03726">http://arxiv.org/abs/2410.03726</a></div>
</div>
<div id="ref-sarker2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[51] </div><div class="csl-right-inline">M. K. Sarker, L. Zhou, A. Eberhart, and P. Hitzler, <span>“Neuro-symbolic artificial intelligence: <span>Current</span> trends,”</span> <em>AIC</em>, vol. 34, no. 3, pp. 197–209, Mar. 2022, doi: <a href="https://doi.org/10.3233/aic-210084">10.3233/aic-210084</a>. Available: <a href="https://journals.sagepub.com/doi/full/10.3233/AIC-210084">https://journals.sagepub.com/doi/full/10.3233/AIC-210084</a></div>
</div>
<div id="ref-kautz2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[52] </div><div class="csl-right-inline">H. Kautz, <span>“The <span>Third AI Summer</span>,”</span> presented at the 34th <span>Annual Meeting</span> of the <span>Association</span> for the <span>Advancement</span> of <span>Artificial Intelligence</span>, Feb. 10, 2020. Available: <a href="https://www.youtube.com/watch?v=_cQITY0SPiw">https://www.youtube.com/watch?v=_cQITY0SPiw</a></div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/01-intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/03-related.html" class="pagination-link" aria-label="Related work">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Related work</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 © 2025 Konstantinos Chousos
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/kchousos">
<p><iconify-icon role="img" inline="" icon="fa6-brands:github" aria-label="Icon github from fa6-brands Iconify.design set." title="Icon github from fa6-brands Iconify.design set."></iconify-icon></p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://orcid.org/0009-0008-6063-7915">
<p><iconify-icon role="img" inline="" icon="academicons:orcid" aria-label="Icon orcid from academicons Iconify.design set." title="Icon orcid from academicons Iconify.design set."></iconify-icon></p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/kchousos/">
<p><iconify-icon role="img" inline="" icon="fa6-brands:linkedin" aria-label="Icon linkedin from fa6-brands Iconify.design set." title="Icon linkedin from fa6-brands Iconify.design set."></iconify-icon></p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="mailto:sdi2000215@di.uoa.gr">
<p><iconify-icon role="img" inline="" icon="material-symbols:mail" aria-label="Icon mail from material-symbols Iconify.design set." title="Icon mail from material-symbols Iconify.design set."></iconify-icon></p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.captionPrefix || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  




</body></html>